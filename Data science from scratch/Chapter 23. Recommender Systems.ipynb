{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f19222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\books\\\\python\\\\0.Data Science from Scratch- First Principles with Python',\n",
       " 'D:/books/python/0.Data Science from Scratch- First Principles with Python/data-science-from-scratch/scratch/',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\python38.zip',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\lidan\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\magic_impute-2.0.4-py3.8.egg',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\seqc-0.2.0-py3.8.egg',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\weasyprint-56.1-py3.8.egg',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\cairocffi-1.3.0-py3.8.egg',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\lidan\\\\miniconda3\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "    # caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, 'D:/books/python/0.Data Science from Scratch- First Principles with Python/data-science-from-scratch/scratch/')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6376a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Hadoop': 2,\n",
       "         'Big Data': 3,\n",
       "         'HBase': 3,\n",
       "         'Java': 3,\n",
       "         'Spark': 1,\n",
       "         'Storm': 1,\n",
       "         'Cassandra': 2,\n",
       "         'NoSQL': 1,\n",
       "         'MongoDB': 2,\n",
       "         'Postgres': 2,\n",
       "         'Python': 4,\n",
       "         'scikit-learn': 2,\n",
       "         'scipy': 1,\n",
       "         'numpy': 1,\n",
       "         'statsmodels': 2,\n",
       "         'pandas': 2,\n",
       "         'R': 4,\n",
       "         'statistics': 3,\n",
       "         'regression': 3,\n",
       "         'probability': 3,\n",
       "         'machine learning': 2,\n",
       "         'decision trees': 1,\n",
       "         'libsvm': 2,\n",
       "         'C++': 2,\n",
       "         'Haskell': 1,\n",
       "         'programming languages': 1,\n",
       "         'mathematics': 1,\n",
       "         'theory': 1,\n",
       "         'Mahout': 1,\n",
       "         'neural networks': 2,\n",
       "         'deep learning': 2,\n",
       "         'artificial intelligence': 2,\n",
       "         'MapReduce': 1,\n",
       "         'databases': 1,\n",
       "         'MySQL': 1,\n",
       "         'support vector machines': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_interests = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]  # 15 users\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "popular_interests = Counter(interest\n",
    "                            for user_interests in users_interests\n",
    "                            for interest in user_interests)\n",
    "\n",
    "popular_interests # 36 interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1e90dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Data',\n",
       " 'C++',\n",
       " 'Cassandra',\n",
       " 'HBase',\n",
       " 'Hadoop',\n",
       " 'Haskell',\n",
       " 'Java',\n",
       " 'Mahout',\n",
       " 'MapReduce',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NoSQL',\n",
       " 'Postgres',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Spark',\n",
       " 'Storm',\n",
       " 'artificial intelligence',\n",
       " 'databases',\n",
       " 'decision trees',\n",
       " 'deep learning',\n",
       " 'libsvm',\n",
       " 'machine learning',\n",
       " 'mathematics',\n",
       " 'neural networks',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'probability',\n",
       " 'programming languages',\n",
       " 'regression',\n",
       " 'scikit-learn',\n",
       " 'scipy',\n",
       " 'statistics',\n",
       " 'statsmodels',\n",
       " 'support vector machines',\n",
       " 'theory']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def most_popular_new_interests(\n",
    "        user_interests: List[str],\n",
    "        max_results: int = 5) -> List[Tuple[str, int]]:\n",
    "    suggestions = [(interest, frequency)\n",
    "                   for interest, frequency in popular_interests.most_common()\n",
    "                   if interest not in user_interests]\n",
    "    return suggestions[:max_results]\n",
    "\n",
    "unique_interests = sorted({interest\n",
    "                           for user_interests in users_interests\n",
    "                           for interest in user_interests})\n",
    "\n",
    "unique_interests # 36 interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fa6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unique_interests[:6] == [\n",
    "    'Big Data',\n",
    "    'C++',\n",
    "    'Cassandra',\n",
    "    'HBase',\n",
    "    'Hadoop',\n",
    "    'Haskell',\n",
    "    # ...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b85087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_user_interest_vector(user_interests: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list ofinterests, produce a vector whose ith element is 1\n",
    "    if unique_interests[i] is in the list, 0 otherwise\n",
    "    \"\"\"\n",
    "    return [1 if interest in user_interests else 0\n",
    "            for interest in unique_interests]\n",
    "\n",
    "user_interest_vectors = [make_user_interest_vector(user_interests)\n",
    "                         for user_interests in users_interests]\n",
    "user_interest_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f19b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_interest_vectors) # 15 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50fa4567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.3380617018914066,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1543033499620919,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1889822365046136,\n",
       " 0.5669467095138409,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1690308509457033,\n",
       " 0.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nlp import cosine_similarity\n",
    "from linear_algebra import dot, Vector\n",
    "import math\n",
    "\n",
    "def cosine_similarity(v1: Vector, v2: Vector) -> float:\n",
    "    return dot(v1, v2) / math.sqrt(dot(v1, v1) * dot(v2, v2))\n",
    "\n",
    "user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)\n",
    "                      for interest_vector_j in user_interest_vectors]\n",
    "                     for interest_vector_i in user_interest_vectors]\n",
    "\n",
    "user_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3447c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users 0 and 9 share interests in Hadoop, Java, and Big Data\n",
    "assert 0.56 < user_similarities[0][9] < 0.58, \"several shared interests\"\n",
    "\n",
    "# Users 0 and 8 share only one interest: Big Data\n",
    "assert 0.18 < user_similarities[0][8] < 0.20, \"only one shared interest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff19d682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0.5669467095138409),\n",
       " (1, 0.3380617018914066),\n",
       " (8, 0.1889822365046136),\n",
       " (13, 0.1690308509457033),\n",
       " (5, 0.1543033499620919)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar_users_to(user_id: int) -> List[Tuple[int, float]]:\n",
    "    pairs = [(other_user_id, similarity)                      # Find other\n",
    "             for other_user_id, similarity in                 # users with\n",
    "                enumerate(user_similarities[user_id])         # nonzero\n",
    "             if user_id != other_user_id and similarity > 0]  # similarity.\n",
    "\n",
    "    return sorted(pairs,                                      # Sort them\n",
    "                  key=lambda pair: pair[-1],                  # most similar\n",
    "                  reverse=True)                               # first.\n",
    "\n",
    "\n",
    "most_similar_to_zero = most_similar_users_to(0)\n",
    "user, score = most_similar_to_zero[0]\n",
    "\n",
    "most_similar_to_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd55742",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user == 9\n",
    "assert 0.56 < score < 0.57\n",
    "user, score = most_similar_to_zero[1]\n",
    "assert user == 1\n",
    "assert 0.33 < score < 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f243467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 0.5669467095138409),\n",
       " ('MongoDB', 0.50709255283711),\n",
       " ('Postgres', 0.50709255283711),\n",
       " ('NoSQL', 0.3380617018914066),\n",
       " ('neural networks', 0.1889822365046136),\n",
       " ('deep learning', 0.1889822365046136),\n",
       " ('artificial intelligence', 0.1889822365046136),\n",
       " ('databases', 0.1690308509457033),\n",
       " ('MySQL', 0.1690308509457033),\n",
       " ('Python', 0.1543033499620919),\n",
       " ('R', 0.1543033499620919),\n",
       " ('C++', 0.1543033499620919),\n",
       " ('Haskell', 0.1543033499620919),\n",
       " ('programming languages', 0.1543033499620919)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def user_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Sum up the similarities.\n",
    "    suggestions: Dict[str, float] = defaultdict(float)\n",
    "    for other_user_id, similarity in most_similar_users_to(user_id):\n",
    "        for interest in users_interests[other_user_id]:\n",
    "            suggestions[interest] += similarity\n",
    "\n",
    "    # Convert them to a sorted list.\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],  # weight\n",
    "                         reverse=True)\n",
    "\n",
    "    # And (maybe) exclude already-interests\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]\n",
    "\n",
    "\n",
    "ubs0 = user_based_suggestions(0)\n",
    "interest, score = ubs0[0]\n",
    "ubs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc83b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert interest == 'MapReduce'\n",
    "assert 0.56 < score < 0.57\n",
    "interest, score = ubs0[1]\n",
    "assert interest == 'MongoDB'\n",
    "assert 0.50 < score < 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6907e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_user_matrix = [[user_interest_vector[j]\n",
    "                         for user_interest_vector in user_interest_vectors]\n",
    "                        for j, _ in enumerate(unique_interests)]\n",
    "interest_user_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b32fb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 0.4082482904638631,\n",
       " 0.3333333333333333,\n",
       " 0.8164965809277261,\n",
       " 0.0,\n",
       " 0.6666666666666666,\n",
       " 0.0,\n",
       " 0.5773502691896258,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5773502691896258,\n",
       " 0.5773502691896258,\n",
       " 0.4082482904638631,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4082482904638631,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4082482904638631,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j)\n",
    "                          for user_vector_j in interest_user_matrix]\n",
    "                         for user_vector_i in interest_user_matrix]\n",
    "interest_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e525d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interest_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97ce1c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hadoop', 0.8164965809277261),\n",
       " ('Java', 0.6666666666666666),\n",
       " ('MapReduce', 0.5773502691896258),\n",
       " ('Spark', 0.5773502691896258),\n",
       " ('Storm', 0.5773502691896258),\n",
       " ('Cassandra', 0.4082482904638631),\n",
       " ('artificial intelligence', 0.4082482904638631),\n",
       " ('deep learning', 0.4082482904638631),\n",
       " ('neural networks', 0.4082482904638631),\n",
       " ('HBase', 0.3333333333333333)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar_interests_to(interest_id: int):\n",
    "    similarities = interest_similarities[interest_id]\n",
    "    pairs = [(unique_interests[other_interest_id], similarity)\n",
    "             for other_interest_id, similarity in enumerate(similarities)\n",
    "             if interest_id != other_interest_id and similarity > 0]\n",
    "    return sorted(pairs,\n",
    "                  key=lambda pair: pair[-1],\n",
    "                  reverse=True)\n",
    "\n",
    "\n",
    "msit0 = most_similar_interests_to(0)\n",
    "msit0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b72000cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert msit0[0][0] == 'Hadoop'\n",
    "assert 0.815 < msit0[0][1] < 0.817\n",
    "assert msit0[1][0] == 'Java'\n",
    "assert 0.666 < msit0[1][1] < 0.667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa9af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_suggestions(user_id: int,\n",
    "                           include_current_interests: bool = False):\n",
    "    # Add up the similar interests\n",
    "    suggestions = defaultdict(float)\n",
    "    user_interest_vector = user_interest_vectors[user_id]\n",
    "    for interest_id, is_interested in enumerate(user_interest_vector):\n",
    "        if is_interested == 1:\n",
    "            similar_interests = most_similar_interests_to(interest_id)\n",
    "            for interest, similarity in similar_interests:\n",
    "                suggestions[interest] += similarity\n",
    "\n",
    "    # Sort them by weight\n",
    "    suggestions = sorted(suggestions.items(),\n",
    "                         key=lambda pair: pair[-1],\n",
    "                         reverse=True)\n",
    "\n",
    "    if include_current_interests:\n",
    "        return suggestions\n",
    "    else:\n",
    "        return [(suggestion, weight)\n",
    "                for suggestion, weight in suggestions\n",
    "                if suggestion not in users_interests[user_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2254a839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 1.861807319565799),\n",
       " ('MongoDB', 1.3164965809277263),\n",
       " ('Postgres', 1.3164965809277263),\n",
       " ('NoSQL', 1.2844570503761732),\n",
       " ('MySQL', 0.5773502691896258),\n",
       " ('databases', 0.5773502691896258),\n",
       " ('Haskell', 0.5773502691896258),\n",
       " ('programming languages', 0.5773502691896258),\n",
       " ('artificial intelligence', 0.4082482904638631),\n",
       " ('deep learning', 0.4082482904638631),\n",
       " ('neural networks', 0.4082482904638631),\n",
       " ('C++', 0.4082482904638631),\n",
       " ('Python', 0.2886751345948129),\n",
       " ('R', 0.2886751345948129)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibs0 = item_based_suggestions(0)\n",
    "ibs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7fa5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ibs0[0][0] == 'MapReduce'\n",
    "assert 1.86 < ibs0[0][1] < 1.87\n",
    "assert ibs0[1][0] in ('Postgres', 'MongoDB')  # A tie\n",
    "assert 1.31 < ibs0[1][1] < 1.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "659b1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the locations of your files\n",
    "    \n",
    "# This points to the current directory, modify if your files are elsewhere.\n",
    "MOVIES = \"ml-100k/u.item\"   # pipe-delimited: movie_id|title|...\n",
    "RATINGS = \"ml-100k/u.data\"  # tab-delimited: user_id, movie_id, rating, timestamp\n",
    "    \n",
    "from typing import NamedTuple\n",
    "    \n",
    "class Rating(NamedTuple):\n",
    "    user_id: str\n",
    "    movie_id: str\n",
    "    rating: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05da1588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story (1995)',\n",
       " 'GoldenEye (1995)',\n",
       " 'Four Rooms (1995)',\n",
       " 'Get Shorty (1995)',\n",
       " 'Copycat (1995)',\n",
       " 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)',\n",
       " 'Twelve Monkeys (1995)',\n",
       " 'Babe (1995)',\n",
       " 'Dead Man Walking (1995)',\n",
       " 'Richard III (1995)']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "# We specify this encoding to avoid a UnicodeDecodeError.\n",
    "# see: https://stackoverflow.com/a/53136168/1076346\n",
    "with open(MOVIES, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"|\")\n",
    "    movies = {movie_id: title for movie_id, title, *_ in reader}\n",
    "list(movies.values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a97f2a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating(user_id='196', movie_id='242', rating=3.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of [Rating]\n",
    "with open(RATINGS, encoding=\"iso-8859-1\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    ratings = [Rating(user_id, movie_id, float(rating))\n",
    "                for user_id, movie_id, rating, _ in reader]\n",
    "    \n",
    "ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ff2632d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3885ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1682 movies rated by 943 users\n",
    "assert len(movies) == 1682\n",
    "assert len(list({rating.user_id for rating in ratings})) == 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ff0eaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'50': [], '172': [], '181': []}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "    \n",
    "# Data structure for accumulating ratings by movie_id\n",
    "star_wars_ratings = {movie_id: []\n",
    "                     for movie_id, title in movies.items()\n",
    "                     if re.search(\"Star Wars|Empire Strikes|Jedi\", title)}\n",
    "\n",
    "star_wars_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1637b55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over ratings, accumulating the Star Wars ones\n",
    "for rating in ratings:\n",
    "    if rating.movie_id in star_wars_ratings:\n",
    "        star_wars_ratings[rating.movie_id].append(rating.rating)\n",
    "        \n",
    "star_wars_ratings['50'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bec54817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(star_wars_ratings['50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e53bcb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.3584905660377355, '50'),\n",
       " (4.204359673024523, '172'),\n",
       " (4.007889546351085, '181')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the average rating for each movie\n",
    "avg_ratings = [(sum(title_ratings) / len(title_ratings), movie_id)\n",
    "               for movie_id, title_ratings in star_wars_ratings.items()]\n",
    "avg_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7bf7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36 Star Wars (1977)\n",
      "4.20 Empire Strikes Back, The (1980)\n",
      "4.01 Return of the Jedi (1983)\n"
     ]
    }
   ],
   "source": [
    "# And then print them in order\n",
    "for avg_rating, movie_id in sorted(avg_ratings, reverse=True):\n",
    "    print(f\"{avg_rating:.2f} {movies[movie_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a2cb917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.530842857142857, 1.2609526646939684)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "random.shuffle(ratings)\n",
    "    \n",
    "split1 = int(len(ratings) * 0.7)\n",
    "split2 = int(len(ratings) * 0.85)\n",
    "    \n",
    "train = ratings[:split1]              # 70% of the data\n",
    "validation = ratings[split1:split2]   # 15% of the data\n",
    "test = ratings[split2:]               # 15% of the data\n",
    "    \n",
    "avg_rating = sum(rating.rating for rating in train) / len(train)\n",
    "baseline_error = sum((rating.rating - avg_rating) ** 2\n",
    "                     for rating in test) / len(test)\n",
    "avg_rating, baseline_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cdef161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what we hope to do better than\n",
    "assert 1.26 < baseline_error < 1.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a94b604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['623', '927', '356', '147', '510', '115', '191', '787', '907', '94']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding vectors for matrix factorization model\n",
    "    \n",
    "from deep_learning import random_tensor\n",
    "    \n",
    "EMBEDDING_DIM = 2\n",
    "    \n",
    "# Find unique ids\n",
    "user_ids = {rating.user_id for rating in ratings}\n",
    "movie_ids = {rating.movie_id for rating in ratings}\n",
    "list(user_ids)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d94a3d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6083431243896484, 0.5195331573486328]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then create a random vector per id\n",
    "user_vectors = {user_id: random_tensor(EMBEDDING_DIM)\n",
    "                for user_id in user_ids}\n",
    "\n",
    "user_vectors['623']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a272d52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0661983489990234, -3.314085006713867]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vectors = {movie_id: random_tensor(EMBEDDING_DIM)\n",
    "                for movie_id in movie_ids}\n",
    "movie_vectors['147']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10fd789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for matrix factorization model\n",
    "    \n",
    "from typing import List\n",
    "import tqdm\n",
    "from linear_algebra import dot\n",
    "    \n",
    "def loop(dataset: List[Rating],\n",
    "         learning_rate: float = None) -> None:\n",
    "    with tqdm.tqdm(dataset) as t:\n",
    "        loss = 0.0\n",
    "        for i, rating in enumerate(t):\n",
    "                movie_vector = movie_vectors[rating.movie_id]\n",
    "                user_vector = user_vectors[rating.user_id]\n",
    "                predicted = dot(user_vector, movie_vector)\n",
    "                error = predicted - rating.rating\n",
    "                loss += error ** 2\n",
    "    \n",
    "                if learning_rate is not None:\n",
    "                    #     predicted = m_0 * u_0 + ... + m_k * u_k\n",
    "                    # So each u_j enters output with coefficent m_j\n",
    "                    # and each m_j enters output with coefficient u_j\n",
    "                    user_gradient = [error * m_j for m_j in movie_vector]\n",
    "                    movie_gradient = [error * u_j for u_j in user_vector]\n",
    "    \n",
    "                    # Take gradient steps\n",
    "                    for j in range(EMBEDDING_DIM):\n",
    "                        user_vector[j] -= learning_rate * user_gradient[j]\n",
    "                        movie_vector[j] -= learning_rate * movie_gradient[j]\n",
    "    \n",
    "                t.set_description(f\"avg loss: {loss / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dc9a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045000000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 1.0211425572137967: 100%|█████████████████████████████████████████████| 15000/15000 [00:19<00:00, 764.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.04050000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 1.0000039868037591: 100%|█████████████████████████████████████████████| 15000/15000 [00:17<00:00, 850.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.03645000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.918619684025979: 100%|██████████████████████████████████████████████| 70000/70000 [01:24<00:00, 825.12it/s]\n",
      "avg loss: 0.9817346749406405: 100%|█████████████████████████████████████████████| 15000/15000 [00:17<00:00, 865.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.03280500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.9663368329091103: 100%|█████████████████████████████████████████████| 15000/15000 [00:17<00:00, 867.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.02952450000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8822064358705789: 100%|█████████████████████████████████████████████| 70000/70000 [01:31<00:00, 766.93it/s]\n",
      "avg loss: 0.9533168068116032: 100%|█████████████████████████████████████████████| 15000/15000 [00:20<00:00, 731.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.02657205000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8676009876392613: 100%|█████████████████████████████████████████████| 70000/70000 [01:32<00:00, 756.93it/s]\n",
      "avg loss: 0.9422547062020881: 100%|█████████████████████████████████████████████| 15000/15000 [00:18<00:00, 806.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.02391484500000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8548664950816122: 100%|█████████████████████████████████████████████| 70000/70000 [01:27<00:00, 797.50it/s]\n",
      "avg loss: 0.9328234525417847: 100%|█████████████████████████████████████████████| 15000/15000 [00:19<00:00, 787.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.021523360500000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8436978737072715: 100%|█████████████████████████████████████████████| 70000/70000 [01:22<00:00, 843.67it/s]\n",
      "avg loss: 0.9247656097770673: 100%|█████████████████████████████████████████████| 15000/15000 [00:16<00:00, 912.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.01937102445000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8338504279918582: 100%|█████████████████████████████████████████████| 70000/70000 [01:17<00:00, 906.88it/s]\n",
      "avg loss: 0.9178724854261849: 100%|█████████████████████████████████████████████| 15000/15000 [00:16<00:00, 902.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.01743392200500001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.817364841013516: 100%|██████████████████████████████████████████████| 70000/70000 [01:21<00:00, 854.43it/s]\n",
      "avg loss: 0.9069100779271915: 100%|█████████████████████████████████████████████| 15000/15000 [00:16<00:00, 897.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.014121476824050006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8104327186696272: 100%|█████████████████████████████████████████████| 70000/70000 [01:18<00:00, 891.22it/s]\n",
      "avg loss: 0.9025654357115206: 100%|█████████████████████████████████████████████| 15000/15000 [00:16<00:00, 886.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.012709329141645007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.8042198043667639: 100%|█████████████████████████████████████████████| 70000/70000 [01:20<00:00, 869.88it/s]\n",
      "avg loss: 0.798633714446718: 100%|██████████████████████████████████████████████| 70000/70000 [01:25<00:00, 821.63it/s]\n",
      "avg loss: 0.895599740334549: 100%|██████████████████████████████████████████████| 15000/15000 [00:18<00:00, 796.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.010294556604732457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.793596568880736: 100%|██████████████████████████████████████████████| 70000/70000 [01:27<00:00, 798.40it/s]\n",
      "avg loss: 0.7890423509101969: 100%|█████████████████████████████████████████████| 70000/70000 [01:24<00:00, 833.16it/s]\n",
      "avg loss: 0.7849148471451856: 100%|█████████████████████████████████████████████| 70000/70000 [01:13<00:00, 952.17it/s]\n",
      "avg loss: 0.8882564345982598: 100%|█████████████████████████████████████████████| 15000/15000 [00:15<00:00, 995.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.007504731764849962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.781166020017358: 100%|█████████████████████████████████████████████| 70000/70000 [01:09<00:00, 1002.56it/s]\n",
      "avg loss: 0.886400856551135: 100%|██████████████████████████████████████████████| 15000/15000 [00:15<00:00, 998.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.006754258588364966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.884772071195777: 100%|█████████████████████████████████████████████| 15000/15000 [00:14<00:00, 1017.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.00607883272952847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.7746455469155945: 100%|████████████████████████████████████████████| 70000/70000 [01:09<00:00, 1000.40it/s]\n",
      "avg loss: 0.8833399448376096: 100%|█████████████████████████████████████████████| 15000/15000 [00:17<00:00, 864.11it/s]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "for epoch in range(20):\n",
    "    learning_rate *= 0.9\n",
    "    print(epoch, learning_rate)\n",
    "    loop(train, learning_rate=learning_rate)\n",
    "    loop(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "25afe97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg loss: 0.889385667482585:  48%|██████████████████████▋                        | 7228/15000 [00:07<00:08, 943.49it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "avg loss: 0.8938446096649737: 100%|█████████████████████████████████████████████| 15000/15000 [00:15<00:00, 947.06it/s]\n"
     ]
    }
   ],
   "source": [
    "loop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a18edcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from working_with_data import pca, transform\n",
    "\n",
    "from linear_algebra import magnitude\n",
    "from linear_algebra import dot\n",
    "from gradient_descent import gradient_step\n",
    "from linear_algebra import subtract\n",
    "from linear_algebra import scalar_multiply\n",
    "\n",
    "def direction(w: Vector) -> Vector:\n",
    "    mag = magnitude(w)\n",
    "    return [w_i / mag for w_i in w]\n",
    "\n",
    "\n",
    "def directional_variance(data: List[Vector], w: Vector) -> float:\n",
    "    \"\"\"\n",
    "    Returns the variance of x in the direction of w\n",
    "    \"\"\"\n",
    "    w_dir = direction(w)\n",
    "    return sum(dot(v, w_dir) ** 2 for v in data)\n",
    "\n",
    "def directional_variance_gradient(data: List[Vector], w: Vector) -> Vector:\n",
    "    \"\"\"\n",
    "    The gradient of directional variance with respect to w\n",
    "    \"\"\"\n",
    "    w_dir = direction(w)\n",
    "    return [sum(2 * dot(v, w_dir) * v[i] for v in data)\n",
    "            for i in range(len(w))]\n",
    "\n",
    "def first_principal_component(data: List[Vector],\n",
    "                              n: int = 100,\n",
    "                              step_size: float = 0.1) -> Vector:\n",
    "    # Start with a random guess\n",
    "    guess = [1.0 for _ in data[0]]\n",
    "\n",
    "    with tqdm.trange(n) as t:\n",
    "        for _ in t:\n",
    "            dv = directional_variance(data, guess)\n",
    "            gradient = directional_variance_gradient(data, guess)\n",
    "            guess = gradient_step(guess, gradient, step_size)\n",
    "            t.set_description(f\"dv: {dv:.3f}\")\n",
    "\n",
    "    return direction(guess)\n",
    "def project(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"return the projection of v onto the direction w\"\"\"\n",
    "    projection_length = dot(v, w)\n",
    "    return scalar_multiply(projection_length, w)\n",
    "\n",
    "def remove_projection_from_vector(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"projects v onto w and subtracts the result from v\"\"\"\n",
    "    return subtract(v, project(v, w))\n",
    "\n",
    "def remove_projection(data: List[Vector], w: Vector) -> List[Vector]:\n",
    "    return [remove_projection_from_vector(v, w) for v in data]\n",
    "\n",
    "def pca(data: List[Vector], num_components: int) -> List[Vector]:\n",
    "    components: List[Vector] = []\n",
    "    for _ in range(num_components):\n",
    "        component = first_principal_component(data)\n",
    "        components.append(component)\n",
    "        data = remove_projection(data, component)\n",
    "\n",
    "    return components\n",
    "\n",
    "def transform_vector(v: Vector, components: List[Vector]) -> Vector:\n",
    "    return [dot(v, w) for w in components]\n",
    "\n",
    "def transform(data: List[Vector], components: List[Vector]) -> List[Vector]:\n",
    "    return [transform_vector(v, components) for v in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3f40880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dv: 4671.773: 100%|█████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 137.36it/s]\n",
      "dv: 970.453: 100%|██████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 149.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1467', 5.0, 'Saint of Fort Washington, The (1993)', [-2.771837209759701, -1.8494031915793183]), ('1642', 4.5, \"Some Mother's Son (1996)\", [-2.7397471962953173, 0.13562094969089605]), ('1536', 5.0, 'Aiqing wansui (1994)', [-2.716630664495698, -0.3253082882465278]), ('1367', 4.2, 'Faust (1994)', [-2.7116138917507255, -0.3181415848135587]), ('1398', 4.5, 'Anna (1996)', [-2.6529933218681343, -0.7040433360887142]), ('1643', 3.75, 'Angel Baby (1995)', [-2.648887059297251, 0.7456847922385637]), ('1500', 5.0, 'Santa with Muscles (1996)', [-2.6385243635713294, 1.3830240992791552]), ('1158', 4.0, 'Fille seule, La (A Single Girl) (1995)', [-2.628207010894224, -0.7527508158869398]), ('1463', 3.3333333333333335, 'Boys, Les (1997)', [-2.600800401823833, -0.23303639566814638]), ('1498', 4.0, 'Farmer & Chase (1995)', [-2.5790271646339313, -0.564000667456121]), ('1629', 4.0, 'Nico Icon (1995)', [-2.572085161988423, -1.1378927126885205]), ('1503', 3.1, 'Gold Diggers: The Secret of Bear Mountain (1995)', [-2.5677809449211777, 0.9266523708176959]), ('851', 3.75, 'Two or Three Things I Know About Her (1966)', [-2.5472208928705515, -0.005247976753935735]), ('811', 3.9444444444444446, 'Thirty-Two Short Films About Glenn Gould (1993)', [-2.5430052310443436, -1.0317234557189312]), ('867', 4.0, 'Whole Wide World, The (1996)', [-2.488883993625356, 0.1317820983480525]), ('1223', 3.5, 'King of the Hill (1993)', [-2.4839210357149963, -2.42445682177899]), ('1064', 4.25, 'Crossfire (1947)', [-2.4746647561566975, -0.46777315495884547]), ('119', 4.5, 'Maya Lin: A Strong Clear Vision (1994)', [-2.447826852358636, 0.10860967012910105]), ('1449', 4.625, 'Pather Panchali (1955)', [-2.432421987445799, 0.796785707763666]), ('1445', 2.75, 'Ladybird Ladybird (1994)', [-2.4301169610022795, 0.5454666310106971]), ('814', 5.0, 'Great Day in Harlem, A (1994)', [-2.427260671400507, -0.024601659035287382]), ('1122', 5.0, 'They Made Me a Criminal (1939)', [-2.4174767767890692, 0.4871268219359049]), ('1537', 4.0, 'Cosi (1996)', [-2.3807489409287648, -0.6412638559820392]), ('1344', 3.2, 'Story of Xinghua, The (1993)', [-2.3735686209689915, 0.49597543721802945]), ('1594', 4.5, 'Everest (1998)', [-2.372654820390716, -0.23780476133267908])]\n"
     ]
    }
   ],
   "source": [
    "original_vectors = [vector for vector in movie_vectors.values()]\n",
    "components = pca(original_vectors, 2)\n",
    "    \n",
    "ratings_by_movie = defaultdict(list)\n",
    "for rating in ratings:\n",
    "    ratings_by_movie[rating.movie_id].append(rating.rating)\n",
    "    \n",
    "vectors = [\n",
    "        (movie_id,\n",
    "         sum(ratings_by_movie[movie_id]) / len(ratings_by_movie[movie_id]),\n",
    "         movies[movie_id],\n",
    "         vector)\n",
    "        for movie_id, vector in zip(movie_vectors.keys(),\n",
    "                                    transform(original_vectors, components))\n",
    "]\n",
    "    \n",
    "# Print top 25 and bottom 25 by first principal component\n",
    "print(sorted(vectors, key=lambda v: v[-1][0])[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "652fb9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1641', 3.0, 'Dadetown (1995)', [0.1050167335940238, -2.3467616155453106]), ('1618', 1.0, 'King of New York (1990)', [0.15671756247280655, 0.2941681103660226]), ('1026', 2.5, 'Lay of the Land, The (1997)', [0.17195168003918782, -0.456604523875275]), ('1661', 1.0, 'New Age, The (1994)', [0.18480707146782177, 0.8710807124118296]), ('1358', 3.0, 'The Deadly Cure (1996)', [0.19918296240916383, -0.8273357229573196]), ('1588', 2.0, 'Salut cousin! (1996)', [0.24435234303008127, -1.0547804018840883]), ('1635', 3.0, 'Two Friends (1986) ', [0.33180815305499023, -0.9860043851834671]), ('1349', 1.0, 'Mille bolle blu (1993)', [0.36740284221107133, -0.09187346821317097]), ('1583', 1.0, 'Invitation, The (Zaproszenie) (1986)', [0.3809323932351213, -0.5512435824019071]), ('1581', 1.0, 'Woman in Question, The (1950)', [0.3947037365523186, -0.7736216232091806]), ('1557', 1.0, 'Yankee Zulu (1994)', [0.45491586950614343, -0.25669202607552744]), ('1670', 3.0, 'Tainted (1998)', [0.5782486309720866, -0.24150988380594524]), ('1601', 1.0, 'Office Killer (1997)', [0.78066288906004, 1.6170291503615062]), ('1660', 2.0, 'Small Faces (1995)', [0.8630625530461743, 0.1277363801631688]), ('1510', 3.0, 'Mad Dog Time (1996)', [0.9418411874774332, 0.2259486706964979]), ('1579', 1.0, 'Baton Rouge (1988)', [0.950299561265947, -0.1237819021021926]), ('1604', 4.0, 'He Walked by Night (1948)', [0.9863627698310007, -1.036013560849804]), ('1520', 3.0, 'Fear, The (1995)', [1.0540873458436928, -1.7808464177934935]), ('1625', 4.0, 'Nightwatch (1997)', [1.28170795759324, -1.106462747543111]), ('1613', 4.0, 'Tokyo Fist (1995)', [1.302001726969499, -1.5100944228592037]), ('1564', 1.0, 'To Cross the Rubicon (1991)', [1.4766504382176178, -1.3031322925314717]), ('1548', 1.0, 'The Courtyard (1995)', [1.7630885213970144, -0.11168918265279529]), ('1576', 1.0, 'Hungarian Fairy Tale, A (1987)', [1.8177927415659458, -1.120160029831416]), ('1546', 1.0, 'Shadows (Cienie) (1988)', [1.9091373326783647, 0.6038719655321185]), ('1343', 1.0, 'Lotto Land (1995)', [2.489500593639033, 1.5248930421999765])]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(vectors, key=lambda v: v[-1][0])[-25:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
