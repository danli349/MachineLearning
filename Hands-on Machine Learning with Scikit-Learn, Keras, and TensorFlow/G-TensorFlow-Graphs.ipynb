{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f28e86",
   "metadata": {},
   "source": [
    "## TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f49da",
   "metadata": {},
   "source": [
    "TF Functions are polymorphic, meaning they support inputs of different types (and shapes). For example, consider the following `tf_cube()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f7fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb7b1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=27>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8dc458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036dcbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant([2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d30b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  8.],\n",
       "       [27., 64.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant([[1.0, 2.0], [3.0, 4.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8781712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction tf_cube(x) at 0x130224EFEE0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6c4f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a352d5e",
   "metadata": {},
   "source": [
    "Figure G-1 shows the `tf_cube()` TF Function, after we called `tf_cube(2)` and `tf_cube(tf.constant(2.0))`: two *concrete functions* were generated, one for each signature, each with its own optimized function graph (`FuncGraph`), and its own function definition (`FunctionDef`). A function definition points to the parts of the graph that correspond to the function’s inputs and outputs. In each `FuncGraph`, the nodes (ovals) represent operations (e.g., power, constants, or placeholders for arguments like `x`), while the edges (the solid arrows between the operations) represent the tensors that will flow through the graph. The *concrete function* on the left is specialized for `x = 2`, so TensorFlow managed to simplify it to just output `8` all the time (note that the function definition does not even have an input). The *concrete function* on the right is specialized for float32 scalar tensors, and it could not be simplified. If we call `tf_cube(tf.constant(5.0))`, the second concrete function will be called, the placeholder operation for `x` will output `5.0`, then the power operation will compute `5.0 ** 3`, so the output will be `125.0`. \n",
    "\n",
    "<img src=\"./chapters/G/1.png\">\n",
    "<div style=\"text-align:center\"> Figure G-1. The tf_cube() TF Function, with its ConcreteFunctions and their FunctionGraphs </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13c6b9",
   "metadata": {},
   "source": [
    "Now let’s continue to peek under the hood, and see how to access function definitions and function graphs and how to explore a graph’s operations and tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82808285",
   "metadata": {},
   "source": [
    "## Exploring Function Definitions and Graphs  \n",
    "\n",
    "You can access a concrete function’s computation graph using the `graph` attribute, and get the list of its operations by calling the graph’s `get_operations()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de199cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb6ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b839b66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x13022556490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b1520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0baca",
   "metadata": {},
   "source": [
    "In this example, the first operation represents the input argument `x` (it is called a *placeholder*), the second “operation” represents the constant `3`, the third operation represents the power operation (`**`), and the final operation represents the output of this function (it is an identity operation, meaning it will do nothing more than copy the output of the addition operation). Each operation has a list of input and output tensors that you can easily access using the operation’s `inputs` and `outputs` attributes. For example, let’s get the list of inputs and outputs of the power operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032a32d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'pow' type=Pow>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1d2d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10466225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982772e",
   "metadata": {},
   "source": [
    "This computation graph is represented in Figure G-2.  \n",
    "\n",
    "<img src=\"./chapters/G/2.png\">\n",
    "<div style=\"text-align:center\"> Figure G-2. Example of a computation graph </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a844e",
   "metadata": {},
   "source": [
    "Note that each operation has a name. It defaults to the name of the operation (e.g., \"`pow`\"), but you can define it manually when calling the operation (e.g., `tf.pow(x, 3, name=\"other_name\")`). If a name already exists, TensorFlow automatically adds a unique index (e.g., \"`pow_1`\", \"`pow_2`\", etc.). Each tensor also has a unique name: it is always the name of the operation that outputs this tensor, plus `:0` if it is the operation’s first output, or `:1` if it is the second output, and so on. You can fetch an operation or a tensor by name using the graph’s `get_operation_by_name()` or `get_tensor_by_name()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819e4e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae40d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eaa79",
   "metadata": {},
   "source": [
    "The concrete function also contains the function definition (represented as a protocol buffer), which includes the function’s signature. This signature allows the concrete function to know which placeholders to feed with the input values, and which tensors to return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd5d519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_tf_cube_29\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd3c77",
   "metadata": {},
   "source": [
    "## A Closer Look at Tracing  \n",
    "\n",
    "Let’s tweak the `tf_cube()` function to print its input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7d07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"x =\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33ea42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454f4152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9f93b",
   "metadata": {},
   "source": [
    "The `result` looks good, but look at what was printed: `x` is a symbolic tensor! It has a shape and a data type, but no value. Plus it has a name (\"`x:0`\"). This is because the `print()` function is not a TensorFlow operation, so it will only run when the Python function is traced, which happens in graph mode, with arguments replaced with symbolic tensors (same type and shape, but no value). Since the `print()` function was not captured into the graph, the next times we call `tf_cube()` with float32 scalar tensors, nothing is printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "358eb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b880bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant(4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72dd907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=64.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba97bf5",
   "metadata": {},
   "source": [
    "But if we call `tf_cube()` with a tensor of a different type or shape, or with a new Python value, the function will be traced again, so the `print()` function will be called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49dc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2) # new Python value: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f11d6da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(3) # new Python value: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a147b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b83e7634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function tf_cube at 0x00000130224FD9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fd77b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.]])) # Same shape: no trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d4df64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(tf.constant(4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a5834f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_cube(3) # new Python value: trace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a9f6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 4\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function tf_cube at 0x00000130224FD9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(4) # new Python value: trace!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907605d",
   "metadata": {},
   "source": [
    "In some cases, you may want to restrict a TF Function to a specific input signature. For example, suppose you know that you will only ever call a TF Function with batches of 28 × 28–pixel images, but the batches will have very different sizes. You may not want TensorFlow to generate a different concrete function for each batch size, or count on it to figure out on its own when to use `None`. In this case, you can specify the input signature like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e739647",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f941f",
   "metadata": {},
   "source": [
    "This TF Function will accept any float32 tensor of shape `[*, 28, 28]`, and it will reuse the same concrete function every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b66fe1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Works fine. Traces the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9069f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_images = shrink(img_batch_2) # Works fine. Same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3922dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 14, 14])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881f1fa",
   "metadata": {},
   "source": [
    "However, if you try to call this TF Function with a Python value, or a tensor of an unexpected data type or shape, you will get an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "488d8782",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[[0.21487963 0.8821975 ]\n  [0.9357896  0.19632602]]\n\n [[0.24513781 0.18792224]\n  [0.5411782  0.5384644 ]]], shape=(2, 2, 2), dtype=float32))\n  input_signature: (\n    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16884/2095809837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_batch_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreprocessed_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshrink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_batch_3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ValueError! Unexpected signature.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   2852\u001b[0m       \u001b[0mflat_input_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2853\u001b[0m       flatten_inputs)):\n\u001b[1;32m-> 2854\u001b[1;33m     raise ValueError(\"Python inputs incompatible with input_signature:\\n\"\n\u001b[0m\u001b[0;32m   2855\u001b[0m                      f\"{format_error_message(inputs, input_signature)}.\")\n\u001b[0;32m   2856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[[0.21487963 0.8821975 ]\n  [0.9357896  0.19632602]]\n\n [[0.24513781 0.18792224]\n  [0.5411782  0.5384644 ]]], shape=(2, 2, 2), dtype=float32))\n  input_signature: (\n    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))."
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "preprocessed_images = shrink(img_batch_3)  # ValueError! Unexpected signature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaeff07",
   "metadata": {},
   "source": [
    "## Using AutoGraph to Capture Control Flow  \n",
    "\n",
    "If your function contains a simple `for` loop, what do you expect will happen? For example, let’s write a function that will add `10` to its input, by just adding 1 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "455227ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47ff72",
   "metadata": {},
   "source": [
    "It works fine, but when we look at its graph, we find that it does not contain a loop: it just contains 10 addition operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f8a7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "215790fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efa0d67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83897584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9fca6",
   "metadata": {},
   "source": [
    "This actually makes sense: when the function got traced, the loop ran 10 times, so the `x += 1` operation was run 10 times, and since it was in graph mode, it recorded this operation 10 times in the graph. You can think of this `for` loop as a “static” loop that gets unrolled when the graph is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af05f36",
   "metadata": {},
   "source": [
    "If you want the graph to contain a “dynamic” loop instead (i.e., one that runs when the graph is executed), you can create one manually using the `tf.while_loop()` operation, but it is not very intuitive (see the “Using AutoGraph to Capture Control Flow” section of the Chapter 12 notebook for an example). Instead, it is much simpler to use TensorFlow’s *AutoGraph* feature, discussed in Chapter 12. \n",
    "\n",
    "`AutoGraph` is actually activated by default (if you ever need to turn it off, you can pass `autograph=False` to `tf.function()`). So if it is on, why didn’t it capture the for loop in the `add_10()` function? Well, it only captures for loops that iterate over `tf.range()`, not `range()`. This is to give you the choice:\n",
    "\n",
    "  - If you use `range()`, the for loop will be static, meaning it will only be executed when the function is traced. The loop will be “unrolled” into a set of operations for each iteration, as we saw.\n",
    "\n",
    "  - If you use `tf.range()`, the loop will be dynamic, meaning that it will be included in the graph itself (but it will not run during tracing).\n",
    "\n",
    "Let’s look at the graph that gets generated if you just replace `range()` with `tf.range()` in the `add_10()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a3a0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ce88d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90796e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7199e",
   "metadata": {},
   "source": [
    "As you can see, the graph now contains a `While` loop operation, as if you had called the `tf.while_loop()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844eb573",
   "metadata": {},
   "source": [
    "## Handling Variables and Other Resources in TF Functions  \n",
    "\n",
    "In TensorFlow, variables and other stateful objects, such as queues or datasets, are called *resources*. TF Functions treat them with special care: any operation that reads or updates a resource is considered stateful, and TF Functions ensure that stateful operations are executed in the order they appear (as opposed to stateless operations, which may be run in parallel, so their order of execution is not guaranteed). Moreover, when you pass a resource as an argument to a TF Function, it gets passed by reference, so the function may modify it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ea06577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)\n",
    "\n",
    "increment(counter) # counter is now equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16f19a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter) # counter is now equal to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0fda9",
   "metadata": {},
   "source": [
    "If you peek at the function definition, the first argument is marked as a resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2fac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "412eb609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401341e0",
   "metadata": {},
   "source": [
    "It is also possible to use a `tf.Variable` defined outside of the function, without explicitly passing it as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eb57131",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "149efef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ca945f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "829059c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a165bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"c\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2142e1",
   "metadata": {},
   "source": [
    "The TF Function will treat this as an implicit first argument, so it will actually end up with the same signature (except for the name of the argument). However, using global variables can quickly become messy, so you should generally wrap variables (and other resources) inside classes. The good news is `@tf.function` works fine with methods too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af5223f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81819763",
   "metadata": {},
   "source": [
    "##  Using TF Functions with tf.keras (or Not)  \n",
    "\n",
    "By default, any custom function, layer, or model you use with `tf.keras` will automatically be converted to a TF Function; you do not need to do anything at all! However, in some cases you may want to deactivate this automatic conversion—for example, if your custom code cannot be turned into a TF Function, or if you just want to debug your code, which is much easier in eager mode. To do this, you can simply pass `dynamic=True` when creating the model or any of its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd424de0",
   "metadata": {},
   "source": [
    "If your custom model or layer will always be dynamic, you can instead call the base class’s constructor with `dynamic=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(dynamic=True, **kwargs)\n",
    "        [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95426e18",
   "metadata": {},
   "source": [
    "Alternatively, you can pass `run_eagerly=True` when calling the `compile()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f19f5",
   "metadata": {},
   "source": [
    "Now you know how TF Functions handle polymorphism (with multiple concrete functions), how graphs are automatically generated using AutoGraph and tracing, what graphs look like, how to explore their symbolic operations and tensors, how to handle variables and resources, and how to use TF Functions with `tf.keras`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
