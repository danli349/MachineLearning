{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 – Introduction to Artificial Neural Networks with Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons  \n",
    "\n",
    "The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron (see Figure 10-4) called a *threshold logic unit (TLU)*, or sometimes a *linear threshold unit (LTU)*. The inputs and output are numbers (instead of binary on/off values), and each input connection is associated with a weight. The TLU computes a weighted sum of its inputs ($\\mathbf z = w_1 x_1 + w_2 x_2 +\\cdots + w_n x_n = \\mathbf x^T\\mathbf w$), then applies a step function to that sum and outputs the result: $h_{\\mathbf w}(\\mathbf x) = step(\\mathbf z)$, where $\\mathbf z = \\mathbf x^T\\mathbf w$.\n",
    "\n",
    "<img src=\"./chapters/10/10.5.png\" width=600>\n",
    "<div style=\"text-align:left\"> Figure 10-5. Architecture of a Perceptron with two input neurons, one bias neuron, and three output neurons </div>\n",
    "\n",
    "*Equation 10-2. Computing the outputs of a fully connected layer*\n",
    "\n",
    "$$h_{\\mathbf W,\\mathbf b}(\\mathbf X)=\\phi(\\mathbf X\\mathbf W+\\mathbf b)$$\n",
    "In this equation:\n",
    "\n",
    "- As always, $\\mathbf X$ represents the matrix of input features. It has one row per instance and one column per feature.\n",
    "\n",
    "- The weight matrix $\\mathbf W$ contains all the connection weights except for the ones from the bias neuron. It has one row per input neuron and one column per artificial neuron in the layer.\n",
    "\n",
    "- The bias vector $\\mathbf b$ contains all the connection weights between the bias neuron and the artificial neurons. It has one bias term per artificial neuron.\n",
    "\n",
    "- The function $\\phi$ is called the activation function: when the artificial neurons are TLUs, it is a step function (but we will discuss other activation functions shortly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we set `max_iter` and `tol` explicitly to avoid warnings about the fact that their default value will change in future versions of Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = per_clf.predict([[2, 1]])\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure perceptron_iris_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "save_fig(\"perceptron_iris_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Multilayer Perceptron (MLP) and Backpropagation  \n",
    "\n",
    "For many years researchers struggled to find a way to train MLPs, without success. But in 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams published a groundbreaking [paper](https://apps.dtic.mil/sti/citations/ADA164453) that introduced the **backpropagation training algorithm**, which is still used today. In short, it is Gradient Descent (introduced in Chapter 4) using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the network’s error with regard to every single model parameter. In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. Once it has these gradients, it just performs a regular Gradient Descent step, and the whole process is repeated until the network converges to the solution.  \n",
    "\n",
    "Let’s run through this algorithm in a bit more detail:\n",
    "\n",
    "- It handles one mini-batch at a time (for example, containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an *epoch*.\n",
    "\n",
    "- Each mini-batch is passed to the network’s input layer, which sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "\n",
    "- Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error).\n",
    "\n",
    "- Then it computes how much each output connection contributed to the error. This is done analytically by applying the chain rule (perhaps the most fundamental rule in calculus), which makes this step fast and precise.\n",
    "\n",
    "- The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, working backward until the algorithm reaches the input layer. As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "\n",
    "- Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def derivative(f, z, eps=0.000001):\n",
    "    return (f(z + eps) - f(z - eps))/(2 * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure activation_functions_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Activation functions\", fontsize=14)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\n",
    "plt.plot(0, 0, \"ro\", markersize=5)\n",
    "plt.plot(0, 0, \"rx\", markersize=10)\n",
    "plt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
    "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "#plt.legend(loc=\"center right\", fontsize=14)\n",
    "plt.title(\"Derivatives\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"activation_functions_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10-8. Activation functions and their derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that some of the limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting ANN is called a *Multilayer Perceptron (MLP)*. An MLP can solve the XOR problem, as you can verify by computing the output of the MLP represented on the right side of Figure 10-6: with inputs (0, 0) or (1, 1), the network outputs 0, and with inputs (0, 1) or (1, 0) it outputs 1. All connections have a weight equal to 1, except the four connections where the weight is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./chapters/10/10.6.png\" width=600>\n",
    "<img src=\"./chapters/10/Picture2.png\" width=600>\n",
    "<img src=\"./chapters/10/10.7.png\" width=600>\n",
    "\n",
    "<div style=\"text-align:left\"> Figure 10-6. XOR classification problem and an MLP that solves it </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heaviside(z):\n",
    "    return (z >= 0).astype(z.dtype)\n",
    "\n",
    "def mlp_xor(x1, x2, activation=heaviside):\n",
    "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1s = np.linspace(-0.2, 1.2, 100)\n",
    "x2s = np.linspace(-0.2, 1.2, 100)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
    "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contourf(x1, x2, z1)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.contourf(x1, x2, z2)\n",
    "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
    "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
    "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, when building an MLP for regression, you do not want to use any activation function for the output neurons, so they are free to output any range of values. If you want to guarantee that the output will always be positive, then you can use the ReLU activation function in the output layer. Alternatively, you can use the softplus activation function, which is a smooth variant of ReLU: $\\text{softplus}(z) = \\log(1 + \\exp(z))$. It is close to $0$ when $z$ is negative, and close to $z$ when $z$ is positive. Finally, if you want to guarantee that the predictions will fall within a given range of values, then you can use the logistic function \n",
    "$$\\displaystyle f(x)=\\frac {L}{1+e^{-k(x-x_{0})}}$$\n",
    "where\n",
    "- $x_{0}$, the $x$ value of the sigmoid's midpoint;\n",
    "- $L$, the curve's maximum value;\n",
    "- $k$, the logistic growth rate or steepness of the curve.\n",
    "\n",
    "\n",
    "or the hyperbolic tangent,\n",
    "$$\\displaystyle \\tanh x=\\frac {\\sinh x}{\\cosh x}=\\frac {e^{x}-e^{-x}}{e^{x}+e^{-x}}=\\frac {e^{2x}-1}{e^{2x}+1}$$\n",
    "\n",
    "and then scale the labels to the appropriate range: $0$ to $1$ for the logistic function and $–1$ to $1$ for the hyperbolic tangent.\n",
    "\n",
    "The loss function to use during training is typically the mean squared error, but if you have a lot of outliers in the training set, you may prefer to use the mean absolute error instead. Alternatively, you can use the Huber loss, which is a combination of both.\n",
    "\n",
    ">The Huber loss is quadratic when the error is smaller than a threshold $\\delta$ (typically 1) but linear when the error is larger than $\\delta$. The linear part makes it less sensitive to outliers than the mean squared error, and the quadratic part allows it to converge faster and be more precise than the mean absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification MLPs  \n",
    "\n",
    "MLPs can also be used for classification tasks. For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class. The estimated probability of the negative class is equal to one minus that number.\n",
    "\n",
    "If each instance can belong only to a single class, out of three or more possible classes (e.g., classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer (see Figure 10-9). The softmax function (introduced in Chapter 4) will ensure that all the estimated probabilities are between 0 and 1 and that they add up to 1 (which is required if the classes are exclusive). This is called multiclass classification.\n",
    "\n",
    "*softmax function*:\n",
    "$$\\displaystyle \\sigma(\\mathbf{z})_{i}=\\frac {e^{z_i}}{\\sum_{j=1}^{K}e^{z_j}}\\quad \\text{ for } i=1, \\cdots, K \\text{ and }\\mathbf{z}=(z_1,\\cdots ,z_K)\\in \\mathbb{R}^{K}$$ \n",
    "\n",
    "In simple words, it applies the standard exponential function to each element $z_{i}$ of the input vector $\\displaystyle \\mathbf{z}$ and normalizes these values by dividing by the sum of all these exponentials; this normalization ensures that the sum of the components of the output vector $ \\sigma (\\mathbf {z})$ is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./chapters/10/10.9.png\" width=600>\n",
    "<div style=\"text-align:left\"> Figure 10-9. A modern MLP (including ReLU and softmax) for classification </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the loss function, since we are predicting probability distributions, the *cross-entropy loss* (also called the *log loss*, see Chapter 4) is generally a good choice.  \n",
    "\n",
    "\n",
    "\n",
    "*Table 10-2. Typical classification MLP architecture*\n",
    "\n",
    "\n",
    "| **Hyperparameter**     | **Binary classification** | **Multilabel binary classification**  | **Multiclass classification**  |\n",
    "| :---        |    :----   |   :--- | :----   |\n",
    "| Input and hidden layers      | Same as regression       | Same as regression   |   Same as regression      |\n",
    "| # output neurons   | 1        | 1 per label |   1 per class     |\n",
    "| Output layer activation   | Logistic        | Logistic |   Softmax     |\n",
    "| Loss function   | Cross entropy        | Cross entropy |   Cross entropy     |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras\n",
    "\n",
    "### Building an Image Classifier Using the Sequential API  \n",
    "\n",
    "First, we need to load a dataset. In this chapter we will tackle Fashion MNIST, which is a drop-in replacement of MNIST (introduced in Chapter 3). It has the exact same format as MNIST (70,000 grayscale images of 28 × 28 pixels each, with 10 classes), but the images represent fashion items rather than handwritten digits, so each class is more diverse, and the problem turns out to be significantly more challenging than MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the fashion MNIST dataset. Keras has a number of functions to load popular datasets in `keras.datasets`. The dataset is already split for you between a training set and a test set, but it can be useful to split the training set further to have a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    " color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corresponding class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first image in the training set is a coat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set contains 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10-11. Samples from Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATING THE MODEL USING THE SEQUENTIAL API**  \n",
    "\n",
    "Now let’s build the neural network! Here is a classification MLP with two hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through this code line by line:\n",
    "\n",
    "- The first line creates a `Sequential model`. This is the simplest kind of Keras model for neural networks that are just composed of a single stack of layers connected sequentially. This is called the *Sequential API*.\n",
    "\n",
    "- Next, we build the first layer and add it to the model. It is a `Flatten` layer whose role is to convert each input image into a 1D array: if it receives input data `X`, it computes `X.reshape(-1, 1)`. This layer does not have any parameters; it is just there to do some simple preprocessing. Since it is the first layer in the model, you should specify the `input_shape`, which doesn’t include the batch size, only the shape of the instances. Alternatively, you could add a `keras.layers.InputLayer` as the first layer, setting `input_shape=[28,28]`.\n",
    "\n",
    "- Next we add a `Dense` hidden layer with 300 neurons. It will use the ReLU activation function. Each `Dense` layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. It also manages a vector of bias terms (one per neuron). When it receives some input data, it computes Equation 10-2.\n",
    "\n",
    "- Then we add a second `Dense` hidden layer with 100 neurons, also using the ReLU activation function.\n",
    "\n",
    "- Finally, we add a `Dense` output layer with 10 neurons (one per class), using the softmax activation function (because the classes are exclusive). \n",
    "\n",
    ">Specifying `activation=\"relu\"` is equivalent to specifying `activation=keras.activations.relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7f05977625b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f0597747910>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f059801a190>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f059776a5e0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">USING CODE EXAMPLES FROM KERAS.IO  \n",
    ">Code examples documented on keras.io will work fine with tf.keras, but you need to change the imports. For example, consider this keras.io code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "output_layer = Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must change the imports like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "output_layer = Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply use full paths, if you prefer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "output_layer = keras.layers.Dense(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This approach is more verbose, but you can easily see which packages to use, and to avoid confusion between standard classes and custom classes. In production code, I prefer the previous approach. Many people also use from `tensorflow.keras import layers` followed by `layers.Dense(10)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model’s `summary()` method displays all the model’s layers, including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (`None` means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters (we will see examples of non-trainable parameters in Chapter 11):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Dense` layers often have a lot of parameters. For example, the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data. We will come back to this later.\n",
    "\n",
    "You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the parameters of a layer can be accessed using its `get_weights()` and `set_weights()` methods. For a Dense layer, this includes both the connection weights and the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Dense layer initialized the connection weights randomly (which is needed to break symmetry, as we discussed earlier), and the biases were initialized to zeros, which is fine. If you ever want to use a different initialization method, you can set `kernel_initializer` (kernel is another name for the matrix of connection weights) or `bias_initializer` when creating the layer. We will discuss initializers further in Chapter 11, but if you want the full list, see https://keras.io/initializers/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The shape of the weight matrix depends on the number of inputs. This is why it is recommended to specify the `input_shape` when creating the first layer in a `Sequential` model. However, if you do not specify the input shape, it’s OK: Keras will simply wait until it knows the input shape before it actually builds the model. This will happen either when you feed it actual data (e.g., during training), or when you call its `build()` method. Until the model is really built, the layers will not have any weights, and you will not be able to do certain things (such as print the model summary or save the model). So, if you know the input shape when creating the model, it is best to specify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPILING THE MODEL**  \n",
    "\n",
    "\n",
    "After a model is created, you must call its `compile()` method to specify the loss function and the optimizer to use. Optionally, you can specify a list of extra metrics to compute during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code requires some explanation. First, we use the `\"sparse_categorical_crossentropy\"` loss because we have sparse labels (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had one target probability per class for each instance (such as one-hot vectors, e.g. $[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]$ to represent class 3), then we would need to use the `\"categorical_crossentropy\"` loss instead. If we were doing binary classification (with one or more binary labels), then we would use the `\"sigmoid\"` (i.e., logistic) activation function in the output layer instead of the `\"softmax\"` activation function, and we would use the `\"binary_crossentropy\"` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to convert sparse labels (i.e., class indices) to one-hot vector labels, use the `keras.utils.to_categorical()` function. To go the other way round, use the `np.argmax()` function with `axis=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the optimizer, `\"sgd\"` means that we will train the model using simple Stochastic Gradient Descent. In other words, Keras will perform the backpropagation algorithm described earlier (i.e., reverse-mode autodiff plus Gradient Descent). We will discuss more efficient optimizers in Chapter 11 (they improve the Gradient Descent part, not the autodiff). \n",
    "\n",
    ">When using the `SGD` optimizer, it is important to tune the learning rate. So, you will generally want to use `optimizer=keras.optimizers.SGD(lr=???)` to set the learning rate, rather than `optimizer=\"sgd\"`, which defaults to `lr=0.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, since this is a classifier, it’s useful to measure its `\"accuracy\"` during training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND EVALUATING THE MODEL**  \n",
    "\n",
    "Now the model is ready to be trained. For this we simply need to call its `fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0188 - accuracy: 0.6805 - val_loss: 0.5218 - val_accuracy: 0.8210\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5028 - accuracy: 0.8260 - val_loss: 0.4354 - val_accuracy: 0.8524\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4484 - accuracy: 0.8426 - val_loss: 0.5320 - val_accuracy: 0.7986\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4206 - accuracy: 0.8525 - val_loss: 0.3916 - val_accuracy: 0.8654\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4059 - accuracy: 0.8585 - val_loss: 0.3748 - val_accuracy: 0.8694\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3751 - accuracy: 0.8675 - val_loss: 0.3706 - val_accuracy: 0.8728\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3650 - accuracy: 0.8707 - val_loss: 0.3630 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3476 - accuracy: 0.8758 - val_loss: 0.3842 - val_accuracy: 0.8636\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3479 - accuracy: 0.8763 - val_loss: 0.3589 - val_accuracy: 0.8702\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3291 - accuracy: 0.8840 - val_loss: 0.3433 - val_accuracy: 0.8774\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3213 - accuracy: 0.8840 - val_loss: 0.3430 - val_accuracy: 0.8782\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8870 - val_loss: 0.3312 - val_accuracy: 0.8818\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8903 - val_loss: 0.3272 - val_accuracy: 0.8878\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2986 - accuracy: 0.8920 - val_loss: 0.3406 - val_accuracy: 0.8782\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2929 - accuracy: 0.8946 - val_loss: 0.3215 - val_accuracy: 0.8862\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2858 - accuracy: 0.8985 - val_loss: 0.3095 - val_accuracy: 0.8904\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2775 - accuracy: 0.9005 - val_loss: 0.3570 - val_accuracy: 0.8722\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2772 - accuracy: 0.9007 - val_loss: 0.3134 - val_accuracy: 0.8906\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2734 - accuracy: 0.9024 - val_loss: 0.3123 - val_accuracy: 0.8894\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2691 - accuracy: 0.9044 - val_loss: 0.3278 - val_accuracy: 0.8814\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2664 - accuracy: 0.9054 - val_loss: 0.3069 - val_accuracy: 0.8904\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2607 - accuracy: 0.9055 - val_loss: 0.2974 - val_accuracy: 0.8964\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2544 - accuracy: 0.9065 - val_loss: 0.2991 - val_accuracy: 0.8930\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2447 - accuracy: 0.9121 - val_loss: 0.3097 - val_accuracy: 0.8886\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2486 - accuracy: 0.9118 - val_loss: 0.2985 - val_accuracy: 0.8942\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2423 - accuracy: 0.9137 - val_loss: 0.3080 - val_accuracy: 0.8876\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2367 - accuracy: 0.9163 - val_loss: 0.3003 - val_accuracy: 0.8954\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2308 - accuracy: 0.9175 - val_loss: 0.2995 - val_accuracy: 0.8942\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2273 - accuracy: 0.9171 - val_loss: 0.3032 - val_accuracy: 0.8898\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2248 - accuracy: 0.9208 - val_loss: 0.3035 - val_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass it the input features (`X_train`) and the target classes (`y_train`), as well as the number of `epochs` to train (or else it would default to just 1, which would definitely not be enough to converge to a good solution). We also pass a validation set (this is optional). Keras will measure the loss and the extra metrics on this set at the end of each epoch, which is very useful to see how well the model really performs. If the performance on the training set is much better than on the validation set, your model is probably overfitting the training set (or there is a bug, such as a data mismatch between the training set and the validation set).\n",
    "\n",
    "And that’s it! The neural network is trained. At each epoch during training, Keras displays the number of instances processed so far (along with a progress bar), the mean training time per sample, and the loss and accuracy (or any other extra metrics you asked for) on both the training set and the validation set. You can see that the training loss went down, which is a good sign, and the validation accuracy reached 89.26% after 30 epochs. That’s not too far from the training accuracy, so there does not seem to be much overfitting going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Instead of passing a validation set using the `validation_data` argument, you could set `validation_split` to the ratio of the training set that you want Keras to use for validation. For example, `validation_split=0.1` tells Keras to use the last 10% of the data (before shuffling) for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training set was very skewed, with some classes being overrepresented and others underrepresented, it would be useful to set the `class_weight` argument when calling the `fit()` method, which would give a larger weight to underrepresented classes and a lower weight to overrepresented classes. These weights would be used by Keras when computing the loss. If you need per-instance weights, set the `sample_weight` argument (if both `class_weight` and `sample_weight` are provided, Keras multiplies them). Per-instance weights could be useful if some instances were labeled by experts while others were labeled using a crowdsourcing platform: you might want to give more weight to the former. You can also provide sample weights (but not class weights) for the validation set by adding them as a third item in the `validation_data` tuple.\n",
    "\n",
    "The `fit()` method returns a History object containing the training parameters (`history.params`), the list of epochs it went through (`history.epoch`), and most importantly a dictionary (`history.history`) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a pandas DataFrame and call its `plot()` method, you get the learning curves shown in Figure 10-12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure keras_learning_curves_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAFgCAYAAABHS1h8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABi8klEQVR4nO3dd5hU1f3H8feZvr33wtLLAssigkRFFKMGCxp7i5qo0USNmmJPjBoTTWI0MRpNLLH91FiiQTSxLYhdmvRF2rIL23uddn5/3NnZwpbZZWB3Z7+v55nnztw2Zw4D8+Hcc85VWmuEEEIIIUKFaagLIIQQQggRTBJuhBBCCBFSJNwIIYQQIqRIuBFCCCFESJFwI4QQQoiQIuFGCCGEECFFwo0QQgghQkpA4UYpdY1S6iulVJtS6ul+9r1BKVWqlKpTSj2plLIHpaRCCCGEEAEItOVmL3AP8GRfOymlTgRuBhYBOcA44NcHUD4hhBBCiAEJKNxorV/TWv8bqOpn10uAJ7TWG7XWNcDdwKUHVEIhhBBCiAGwBPl8ucAbnV6vA1KUUgla6y7BSCl1JXAlQFhY2GFZWVlBLkoHr9eLySTdi4JB6jI4pB6DR+oyeKQug0PqMXj6qsvCwsJKrXVST9uCHW4igbpOr9ufR9Gt1Udr/TjwOMCcOXP0V199FeSidCgoKGDhwoUH7fyjidRlcEg9Bo/UZfBIXQaH1GPw9FWXSqndvR0X7GjZCER3et3+vCHI7yOEEEII0aNgh5uNQF6n13lAWfdLUkIIIYQQB0ugQ8EtSikHYAbMSimHUqqnS1rPAD9QSk1TSsUBtwNPB620QgghhBD9CLTl5nagBWOY90W+57crpbKVUo1KqWwArfU7wP3Ah8Bu3+NXQS+1EEIIIUQvAupQrLW+E7izl82R3fZ9AHjggEolhBBCCDFIMlZNCCGEECFFwo0QQgghQoqEGyGEEEKEFAk3QgghhAgpEm6EEEIIEVIk3AghhBAipEi4EUIIIURIkXAjhBBCiJAi4UYIIYQQIUXCjRBCCCFCioQbIYQQQoQUCTdCCCGECCkSboQQQggRUiTcCCGEECKkSLgRQgghREiRcCOEEEKIkCLhRgghhBAhxTLUBRBCCCHECKU1eN3gbjMenvalE9ytkDQVLLZDXiwJN0IIIcRwpjV4PeB1GaHB4/I9fM97W98laPiWnZ/3tc4fVJwdS3drt22+B7r3sl+/HmKzD1lVtZNwI4QQQgB43OBs8AUGty9QdF66e3nddV1S+TpYUwLuFnC1dlq2gqslgKUvPHjcHeGjrwAxWCYLmO1gtoLFbjy32Dqtcxiv7VHG9u77dF9ncYDZ5lvnW4YnBL/cAZBwI4QQYuTxeo3Q4GzqeLiawdkIbY2+dY3Q1mAsnU2+9Q09b29rNAJFEOQCbOq2UpnAEgZWh7G02MEaZgQCaxhEJHVsszp8AcNmhAyzteO5yRrA+k7LzkHDbOv63GQOyucdjiTcCCGE2J/WRguGq9nXotBstD64WnwtES2dWht82zxtxnHoHpb0sr7b0tUKrvbA4gsrruZuz31BJlDKBLYosEeCLdK3jIDwMR3PbZFGC4UtwvfDb+n2MAfw2lj3xao1zP3Wgq5hxmwFpYL+xyR6JuFGCCFGgt46brY/91/+aPGFjZZuj+aOZfvlj87rXK0c0VADX3g7Aov2HqIPp3w//MpoxbBFgDXcFzp8wSMypeN1523WcGO7zbfOGtERYtqDjMVxSINFc0QVxOUcsvcT+5NwI4QQA+H1QlsdtNRASy201vouaTg7dc5sf95mtH7s13HT19mz8749BRZ3t9cHEjbMNiM4WMN9l0PCfK/DIDIVrA5qzfWkZo3ttM1h7G/xLft8HWa8R3tICWQpLRniIJFwI4QYWbxeaKuH1jporSO6bivsiej0Q6m6LDped9re+bn2na89qLSHlpYa3+tuz1vrGHDnzvb+EBZfn4f2Dpud11kcYI3t6MTZuXOmv9NmP9tsnYNHpyBjDQuof8WWggJSFy4c2GcTYhiScCOEOHS0Ni6DdO7I2doRVAJ6tNXTOVzMBlgT5HKaLOCIhbA4CIuFyGRInGQ8D4vrui0sztdPw75/eLHYjWBjCo35UrXTiau8HPe+fbhKS3Ht3YerdB/ufaW4SkvxNjVhjorCFBONOSoac0w0pqhozNHRmKKjMEfHYI6O8r2O9i9NtkM/D8p+n01rvPX1uCsqMEVFYUlKQh2iPzetNZ6qKpy7duHcvRvnrt1opxNls6KsHQ8slk6vbcbSYtlvP2WxoBwOzLFxWOLjjGNHGQk3QogO7Z1I3a2dHm2+PhidX/uGq7aPOHE2dR114mzs+tw/OqUhsEsr9hhwdHrEZnd93enx9aZCZs6c0VF+40kfr7tvAxzRXUOLLSLgSyba68Xb3Nzxo2IemSNQtMeDqaaG5jVrcJeW4tpX2iW4uEr34ams6lpvgDkmBktaGtbUVEyRkXgbGvDU19NWsR1vXT2ehgZ0a2uf760cDn8AssTGYY6Px5wQjyUuHnN8PJaEeMxx8Zjj47AkJGCOjR1QPWu3G3dFBe6yMlxl5bjLynCX+56XluIqL8NdVt61nFYr1vQ0bBkZWHt4DCb8eBobce5sDzC7ujy8jY1d3ttks6FdLrTTOaD36IkpOhpLvFGX5vg4LPEJvmU85vgELPG+Oo+PxxLXcxjSbjfepia8TU14GhvxNjb5Xjcay8ZGPE1NxvrGjnVpv/stlri4A/4MAyXhRohQ4Grt1rrRvcWjo3VEt9bhqa7BU1ePNbwNE86O0OJqYdDzaVgcvk6cEb5RJ5EQHm8Ek+4dPDuPTHHE+oOKtkTgafHgqavHXVNjlLO2Bnd1NZ6aWjw1NXiqv8Fd69tWU4MpIoKyMzxEL16MY9o01CHox6G1pvXrr6l76y3q334bT0Vlx0aTaf//Rbc/t1nBakVZuv1P22bDmpGOLScH+9ix2MaOxZKSclA+i/Z6cRUX07Ztm+/xjbHcuZMkl4vdnfZV4eFYfcHFPnkS1tQ0rGmpWFJT/etN4eH9vqe3rQ1vvRF0PHV1RgCqq8fTUG+sr2/AU19nhKGaGtq2b8fzxRd46ur2C1NGwRTmmBjMCQlY4rqGIWWz4i4v7wgxZWW4q6qMy5mdT2G1YklJwZKSQlhuLpZjjzNeJyXhbWzAVVKCq6QEZ0kJrR8W4Kms3P/49DRsGZn7B5+SEhreew/nrl20+QPM7q7nUApruvFnHrNkCbacHN9jDNb0dH9401qDx2MEHZcL7XZ3PHe6/M9xdzzXLhfelhY8Nb6/O9U1uKur8FTX4NpdRMuatXhqavark3am6Gh/IPH4Qkp/AdX/sex2TJGRmCIjMEVEBHxcsEm4EeJQ8I90MUKEvbUCKrZ2mpuj2TdipbnbuibfZRzfc2enfZyNHeHF4+x4G5fC1WzG1WzG7V9acLXacTWbcDeB9vjKZQJbYiSOjAzsmfE4shOxj0nFkhCHap+Dw+LwDWd1+Pp4+OboaO9E2h5WzH03ffub3nfuNP7B37kLZ9FuPFXVxj/CNTV46+p6Pd4UFYU5Lg5zXCzW5BQck6dgjo1l31dfUv3PZ6h+4klsOTlEL15M9MmLsY8fH6w/Pb+2b76hbulS6t9ahmvPHpTVSuTCYwiblY/2dvwA4er8Q+Pu8qPT5eF04m1uRre00PTJJ+iWFv97qfBwbDljsOeMNX70fKHHlpODOTKi37JqrXGXlnYNMNu20bZjR5f3saanY5s4gYijj2JXSwvTFizoCC7R0UEJWCa7HVNSEpakpAEdp91uPHV1uKuqfGG2GndVNZ7qatw11cZ3p7raCENffomntha0xhQTgzU5GUtKihHKUlKwpKRiSUn2PU/BHBc3oM/mbWnBtW+fP/R0DT8fdgkuCUCx77k5MRFbzhgiFx6D3R9gcrBmZWGy2/t9X6WUcTnKYoGwsAHVX1+014unrg5Pta8+q2vwVFd1CUNKmTBFRBhhJSICU2QEZv9z3zIiErMvyJgiIobNJTAJN0J0527r1Lm0l6WzqeNyTZ+Xbzpdxul0OWY+wGcBlMUSBrZwtDkMjzcMr9eBx23H4w7D3RqFqzENV6MXd50TV20L7upGvK3dmrHNZizJSVjT0wlLTcWSloo1NQ1zTDRtO3bQtrWQ5q1bqF+zoeOQuDjskyfjmDzZWE4Zj23MhID6RnhbW41m9507jf+x7txJ205j6W1o8O+n7HZs2VmYExNxTJtqXHbwhRdLfPvzeON1bCyql/feXFDA0bNmUf+//1G/7G0qH32UykcewT5lihF0Fi/GlpkRQGX3zFlcQv2yZdS/9RZtW7eCyUTEEUeQeNVVRH37eMzR0YM+d2daa9xlZb762mmEv507afn6a+rffrtLC4YlOdkfdGxjjdYeZbN1hJhvjGXnSx2WpCTsEycQd87Z2CdOxD5hArYJEzBHRvr32VxQQNQw6lCsLBYsCQlYEgKb5Vb7WjhMDkfQy2IKC8M+bhz2ceN63O5tacG1dy+ukhLWf/EFs076DracMV3qdzhRJhOWuDijheYg/EdgqEm4EaHL7YSWamiqhOaqTo/qboGlpmt4cbf0dVZjMjBbRKcZRu1oszFiRdsTIMyGNjnQygYmG1pZQdnQJivaZANlZcfOPWSnjcHT6sXT4sbb7MbT3IanqQ1PY7PxqG80muzr6nw/Uk2+R1fmxETjskHuVCJS04z/dXe6dGBJSgqof4Knro62wkJat2ylrXArrVu2UvPSSx3NymYz9nFjsU+egmOKEXowmYwfYV+Ice7ciWvfvq4/xGlp2MfmEHPqKdhyxvpbIKzpaUHrsGmOjSXunHOIO+ccXOXlNLzzX+qXLaPigQeoeOABwvLyiD55MVEnnYQ1Obnf87mrqqh/5x3ql75Fyxqjt3LYrFmk3HYb0d85CUtiYlDK3ZlSCmtqKtbUVCLmz++yzdvW5guMHfXs3LWL+nfe2a+1yxwTg33iRGJOO7VLiBmKfg+HmjKbh6zPkyksDPv48djHj6fN6yVseu6QlEMYJNyIkcHj7ggizdXQ3C2wNFV1CzBVvlE1vbBFGSNdHLHGMmF819eOWDweB85aF67KFpwV9TjLqnDtLcNZXGJcg/Z4wN2K9jSBx9P7e/WiqPsKq9XoRxAdjdnXrG6eNBFTdEzH+tgY3yiTGCxJiVhSUoI20sQcE0P44YcTfvjh/nXa48G5u4i2rVto3bqVti1baV61ivqlS7scawoPxzZ2LGGzZxMztqPfiG3MmID6ZASTNTmZ+O9dTPz3LjZaXd5eRv2ytym797eU/fZ3hM+dS/TixUSd8O0uP/iexkYa3n2P+qVLafrsM/B4sE+aRNINNxB98mJsmZmH9HN0ZrLbcUyahGPSpC7rtdZ4ampw7tyJdjqxT5iAOTHxkPQ7EmI4k3AjutAu136d/rwN9Xh8nf7Ct39D1TffgNk3KsRiRpktKLPJWGfx/c/J9xxz5+1mTFaFLSUGs9nlazGp6TSHSKfX7XOLtC+dDb0X2uKA8ESj82pEIsSPNW7W1r4uPMF4RCQay7A4MFvRXi/u8nKcRUW49uzBuWMPrj1FOIsKce7Zs///iJMSsWVlEzF3LubYGDCZu35Gi9lfLx3PTftvt5jZuGULM7/1LSO0+IKLCgsbdj9Kqr21ZtxYor/zHf96T10drVu3ggbb2ByjdWiYlR3AlplB4hVXkHjFFbRt3079srepf+stSn/1K0rvvpuII79F5JFH0fzVVzQWFKCdTqyZmSRcfjnRJy/eL0wMN0opLPHxWOLjh7ooQgwrEm5CkNbaCCY1NXhqa41RJ7W1eGpr8dYbwzS9DfW+0QoNeOvrfKMV6rt0NOxJFFAehDJaHB5s0W7s0W5s0S5jGauwxMegwmONABKdDim5neYU8c0r0jmwhCcaE5f1Vg91dThLSnBtK8FV8rnRCbC4GOeePbj27Ok6zNJsxpqRgS0ri+gZ07FlZWPLzsKalY0tKzOoLRBtDgcRc+cG7XyHmjkmZsSV3z5+PEnXXkPiNT+mbfNm6pcto27ZMpqWr8CcmEjsuecSc/JiHHl5wzKoCSECJ+FmhHBXVeHcvdsIKZ3Cij+41NR2bKur6/MyiSmq6yRatpwc43lkBGa7CZPVi9niwmRqwawaMXvrMHmrMTsrcNWXYnU3GZdkvKC1MrpXeFXH/e/MYWhbNFij0bYotDUKrJFoSyRer422KifOsnra9lZTt6cM7zcdgcoUGYlt/DjsY8cZy9Tx2MeNw5qZaYwW6MQfXrbt9I1c2LvfSAZvU9c+KqaICKyZmdjHjSXymGN84SULW3Y21rS0/d5DhB6lFI5p03BMm0bSjTfiKi7GmpExYuenEULsT/4lHwFaNm5k94UX7TdfgLJajRElsbGYY2ON6+2+5+Y4Y2mJizMue9g1ZlMjJk89qrkMGkqhfq+xbPgGGvYZ/Vjaur25yQpRqcYjfiJVYTmkj881WlHC4zu1qMR1TIJm7XukQlSn51pr3OUVOHdsp237Dpw7dtC2YwdNH39M3b//3eWz2nLGYBs7Du1y9RterJmZhM+bhzUj3WiN8c0/EayhrSI0KJMJW3b2UBdDCBFkEm6GOXdNDSXXXoc5Npa0u36NOT7BF1piUeHhxg+1qxXqS6CuGOr2+JZfGsuiPcY2d/eJlJQxpXxUGsRkQuYc43lUascyOh3C4rtMHV9YUEB6EIeKKqWwpiRjTUneb4SIp6HBCDvbdxjhZ8dO2goLUXa7hBchhBC9knAzjGmPh70//SnuigrG/OUuwpLqoW4jlHQKMbV7oKmHXjCRqUZoSZ0BUxZDTBZEZ0B0mhFeIpLBPLz/+M1RUYTl5RGWlzfURRFCCDGCDO9ft2HC63Qeuhu7OZugdAOUfk3Fk6/S9Mlu0uY1EFZwScc+ljAjuMRkwqQTjent21/HZBktLpb+Z74UQgghQpGEmz54W1qofOwxqp94kthzziHl9tuCe8mjuRpKv4Z9X8O+dcbzym2Apn6Pg6qP44mdFUPsRWdD6kxjLpaYLGOUkFx6EUIIIXok4aYHWmsa/vcuZff9DvfefThyc6l5/nkwm0i55ZaBBxytjQ67+9YZQabUF2bq9nTsE50JaTNh+pm0uVLYd9NfcMycQMozz8GhajUSQgghQoCEm27aduyg7J7f0PTJJ9gnTSLj2fsImzOHst/+lppnnkVZrCT//Gf9B5yGMti5AnYUwM7lnYKMgoQJkDUX5l5htMikzoQI494pnsZGis8+B+UII/PPfz50l8OEEEKIECHhxsfT2ETlo49Q/c9nMIWFkXLbbcSdf55/3pOUW24Bt5vqJ59EWSwk3XB914DTWge7PjaCzI7lULHZWO+IhbFHw7euhbRZxqR09p5vpKa9XvbefDPOoiKyn3oSa2rqwf3QQgghRAga9eFGa039W8sov/9+3OXlxHz3uyTfeMN+N8ZTSpFy++1ol5uqxx9HmRVJp802gszO5VCyGrTH6Ow7Zj7knQfjjjFaZUyBTQ5W9fd/0Pje+6TccvOIm/1VCCGEGC5GdbhpLSyk7J7f0PzFFzimTSPzzw8RNmtWzzt7Pah9a0k9Pga9NZrKRx9DrawncXoLZBwGR98IY48xLjcNYqRS48qPqXjwQaJPPpm4733vwD6YEEIIMYqNynDjaWig8uGHqX7uecyRkaTeeSexZ5/V8/TrrhZYegNsXQatdSggbcFUsGVS8VUx6rhbSbj8xwdUHmdxMXt/+lPsEyeSdvddMgmdEEIIcQBGVbjRXi91b75J+R/+iKeqithzziHp+p9giYvr5QANb/0U1v0fzLoIxh8LYxegIpNJu9qD/vkvKH/oYQiLIOHSSwdVJm9LC8XXXofWmsyH/xLUmzMKIYQQo9GoCTetmzdTetfdtKxZgyNvJlmPPkrYjOl9H7TqaVj7PCz4BRx3W5dNymwm/f770B4P5b+7D2W2EH/xRQMqk9aa0jvvpG3LFrL+9qjc40YIIYQIgpAPN566OqL+70V2fvSRcX+m3/yGmDNOR3W6X1KPSlbB27+A8Ytg4c097qIsFjL+8HuKPW7KfvMblNVC3HnnBVy2mhdeoO6NN0m89hoijzlmIB9LCCGEEL3o5xd+5Cv99V2ErVhB3AUXMP7tZcSe+d3+g01TFbx8iXF/pjP/0edoJ2W1kvnAA0QuXEjpnb+m9pVXAipX8+rVlP32d0QuXEji1VcP5CMJIYQQog8h33KTdP1P2Dk7n2kXBXjJyOuB1y6HxjL4/n8hPL7fQ5TNRsafH6L4x9ew745fgtlC7Bmn97q/q7yc4p/8BGtGOun339d/2BJCCCFEwEL+V9WWnY07MzPwAwp+C9s/gMV/gIzZAR9mstnI/MufiZh/BPtuvZW6/yztcT/tdFJy/Q14G5vI/MtfMEdHB142IYQQQvQr5MPNgGx9B1b8HvIvgsMu6X//bkwOB5l//Svhc+ey96abqH/77f32KbvvflpWryb9N/fgmDQpGKUWQgghRCcBhRulVLxS6nWlVJNSardS6oJe9rMrpf6mlCpTSlUrpf6jlMoIbpEPkuod8PqVxozCi/8w6NOYwsLIevQRwmbnU/Kzn1P/v//5t9X++9/UPP888ZddRvTixcEotRBCCCG6CbTl5q+AE0gBLgQeVUrl9rDfT4D5wEwgHagF/nLgxTzInM3w0vcABec+C9awAzqdKTycrL89RtjMmZTc+FMaPviQ1k2bKP3VnYTPnUvyT28MTrmFEEIIsZ9+w41SKgI4E7hDa92otV4JvAlc3MPuY4H/aq3LtNatwItATyFo+GifqK9sgzEyKi4nKKc1R0aQ9ffHcUybRslPfsKeH16FOS6OjD894L8ZpxBCCCGCT2mt+95BqXzgE611WKd1PwOO0Vqf2m3fOcBDwNkYrTb/AMq11tf3cN4rgSsBUlJSDnvxxRcP6IP0pbGxkcjInu/Enbb3HSYXPsquMeexa+z5QX9v1dxM3IMPYdm7l+qf/RR3Tk7Q3+NQ6qsuReCkHoNH6jJ4pC6DQ+oxePqqy2OPPXaV1npOT9sCaUKIBOq6rasDonrYtxAoAkoAD7AeuKank2qtHwceB5gzZ45euHBhAEUZnIKCAno8f/Eq+OgJmHA8ORc8Ss5BGpLtPe443JVV2DJHRvejvvRal2JApB6DR+oyeKQug0PqMXgGW5eB/Jo3At3HK0cDDT3s+yjgABKACOA1YP8hQ8NBUxW8/D2ISoXv/h0O4lwzJocjJIKNEEIIMRIE8oteCFiUUhM7rcsDNvawbx7wtNa6WmvdhtGZeK5SKvHAixpEXg+8+n1oqoBzng1ooj4hhBBCjAz9hhutdRNGC8xdSqkIpdSRwBLg2R52/xL4nlIqRillBX4E7NVaVwaz0Afsw3thRwGc/AdInzXUpRFCCCFEEAV6LeZHQBhQDvwfcLXWeqNS6milVGOn/X4GtALbgApgMXBGEMt74LYsg4/+APkXw+zvDXVphBBCCBFkAY1J1lpXA6f3sP4jjA7H7a+rMObBGZ6qtsPrV0HarAOaqE8IIYQQw9fouf2Cs9noQGwywTnPgNUx1CUSQgghxEEwOmaT0xqW3gBlG+HCVyBuzFCXSAghhBAHyagIN+l734FtL8LCW2Hi8UNdHCGEEEIcRKF/War4KyZ88w+YeAIs+PlQl0YIIYQQB1noh5vVz9Bmj4czHjuoE/UJIYQQYngI/ctSpzzIGvsxfEsm6hNCCCFGhdBvyjCZcNoThroUQgghhDhEQj/cCCGEEGJUkXAjhBBCiJAi4UYIIYQQIUXCjRBCCCFCioQbIYQQQoQUCTdCCCGECCkSboQQQggRUiTcCCGEECKkSLgRQgghREgJ+XDz5/e38dvPW4a6GEIIIYQ4REI+3Chga42XuhbXUBdFCCGEEIdAyIeb/Ow4ANbtqR3aggghhBDikAj5cJOXFYMC1hTVDnVRhBBCCHEIhHy4iXJYyYhUrNlTM9RFEUIIIcQhEPLhBmBcrJk1RbV4vXqoiyKEEEKIg2xUhJvxsSbqWlzsrGoa6qIIIYQQ4iAbFeFmQqwZkH43QgghxGgwKsJNWoQiym5hdZH0uxFCCCFC3agINyalmJUdKy03QgghxCgwKsINGPPdbC2tp6nNPdRFEUIIIcRBNIrCTSxeDeuKa4e6KEIIIYQ4iEZPuMmKBaRTsRBCCBHqRk24iQ23MS4pQsKNEEIIEeJGTbgByM+KY01RDVrLZH5CCCFEqBpd4SY7lqomJ3uqW4a6KEIIIYQ4SEZVuJntu0O43GdKCCGECF2jKtxMSokk3GZm9W4JN0IIIUSoGlXhxmI2MTMzhjV7aoe6KEIIIYQ4SEZVuAHj0tSmvfW0ujxDXRQhhBBCHASjLtzkZ8fh9mrWl9QNdVGEEEIIcRCMwnATC8AauYmmEEIIEZJGXbhJjLSTHR8uk/kJIYQQIWrUhRswWm9Wy2R+QgghREgaleFmdnYcZfVt7KtrHeqiCCGEECLIRmW46eh3Uzuk5RBCCCFE8I3KcDMlNRq7xcRq6VQshBBChJxRGW5sFt9kfhJuhBBCiJAzKsMNGPPdbNhbT5tbJvMTQgghQsnoDTdZsTjdXjbtrR/qogghhBAiiEZtuJk9xneHcOlULIQQQoSUURtuUqIdpMc45CaaQgghRIgZteEGjH43q3dLp2IhhBAilIzycBNLSW0L5fUymZ8QQggRKkZ5uPH1u5FLU0IIIUTIGNXhJjc9GqtZyWR+QgghRAgZ1eHGYTWTmx4jI6aEEEKIEBJQuFFKxSulXldKNSmldiulLuhj39lKqRVKqUalVJlS6ifBK27w5WfH8nVxLS6Pd6iLIoQQQoggCLTl5q+AE0gBLgQeVUrldt9JKZUIvAM8BiQAE4D/BaeoB0d+dhytLi9bSxuGuihCCCGECIJ+w41SKgI4E7hDa92otV4JvAlc3MPuNwL/1Vo/r7Vu01o3aK03B7fIwTXbf4dw6XcjhBBChAKlte57B6XygU+01mGd1v0MOEZrfWq3fT8A1gOHY7TafA78WGtd1MN5rwSuBEhJSTnsxRdfPMCP0rvGxkYiIyN73Ka15vqCFqYlmPjhTMdBK0Oo6KsuReCkHoNH6jJ4pC6DQ+oxePqqy2OPPXaV1npOT9ssAZw7Eqjrtq4OiOph30xgNvBtjJBzP/B/wJHdd9RaPw48DjBnzhy9cOHCAIoyOAUFBfR1/nl7vqKwrKHPfYShv7oUgZF6DB6py+CRugwOqcfgGWxdBtLnphGI7rYuGuipk0oL8LrW+kutdSvwa+BbSqmYAZfsEJo9Jo5dVc1UNzmHuihCCCGEOECBhJtCwKKUmthpXR6wsYd9vwY6X+dqf64GV7xDIz8rFpB+N0IIIUQo6DfcaK2bgNeAu5RSEUqpI4ElwLM97P4UcIZSapZSygrcAazUWtcGscxBNzMzFrNJyXw3QgghRAgIdCj4j4AwoByjD83VWuuNSqmjlVKN7TtprT8AbgXe8u07Aeh1TpzhIsxmZmpaFGv2SMuNEEIIMdIF0qEYrXU1cHoP6z/C6HDced2jwKPBKNyhlJ8Vx2uri/F4NWbTsL6KJoQQQog+jOrbL3Q2e0wsTU4P28plMj8hhBBiJJNw45Of5btDuPS7EUIIIUY0CTc+YxLCiY+wsXq39LsRQgghRjIJNz5KKfKzYlmzp3aoiyKEEEKIAyDhppP87Fi+KW+krsU11EURQgghxCBJuOkkP9vod7NWWm+EEEKIEUvCTSd5WbEoJTMVCyGEECOZhJtOIu0WJqdEyYgpIYQQYgSTcNNNfnYsa4pq8Hp1/zsLIYQQYtiRcNNNfnYc9a1udlQ2DXVRhBBCCDEIEm66mZ0dC0i/GyGEEGKkknDTzbjESKIdFlZLvxshhBBiRJJw043JpJiVHSctN0IIIcQIJeGmB/lZsRSWNdDY5g7K+daUr+HvX/89KOcSQgghRN8k3PQgPzsWr4avgzCZn8vj4vaVt/PnNX/mm5pvDrxwQgghhOiThJse+O8QHoRw86/Cf1HUUATAm9vfPODzCSGEEKJvIR9uNlRuoKC+YEDHxIRbGZ8UccD9bhqdjfxt3d+YmzqXhVkL+c+O/+D2BudSlxBCCCF6FvLh5t/f/JvXal5jS/WWAR2Xnx3H6qJatB78ZH5PbniSmrYabjzsRk6fcDqVLZV8sveTQZ9PCCGEEP0L+XBzbf61RJgiuPuzu/Fqb8DHzc6Oo7rJSVF186Det7y5nGc3Pct3xn6H3MRcFmQsIM4ex7+/+fegzieEEEKIwIR8uImxx3B63Ol8XfE1r217LeDj8v2T+dUO6n0fWfsIbu3muvzrALCarZw87mQK9hRQ2zq4cwohhBCifyEfbgDmRszlsJTD+NOqP1HdWh3QMZNSooiwmVk9iH4339R8w+vfvM55k88jMyrTv/70Cafj8rp4e9fbAz6nEEIIIQIzKsKNUorb591Os6uZB1c9GNAxZpMiLyt2UC03D65+kAhLBD+c+cMu6yfHT2ZK/BTe+OaNAZ9TCCGEEIEZFeEGYELcBC7OvZjXv3mdNeVrAjomPzuWzfvqaXF6An6fL0u/ZHnxcn4w4wfEOmL3275k/BI2Vm1kW822gM8phBBCiMCNmnADcNXMq0iNSOXuz+7G5XX1u//s7DjcXs36krqAzq+15oGvHiAlPIULp17Y4z6Lxy3GoizSeiOEEEIcJKMq3IRbw7l57s1sq9nGC5tf6Hf/WVmxQOB3CP/v7v+yoWoD1+Rfg8Pi6HGfeEc8CzIXsHTH0oAClhBCCCEGZlSFG4Djso5jQeYCHln7CKVNpX3umxBpZ0xCeED9blweFw+teoiJcRM5ddypfe57+oTTqWqt4pMSmfNGCCGECLZRF26UUtw892Y82sP9X97f7/6zs+NYXVTT72R+Lxe+THFjMTcediNmk7nPfY/KPIp4RzxvbJdLU0IIIUSwjbpwA5AVlcWVM6/k3d3vsrJkZZ/75mfHUt7Qxt661l73aXA28Ni6x5iXNo8j04/s9/2tJmPOmw/3fChz3gghhBBBNirDDcCluZeSE53DvZ/fS5unrdf92m+i+cGW8l73eWrDU9S01XDDYTeglAro/ZeMX4Lb62bZzmUDK7gQQggh+jRqw43NbOO2I25jT8Menlj/RK/7TU2LIi8rll+9sYFnPt213/bSplKe2fQMi8cuJjchN+D3nxw/manxU+V2DEIIIUSQjdpwA3BE2hF8Z+x3eGL9E+yu393jPhaziRcun8dxU5L55Rsbues/m/B4O/rfPLL2Ebzay7X51w74/ZdMWMLm6s1srd466M8ghBBCiK5GdbgB+Pmcn2M1W/nt57/ttdNwhN3CYxfP4ftHjuXJj3fyw2dX0ex0s61mG29sf4Pzp5zf5TYLgVo8djEWk4U3t795oB9DCCGEED6jPtwkhSdxbf61fLz3Y97d/W6v+5lNil+eOo27luTywZYyznnsU+77/AEiLBFcMeOKQb13nCOOhZkLZc4bIYQQIohGfbgBOHfyuUyNn8p9X95Hk6upz32/Nz+HJy45nJ0N6/i8bCWn5Vzc420WArVkwhKqW6v5uOTjQZ9DCCGEEB0k3AAWk4Xbj7idiuYKHln7SL/7HzM5kQlTl6PcsTz730w+3Nr7SKr+HJlxJPGOeOlYLIQQQgSJhBufmUkzOXPSmTy/+fl+O/j+d9d/2VG/hZ/PvZ6chFh+8PSXPPtZzx2S+2M1WTll3Cks37Oc6tbqQZ1DCCGEEB0k3HRy/ezribZFc89n9+DV3h73cXqcPLT6ISbFTeKC3NN5+YfzOW5KMnf8ewP3LO06kipQSyYswa3dvL3z7QP9CEIIIcSoJ+Gmkxh7DDfOuZG1FWt7vWv3y1tfpqSxxH+bhfaRVJcdmcM/Vu7kqueMkVQDMSluEtMSpsmdwoUQQoggkHDTzWnjT2N28mweWPXAfrdGqHfW89jXj3FE2hF8K/1b/vVmk+JXp+Zy56nTeH9zGec+9hnl9b3frqEnS8bLnDdCCCFEMEi46cakTNx+xO00OBt4cPWDXbY9uf5JattqufGwG3u8zcKlR47lH5fMYXtFI6f/9WM276sP+H3b57yRm2kKIYQQB0bCTQ8mxk3k4mkX8+q2V1lbvhYwbrPw3ObnOHncyUxNmNrrscdNSeFfV83HozVn/+1TCgIcSRXriOXYrGN5a8dbMueNEEIIcQAk3PTi6ryrSQ5P5p7P7sHtdfPXtX8N+DYLuekxvPHjo8iOD+cH//wq4JFUS8Ybc958VPzRgRZfCCGEGLUk3PQi3BrOzXNvZmvNVn7z+W9445s3uGDKBWREZgR0fGqMg39dNZ9jJiVxx7838Ks3NlDX0neLzJEZR5LgSJCOxUIIIcQBkHDTh+Ozj+eojKN4pfAVIm2RXDFzYLdZiLBb+Pv3jHtS/fPT3Rx93wf85f1tNLb1PJrKYrJw6vhTWVG8Qua8EUIIIQZJwk0flFLcOvdW4uxxXJd/HTH2mAGfo/2eVG9ddxRzxybwx3cLOfq+D/jb8u09Dhk/bfxpuLWbZTuWBeMjCCGEEKOOhJt+ZEVn8f4573PelPMO6Dy56TH845I5vPHjI5mZGcvv3t7CgvsLeGLlTlpdHv9+E+MmkpuQK6OmhBBCiEGScBMAq8katHPlZcXyz+/P5ZWr5jMpJZK7l27imN9/yLOf7qLNbYScJROWsKV6C1uqtwTtfYUQQojRQsLNEJmTE88LVxzB/11xBNnx4dzxxkaO+8NyXvyiiG9nn4TVZJWOxUIIIcQgSLgZYvPHJ/DyD+fzzPfnkhhl5+bX1vPdh9cyMfIIY84bj8x5I4QQQgyEhJthQCnFgklJ/PtH3+KJS+YQ5bDw1Ybx1LTV8MeVb+AdxM04hRBCiNFKws0wopRi0dQUll57FH8+/VxM3mieXv8vTnpoBW+v3ychRwghhAiAZagLIPanlOLkGZlsaf0uz2x6FmdVPVc/v5r0GAen5qVz2qx0pqVF93h/KyGEEGK0C6jlRikVr5R6XSnVpJTarZS6oJ/9bUqpLUqp4uAUc3RaMmEJXjxcekI1fzk/nylp0Tyxcicn/3klxz+wnIfe28bOyqahLqYQQggxrATacvNXwAmkALOAt5RS67TWG3vZ/+dAORB5wCUcxSbETWB6wnTe3PEGr576PU7NS6emycmyDft4c+1eHny/kD+9V8iMjBiWzErnlJnppMY4hrrYQgghxJDqt+VGKRUBnAncobVu1FqvBN4ELu5l/7HARcBvg1nQ0er0CaezrWabf86buAgbF84bw0s/nM8nNx/HbYuNO5Tf89Zm5v/ufc597FOe/3w3NU3OoSy2EEIIMWSU1n13UlVK5QOfaK3DOq37GXCM1vrUHvZfCjwB1ADPaa0zeznvlcCVACkpKYe9+OKLg/4Q/WlsbCQycmQ2IjV7mrmt+DaOjDqSs+LP6nW/0iYvn+9z8+k+N6VNGrOC6Ylm5qVZmJ1sxmEJTv+ckVyXw4nUY/BIXQaP1GVwSD0GT191eeyxx67SWs/paVsgl6Uigbpu6+qAqO47KqXOACxa69eVUgv7OqnW+nHgcYA5c+bohQv73P2AFBQUcDDPf7B9sPwDPt/3OX86+k9Yzb3PlnweoLVm4956/rNuL/9Zt5fHv27FYTWxaGoKS/LSWTg5GZtl8IPkRnpdDhdSj8EjdRk8UpfBIfUYPIOty0DCTSMQ3W1dNNDQeYXv8tX9wOIBl0L0acn4Jfx31395YNUDnD35bMbFjOt1X6UU0zNimJ4Rw00nTWFVUQ1vrt3LW+v38dbX+4gNt7J4Rhpn5GdwWHYcJpOMuBJCCBFaAgk3hYBFKTVRa73Nty4P6N6ZeCKQA3zkG6JsA2KUUqXAEVrrXUEp8Sg0P30+CzIX8Nzm53hu83OMixnHouxFLBqziGnx03odEm4yKQ7PiefwnHh+eeo0Vm6r5N9rS3htdTEvfF5EZlwYp8/K4PT8dCYk79cQJ4QQQoxI/YYbrXWTUuo14C6l1OUYo6WWAN/qtusGIKvT628BDwOzgYqglHaUspgs/HXRXyltKuXDPR/y/u73eXLDk/x9/d9Ji0hjUfYijss+jtnJszGbzD2ew2o2ceyUZI6dkkxTm5v/bSrl9TV7eaTgGx7+8BumZ0Rz+qwMTstLJzl6eI648mova8vXkhKRQkZkxlAXRwghxDAV6FDwHwFPYgzvrgKu1lpvVEodDbyttY7UWruB0vYDlFLVgFdrXdrjGcWApUakcv6U8zl/yvnUttZSUFzA+0Xv8/LWl3lu83PEO+JZmLWQRdmLOCLtCGxmW4/nibBbOCM/kzPyMylvaOU/6/bx7zUl3PPWZu5dtpkjJyRy+qwMTpyeSqR96Od5rGyp5PVtr/PqtlcpaSzBrMx8Z+x3uHzG5YyPHT/UxRNCCDHMBPTLpbWuBk7vYf1H9DKXjda6AOhxpJQ4cLGOWE6fcDqnTzidZlczK0tW8l7Re/xv1/94bdtrRFgjODrjaBaNWcTRGUcTYY3o8TzJUQ5+cNRYfnDUWL4pb+SNtSW8vqaEn/5rHbf9ez0nTEvljPwMjpqYiNV86O7W4dVePtv7Gf8q/BcFewpwazfzUudxTf41bKnawsuFL7N0x1KOzz6ey2deTm5C7iErmxBCiOFt6P9bLg5YuDWcE3JO4IScE3B6nHy+73PeL3qfD/d8yDu73sFmsnFE+hF8K/1bJIcnE2uPJc4eR6wjllh7LBaT8TWYkBzJT0+YzI3fnsSq3TW8vqaEt9bv4811e4mPsHHqzDQSnG7yW1zEhPU+autAVLZU8u9v/s2rha9S3FhMnD2Oi6ddzJmTzmRM9BgAThl3CpfPuJznNj/HC1te4L2i9zgy/Ugun3E5c1J7HBUohBBiFJFwE2JsZhtHZx7N0ZlHc4f3DtaUr+H9ovd5v+h9VhSv6PGYaFs0cY44f+BpX06cGM/t02IorjKxakcz/7e2DGdrFH9a/T8mJkdy2Jh4DhsTx2Fj4shJCB/0va682svn+z7nX4X/4sOiD3FrN4enHs51s69jUfaiHi+vxTpiuSb/Gi7NvZSXtr7EM5ue4bL/Xsbs5NlcMfMKjkw/Uu69JYQQo5SEmxBmNpmZkzqHOalz+MXhv6CipYKa1hpq22qpaa2hpq2G2tZaqlurjXVtNext3Mumyk1Ut1Xj9rq7nM+eAw4UkeYkGt2JLC2J5ZVt8XhdicSYU8lPH8/hOUkcNiaOGRkxOKw9d25uV9VSxRvb3+CVwlfY07CHWHssF069kDMnncnYmLEBfcZIWyQ/mPEDLph6Aa9ve52nNj7F1e9dzdT4qVwx8woWZS/CpA7d5TQhhBBDT8LNKKGUIjk8meTw5ID211rT7G42gk+rEXyqW6v5eMPHqHhFUX0RRbb1EG1Md+QCvtAmPiuMw7shAVyJpIZnMS1xHPOzJ7NowmTSYiPxai9fln7Jvwr/xftF7+P2upmTMocfz/oxx485HrvZPqjPF2YJ44KpF3D2pLNZumMpT2x4ghsLbmRszFgun3E53xn7Haymg3MpTQghxPAi4Ub0SClFhDWCCGsEWVEdI/xji2NZuGAhYASgmrYaiuqL2F2/m931u/mmZheF1Tspa1lNpf6EFQ2wYiP8boMZsycBuwVaKCfSEs25k87jnCl9T0o4UFazlTMmnsFp40/j3d3v8vf1f+e2lbfxyNpHuCz3Mk6fePqgA5QQQoiRQcKNGDSlFPGOeOId8cxKntVlm9aaqtYqttfs4tM9W1hX+g07a3dT09JES/WxNDRM56nNdlatKSU/u438rFjys+OCdldzs8nMSWNP4sScE1levJy/f/137vn8Hv729d+4aOpFnJBzQpfQJoQQInRIuBEHhVKKxLBEEsMSmZfeMYJJa83eulbWFNWwpqiWNUU1PP3xLh73eAFIi3GQnx1LflYcs8fEkpvef9+d/sqxMGshx2QewxelX/D39X/nwdUP8uDqBxkXM45jMo9hQeYCZiXP8o8aE6PH5qrNPLDqAS7JvYSjMo4a6uIIIYJE/jUXh5RSiozYMDJiwzhlZjoAbW4Pm/c1sKaohtW+wLNsvTH3o9WsmJYWTX52nD/0ZMWHDXgklFKKeWnzmJc2j6L6IlYUr2B58XKe3fwsT218iihbFEelH8WCrAUclX4UsY7YYH90Mcx8uvdTbii4gWZXM1+UfsHP5vyMi6ZeJKPshAgBEm7EkLNbzMzKimVWViyXHWmsK29oZW1RLWv2GGHnpS/38PQnuwCIC7f6bw46PT2GGRkxAwo82dHZXDTtIi6adhGNzkY+2/cZy4uXs6J4BW/vehuTMpGXlMeCzAUck3kME2InyA9eiHl759vcuvJWcqJz+NPCP/Hg6ge5/8v72VazjduPuL3X2b2FECODhBsxLCVHOTghN5UTclMBcHu8FJY1srqohg0ldawvqeMfH+3A5dEARDssTM8wgk77Mjs+vN+7nkfaIjl+zPEcP+Z4vNrLxsqNrChZwfI9y3lo9UM8tPoh0iLS/EFnbtpc6ZA8wj276Vnu//J+Dks5jD8f92eibdE8sPABHln7CI99/Ri763fzwMIHSAhLGOqiCiEGScKNGBEsZhPT0qOZlh7tX9fm9rC1tIENJfWsL6ljQ0kdT328C6ev/06Uw0JuerQ/8EzPiGFsQkSvgcekTMxImsGMpBn8eNaPKW8u56Pij1hevJw3t7/JS1tfIswSxrzUeYyJHoNSynigMCkTCuU/j1IKEyZQdNnevv+e+j1El0UzLWEaDsvwvFFpqNFa86fVf+KpDU9xfPbx/G7B7/xB1aRMXJN/DRNiJ3D7x7dz/lvn85fj/sLk+MlDXGohxGBIuBEjlt1iZmZmLDMzY/3rnG4vhWUNbCipY8PeOtaX1PPPT3fjdBuBJ8JmJjc9hilpUUxOjWJKajSTU6N6vEFocngyZ046kzMnnUmbp40vS79kRfEKPir+iM9LP0drjUbj1V402v+6fdmfV995FYvJwtT4qeQl5ZGXlMes5FmkRqQGrY4OhsqWSr4q/Yqvyr4izBLGyeNOZnLc5GF96c7ldXHnJ3fy5vY3OXfyudwy9xbMpv07qp809iSyorO47oPruPjti/ntUb9l0ZhFQ1BiIcSBkHAjQorNYvK30rRzebx8U97I+pI6NpbUsWFvPa+tLqGxrWMG5sy4MKakRjMl1Qg9U9OiyEmIwOK7WajdbOeojKOMETXzAiuL1p2CT6fQ49Ve3l3+LlETo1hbsZZ1Fet4pfAVntv8HGCEqs5hZ2r81CHtA1LbWstXZV/xRekXfFn6Jd/UfgNAhDWCNk8bT298mgmxEzhl3CmcPO7kYRfOml3N3Lj8Rj4u+ZhrZl3DlTOv7DOI5Sbk8uLJL/KTD3/C9QXXB3SMEGJ4kXAjQp7VbGJqWjRT06JhjjG3jdaaktoWtuxrYGtZA5v31bO1tIEPt5bj8RqtLjaLiYnJkb4Wnih/+EmKsgf0Q6eUwqx6HsYebY5mYfZCjs0+FjBaFgprCllbboSdryu+5t3d7xrlN1mZljDNH3bykvICnml6MOqd9awqXeUPM4U1hWg0YZYwZifP5pRxpzA3dS5TE6bS6Gzkf7v/x3+2/4cHVz/IQ6sf4vDUwzll3Cl8e8y3ibRFHrRyBqK6tZofv/djNlVv4s75d3LmpDMDOi4pPImnTnqKOz+5k4fXPsz22u3cdeRdcglRiBFCwo0YlZRSZMaFkxkXzvHTUvzr29wevilvZGtpA1t8j4+/qeS11SX+feLCrUxMjmJsYgRjkyIYmxjBuMQIshPCsVsGNyeP1WQlNyGX3IRcLpx6IQAVzRV8XfG1v3XnxS0v8symZwBIi0hjbMxY4w7vjjhi7cYd3v03Pu20vr9WnyZXE6vLVvNF6Rd8UfoFW6q34NVe7GY7s5JncU3+NcxNnUtuYu5+t7CIdcRyzuRzOGfyOeyp38PSnUtZun0pv/zkl/zm899wbNaxnDr+VOanzz/kt78obijmqveuorSplAcXPugPkoGym+3ce9S9TIidwEOrH6KooYiHjn2IlIiU/g8WQgwpCTdCdGK3GH1yctNjuqyvaXL6wo7RwrO9opH3t5RR+ZXTv49JQUZcGGMTIxmXaISe9kd6bBjmfkZudZcUnsSiMYv8fT5cHhdbqrewrmIdayvWsrdxL0X1RdS21dLoauz1POGW8B4DkFmZWVOxho2VG/FoD1aTlZlJM/nhzB9yeOrh5CXlDehyWFZ0FlfnXc1VM6/i68qvWbp9Ke/seod3dr1DvCOek3JO4tTxp5KbkHvQL/Fsqd7C1e9djdPj5B8n/GO/GbQDpZTiBzN+wPjY8dy04ibOf+t8Hjr2IWYkzQhugQfJ7XXzdcXXrCheQaunldPGn8a0hGlDXSwhhpyEGyECEBdhY/74BOaP7zo8uL7Vxa7KJnZWNrGjwljurGzild01Xfr02CwmchLCGZsYQU5iBK4qF7F7apmUEkm4LbC/hlaz1T+a6yIu6rLN5XFR56zrctf32rba/Z7Xttayq34XtW21tLnbyE3M5fvTv8/hqYczK3kWYZawA64rpZS/z9AvDv8FK0tWsnTHUl4pfIUXtrxATnSOv39OZlTmAb9fd5/v+5yffPgTomxRPHHCE4yLPfB7ly3MWshzi5/j2g+u5dJ3LuWuI+/i5HEnB6G0A1fbWsvKvStZUbyCj0s+pt5Zj0VZMCkTz29+nqnxUzlr0lksHrt4yC8LCjFUJNwIcQCiHdb9RmyB0aenorGNnZ0Cz47KJrZXNPHBlnJcHs2TGz5GKciOD/d1ZO7o0JyTEDGglh6r2eq/3UWgtNYHvQXFarZybPaxHJt9LPXOet7d9S5Ldyzl4bUP8/Dah8lPzmde2jxmJc1iZtJMomxRB/R+7+x8h1tW3kJOdA6PHv9oUDs3T4ybyP+d/H/cWHAjN390M9tqtnHd7OswKVPQ3qMnWmsKawr5qOQjVhSvYF3FOrzaS7wj3n9rkfnp8/FqL2/teItXtr3C3Z/dzR+++gOLxy7mzIlnMj1xunSIFqOKhBshDgKlFMlRDpKjHMwb17W1x+3x8uo7BcSMmcbW0ga2ltWzpbSBdzeV4evLjN1iYmJKZJcRXJNTo0iKDKwzc6BlPJSibdH+ofV7G/eybOcy/rfrfzz+9eN4tReFYkLcBPKT8pmVPItZSbPIjMoMuJzPb36e+764j/zkfP583J+Jscf0f9AAxTniePzbj3PvF/fyxIYn2F63nd8d/TsirBFBfZ8Wdwtf7PuCFcUrWFGygtIm43YkU+OncuXMK1mQsYDcxNz9gtUFUy/g/Cnns75yPa8UvsKynct4ddurTI6bzFmTzuLkcScfcIAUYiSQcCPEIWYxm0iJMLFweionTe9oWWh1edhW1ujv17O1rIGCrRW8sqrYv098hI3JKVFMSYtiXFIkWXFhZMWHkxEbdkA3GD3U0iPTuXzG5Vw+43KaXE3+jtNry9eybOcyXi58GYAERwKzkmeRn5xPXlIe0xKm7dcPSGvNg6se5IkNT7AoexG/O/p3B3VUk9Vs5ZdH/JKJsRO5/8v7uWjZRfz6W78mxh6D1WTFYrL4l+3Pzcrcb0jb27jXCDPFK/ii9AvaPG2EWcKYnzafq/Ou5qiMowIaJaeUYmbSTGYmzeTnh/+ct3e+zb8K/8VvPv8Nf/zqj5yYcyJnTTqLvKQ8ac0RIUvCjRDDhMNqZkZmDDMyu7Y4VDW2+UdvbfV1an7xiz20uDxd9kuJtpMVF05WfDhZcWFkxof7XoeRFjPwDs2HSoQ1gvnp85mfPh8Aj9fD9rrtrC03ws7airW8X/Q+ADaTjdzEXGYlzSIvOY8ZiTN4ruo5vij6grMnnc1t827rcXK+YFNKccHUCxgbM5afLv8pFy67sN9jOoeezkuryYrL66Kk0RiRlxWVxdmTzubozKOZkzLngOY4irJFcc7kczh70tlsqtrEK9teYdmOZbyx/Q0mxE7grElnccq4Uw5KK5cQQ0lp3f9MqgfbnDlz9FdffXXQzl9QUMDChQsP2vlHE6nL4DjQevR6NWUNreypbmFPdTN7apqN5zXNFFc3s6++lc5/tS0mRXpsGFnxYf4AlBln3J09LTaMlCi7f8LC4aiypZJ15cYosTXla9hUtQmX1+Xf/qNZP+KqmVcNSUtEaVMpa8vX4vK6cHvd/mXn570t2597tZeZSTNZkLmAnOicg/o5mlxNvL3zbV4tfJUNVRuwm+18e8y3OXPimdRtrmPRsSNnRubq1mo2VW1iU9UmNlZuZGPVRura6piaMJUZiTOMR9IM0iPSD/p3w+V1sbtuN4U1hXy+4XMWzlrImJgxZEVmYTUf2mkQQklf/1YqpVZpref0uE3CjRgIqcvgONj16HR72Vvb4g89xTXN7KkxglBxTTOVjc4u+5uUcbPStFgH6TFhpMU4SIsNI73TMjHS3u+NSA+VNk8bm6s2s7Z8LfVF9Vy3+LqhLtKItKV6C68UvsJbO96i0dWIBQsT4ycyKW6S8Yg3lvGO+KEuKnVtdWys2ugPMpuqNrG3aa9/e050DtMSphFrj2Vj1UY2V23G6TW+5/GO+I6wkziD6UnTibZF9/ZW/apqqaKwprDLY3vt9i6Bu51JmUiPSGdMzBjGRI1hTHTHIy0i7ZC0NAZTb7ed8Wpvj9sirZEH9BkHG27kspQQIchmMZHjG3bek2anm+KaFvbWtrCvrpV9tS3srWtlX10Lm/fV8/6WMlpd3i7HWM2KlGhf+Il1kBZjtATlJEQwJiH8kF76ap9gcFbyLAoqCw7Je4aiKfFTuP2I27nxsBsp2FPAf9f9lxZ7Cx/v/Zg3tr/h3y8xLLEj8PgeY2PGHrTbgtS11bG5erM/xGys2ui/bAeQHZVNXlIe5085n9zEXKbET9mvo3T7rN8bKjbwdeXXbKjcwPLi5f7tOdE5/padGYkzmBw3eb8WFqfHyc66nRTWFLK1eqs/yFS1Vvn3SQ5LZmL8ROanz/fXzdbVW8mZmcOu+l3srt9NUX0Ru+p3sbZ8LU2uJv+xVpOVrKisLoFnTPQYsqOyibZHY1ZmzMrsvxnvYLW6W6lrq6POWUddWx31bfXUO+u7rGt/Xt/Wsd7pce4XYAbqnTPfISMyY9BlHywJN0KMQuE2C5NSopiU0vPIGa01tc0u9ta1sK+2lb11LeytNcLPvtpWVu2uoax+Hy5PR8uvzWzqFHaMwDMmIZychAgy4sKwDuPLXqNduDWcxeMWE14U7v9fclVLFdtqt1FY3dE68cLmF/ytIRZlIScmp0vgSYtIw+l14vQ4afO0dXm0r3N6nLS6W7uu8xrLZlcz22u3U9RQ5C9bZmQmuQm5nDP5HHITcpmaMDWgVpfOs36fy7kANDgb2Fi1kfUV61lfuZ5P933Kf3b8x7//1PipTEuYRr2znsKaQnbV7cKtjfmqbCYbE+ImcHTm0f7POzFuYo+tWnvNe/1zUnWmtaaqtYpddbsoajACT1F9Ebvrd/Nxycf+uu1J+1xGZpPZeG4yYVbGc7PJCEAWk8UfhgAjqDjraPO09XneaHs0MfYYYmwxJIcnMzFuItG2aGxmmxGsUCilujxX9Py6/b3bt8XYhqY/l4QbIcR+lFLERdiIi7DtN1tzO69XU1rfyq6qJoqqmtlV1czuqiZ2VTXz6Y4qmp0dHZ7NJkVmXBhjEiLISQjvtAwnNSasx7uyi6GVEJZAQlgCR6Qd4V/n9ropqi/qcjlmTfkalu1cNuDzm5QJu9mO3WzHZrb5n0+On8wZE89gWsI0chNyg9rZOcoWxRFpR/g/k9aa0qZS1leu9z/e2P4GsfZYJsVN4tisY/2X57KjsrGYDux7qpTyz0c1J7Xr1RSP10NZc5k/8DS7m/F4Pbi1G6/2djz3evFoD26vb32n527txuP14NEeFMoILbaYLuElxm48om3GunBLeEiOmpN/UYQQg2LydVJOjw3jW+O7bmufxHB3VTO7KpuMZZWxXLO7hoZOszcDRNotpETbSYl2kBrtICXGQUqUndQYBynRxiMpyi6tP0PMYrIwLnYc42LHcdLYk/zr6531bKvZRkVLBXZTR2BxWBxdgkvn5wcaFIJBKUVaZBppkWmckHPCkJbFbDKTHplOemQ630r/1pCWJRQM/bdLCBFyOk9ieHhO12Z7rTU1zS5/i09pfStlvkdpXSuf76ymvKG1yyUv45yQEGEnNcZOarSDZF8QqtnnQm8pJznaTnKUg4QI27Dp+DxaRNuiOSzlsKEuhhB+Em6EEIeUUor4CBvxETZmZ8f1uI/Xq6ludnYKPW0dz+tbKaltZXVRLdVNRh+FpzZ86T/WbFIkRdp9YcdOUpSDFF/wSY4yWoeSo+0kRNiG9fB3IcTgSbgRQgw7JpMiMdJOYqS91z4/AG1uD2/+bznjcvOpaGilrL6N8oZWyuvbKGtoo7imhTVFtVQ17d9R06QgPsJOSrSd9Fhjzp/0WAcZseG+ZdiwGv4uhAichBshxIhlt5hJCjdx2JieW4DaOd1eKhvbKG9oo7y+lbKGNirqWylvaKO0vpWiqmY+3V7V5U7uYIwAa5/7Jz02jIy4MDJiHZ3C0Mi67YUQo4WEGyFEyLNZTP7Oz32pb3Wxt7aFEt8cQCW1rZTUGs8/2V5JWX2r/+am7RIibKTGGB2ekyLtJPqWSVFGy1P7+ugwS0iOShFiOJJwI4QQPtEOK9GpVqak9jyPisvjpbSulb21Lf65f4prWiirb6XSdw+wysa2/TpDg9EKZAQeW9fg43vePlosOcqBzSJ9gYQ4EBJuhBAiQFazybgxaXx4r/toralrcVHR0GY8GrsuKxudlNS2snZPHdVNbfu1BAEkRtpIjnL4h8KnRjtIjbH7R4ilRjuIDbdKS5AQvZBwI4QQQaSUIjbcRmy4jYm9zADdzuPVVDc5/Z2guw+L31fXyro9PXeItltMvjmA7F3mAup+aSw+wjZs7wgvxMEi4UYIIYaI2aT8l6Zy03vfr83tMUaA1Rsjwko7BaCy+lY2lNTx/uZyWlye/Y5tHxXW+ZJYUqfw0zkMDYcbKQsRDBJuhBBimLNbzP1eDgNoanP7Ln11vxTW5r9MtqOiiYqGNpye/W+CaFaQ9On7JEbZjD5BnYJPoi8cJfv6CMWEyWUxMXxJuBFCiBARYbcQYbf0ejf4dlpr6lvc+/UHWr1xG+HxiVQ0GoFoyz6jg7S7h45BVnPHXETtLUIJkcbkiPHdHgkRdsJsMmReHDoSboQQYpRRShETbiUm3MqE5Ej/+vHu3SxcmNdlX6/X6CDduTWostHpf13ZaKzbtK+eqkZnj0EIwGE1kRBh9AGKi7D1EoJsJPjCUqRdhs6LwZNwI4QQolcmU8cd4vvrIK21pr7VTU2Tk6omJ9VNTqqb2qhuclHd1NZpnZMdFY1UNzm73D2+M7vF5G8VSoy0k+BbJrZfIouw+S6V2YkNs8pM0qILCTdCCCGCQilFTJiVmDBrv5fG2rW6PFQ1Of2BqLKhjaomX+uQr6VoX10r60vqqGpy4umhZchsMu5X1h6GjFYhIxB1bhVqv0QmEyqGPgk3QgghhozDaibDdzuL/ni9mtoWF1WNnS6PtYehBuNSWWWTk11VTVQ3OmnqpVXI4muNSojoHn6MQBQXbiM23Op72IgLtxJmNUsgGkEk3AghhBgRTKaOO8r3d4kMjFah9stgVb5LZFWNzm7rnGzcW09VYxv1re5ez2Uzm7oEntgwa6cQ5FuGGc/3NHgpb2glPlzuPD9UJNwIIYQISQ6rOaB7irVzebzUNDmpaXZR22ws61raXxvraptd1DQ7KapuZl1xLTXNLpzu/YfV3/Hx+wDEhFm7thB1GlHW9bKZ0dlabr0RHBJuhBBCCIzbayRHO0iOdgzouBanh9oWJzVNLmpbnKz8ci1pYyb4W4aqmpxUNbaxq6qJ1UU1VDc5e7ztBkCU3UJCpI2YcJu//1K0w+J/3vkR3WkZZbdIp+pOJNwIIYQQByDMZibMFkZajNFC5NxjYeH8nF73bx9e33lEmRGAOsJQbbOTuhYXe6qbqWtxUdfi6rEzdTuTgiiHlegwIwjFhhktQwm+fkTtw+wTIm0kRtiJj7QRYQvdfkQSboQQQohDqPPw+kBprWlyeqhrcVHvCzvtj/oe1tW2uNizp5mqRieNbT33JWofbt9+eSwhwjfazBeKYsKsRDksRDmMZXSYlUi7ZUTcq0zCjRBCCDHMKaWItFuItFsCGlnWWftw+6rGjhaiLs99Ha0LSxuobHL22Ieos0i7xRd6OoJPlMO4fOYPQr7nx09LIdJ+6KOGhBshhBAihA1kuH17C1FlQxt1LS4aWt00tBrL+m7L9vVVjU52VTZR71vn8nRcPvv45uMk3HTmcrkoLi6mtbX1gM8VExPD5s2bg1Cq0cvhcJCZmTnUxRBCCHEQdW4hGgytNW1urz8ApUTZg1zCwAzbcFNcXExUVBQ5OTkH3OGpoaGBqKj+50QQPdNaU1VVRXFx8VAXRQghxDCmlMJhNeOwmkkewp/dYTugvrW1lYSEhJDtyT2SKKVISEgISiuaEEIIcbAN23ADSLAZRuTPQgghxEgRULhRSsUrpV5XSjUppXYrpS7oZb+fK6U2KKUalFI7lVI/D25xhRBCCCH6Fmifm78CTiAFmAW8pZRap7Xe2G0/BXwP+BoYD/xPKbVHa/1ikMp7SEVGRtLY2DjUxRBCCCHEAPTbcqOUigDOBO7QWjdqrVcCbwIXd99Xa32/1nq11tqttd4KvAEcGexCCyGEEEL0JpCWm0mAR2td2GndOuCYvg5SRieNo4HHetl+JXAlQEpKCgUFBV22x8TE0NDQAMB9/9vOlrLBt6BorffrMzIlJZKbThjf77ENDQ1orbnjjjt49913UUrx85//nDPPPJPS0lIuvfRSGhoacLvd/OlPf2LevHn8+Mc/Zs2aNSiluOiii7jmmmsGXfbhpLW1lcbGxv3+rMTAST0Gj9Rl8EhdBofUY/AMti4DCTeRQF23dXVAf4O87sRoGXqqp41a68eBxwHmzJmjFy5c2GX75s2b/cO3rTYrZrM5gKL2zOPx7He81WYNaHh4VFQUr776Kps2bWL9+vVUVlZy+OGHc+KJJ/Lmm2+yePFibrvtNjweD83NzRQWFlJeXs6mTZsAqK2tDZlh6A6Hg8jISLr/WYmBKygokHoMEqnL4JG6DA6px+AZbF0GEm4agehu66KBht4OUEpdg9H35mitdduAS9XNr07NPaDjD3Sem5UrV3L++edjNptJSUnhmGOO4csvv+Twww/n+9//Pi6Xi9NPP51Zs2Yxbtw4duzYwbXXXsvJJ5/MCSeccEBlF0IIIcTABDJaqhCwKKUmdlqXB3TvTAyAUur7wM3AIq11SMz6pnXPd2JdsGABK1asICMjg4svvphnnnmGuLg41q1bx8KFC/nrX//K5ZdffohLK4QQQoxu/YYbrXUT8Bpwl1IqQil1JLAEeLb7vkqpC4F7gW9rrXcEu7BDZcGCBbz00kt4PB4qKipYsWIFc+fOZffu3SQnJ3PFFVfwgx/8gNWrV1NZWYnX6+XMM8/k7rvvZvXq1UNdfCGEEGJUCXQo+I+AJ4FyoAq4Wmu9USl1NPC21jrSt989QALwZacOvM9pra8KYpkPuTPOOINPP/2UvLw8lFLcf//9pKam8s9//pPf//73WK1WIiMjeeaZZygpKeGyyy7D6zXuqvrb3/52iEsvhBBCjC4BhRutdTVweg/rP8LocNz+emzQSjYMtM9xo5Ti97//Pb///e+7bL/kkku45JJL9jtOWmuEEEKIoTOsb78ghBBCCDFQEm6EEEIIEVIk3AghhBAipEi4EUIIIURIkXAjhBBCiJAi4UYIIYQQIUXCjRBCCCFCioSbYcDtdg91EYQQQoiQEegMxUPr7ZuhdP2gDw/zuMHc7aOmzoDv/K7fY08//XT27NlDa2srP/nJT7jyyit55513uPXWW/F4PCQmJvL+++/T2NjItddey1dffYVSil/96leceeaZREZG+icDfOWVV1i6dClPP/00l156KfHx8axZs4bZs2dz7rnncv3119PS0kJYWBhPPfUUkydPxuPxcNNNN/Hf//4XpRRXXHEF06ZN4+GHH+b1118H4N133+XRRx/ltddeG3QdCSGEEKFiZISbIfTkk08SHx9PS0sLhx9+OEuWLOGKK65gxYoVjB07lurqagDuvvtuYmJiWL/eCGE1NTX9nruwsJD33nsPs9lMfX09K1aswGKx8N5773Hrrbfy6quv8vjjj7Nz507WrFmDxWKhurqauLg4fvzjH1NRUUFSUhJPPfUUl1122UGtByGEEGKkGBnhJoAWlr60NDQQFRU1qGP//Oc/+1tI9uzZw+OPP86CBQsYO9a400R8fDwA7733Hi+++KL/uLi4uH7PffbZZ2M2mwGoq6vjkksuYdu2bSilcLlc/vNeddVVWCyWLu938cUX89xzz3HZZZfx6aef8swzzwzq8wkhhBChZmSEmyFSUFDAe++9x6effkp4eDgLFy4kLy+PrVu37rev1ppONwv167yutbW1y7aIiAj/8zvuuINjjz2W119/nV27drFw4cI+z3vZZZdx6qmn4nA4OPvss/3hRwghhBjtpENxH+rq6oiLiyM8PJwtW7bw2Wef0dbWxvLly9m5cyeA/7LUCSecwMMPP+w/tv2yVEpKCps3b8br9fpbgHp7r4yMDACefvpp//oTTjiBv/3tb/5Ox+3vl56eTnp6Ovfccw+XXnpp0D6zEEIIMdJJuOnDSSedhNvtZubMmdxxxx0cccQRJCUl8fjjj/Pd736XvLw8zj33XABuv/12ampqmD59Onl5eXz44YcA/O53v+OUU07huOOOIy0trdf3+sUvfsEtt9zCkUceicfj8a+//PLLyc7OZubMmeTl5fHCCy/4t1144YVkZWUxbdq0g1QDQgghxMgj1zL6YLfbefvtt3vc9p3vfKfL68jISP75z3/ut99ZZ53FWWedtd/6zq0zAPPnz6ewsND/+u677wbAYrHwwAMP8MADD+x3jpUrV3LFFVf0+zmEEEKI0UTCzQh12GGHERERwR//+MehLooQQggxrEi4GaFWrVo11EUQQgghhiXpcyOEEEKIkCLhRgghhBAhRcKNEEIIIUKKhBshhBBChBQJN0IIIYQIKRJugiQyMrLXbbt27WL69OmHsDRCCCHE6DUihoLf98V9bKneMujjPR6P/waV7abET+GmuTcdaNGEEEIIMcxIy00vbrrpJh555BH/6zvvvJNf//rXLFq0iNmzZzNjxgzeeOONAZ+3tbWVyy67jBkzZpCfn++/TcPGjRuZO3cus2bNYubMmWzbto2mpiZOPvlk8vLymD59Oi+99FLQPp8QQggRqkZEy82BtrA0NDQQFRU1oGPOO+88rr/+en70ox8B8PLLL/POO+9www03EB0dTWVlJUcccQSnnXZaj3ft7s1f//pXANavX8+WLVs44YQTKCws5G9/+xs/+clPuPDCC3E6nXg8HpYtW0Z6ejpvvfUWYNxcUwghhBB9k5abXuTn51NeXs7evXtZt24dcXFxpKWlceuttzJz5kyOP/54SkpKKCsrG9B5V65cycUXXwzAlClTGDNmDIWFhcyfP597772X++67j927dxMWFsaMGTN47733uOmmm/joo4+IiYk5GB9VCCGECCkSbvpw1lln8corr/DSSy9x3nnn8fzzz1NRUcGqVatYu3YtKSkptLa2DuicWuse119wwQW8+eabhIWFceKJJ/LBBx8wadIkVq1axYwZM7jlllu46667gvGxhBBCiJA2Ii5LDZXzzjuPK664gsrKSpYvX87LL79McnIyVquVDz/8kN27dw/4nAsWLOD555/nuOOOo7CwkKKiIiZPnsyOHTsYN24c1113HTt27ODrr79mypQpxMfHc9FFFxEZGbnfncSFEEIIsT8JN33Izc2loaGBjIwM0tLSuPDCCzn11FOZM2cOs2bNYsqUKQM+549+9COuuuoqZsyYgcVi4emnn8Zut/PSSy/x3HPPYbVaSU1N5Ze//CVffvklP//5zzGZTFitVh599NGD8CmFEEKI0CLhph/r16/3P09MTOTTTz/tcb/GxsZez5GTk8OGDRsAcDgcPbbA3HLLLdxyyy1d1p144omceOKJgyi1EEIIMXpJnxshhBBChBRpuQmi9evX+0dCtbPb7Xz++edDVCIhhBBi9JFwE0QzZsxg7dq1Q10MIYQQYlSTy1JCCCGECCkSboQQQggRUiTcCCGEECKkSLgRQgghREiRcBMkkZGRQ10EIYQQQjBCRkuV3nsvbZu3DPp4t8dDtdncZZ196hRSb731QIs27LjdbiyWEfHHKoQQQhwU0nLTi5tuuolHHnnE//rOO+/k17/+NYsWLWL27NnMmDGDN954I6BzNTY29nrcM888w8yZM8nLy/PPkVNWVsYZZ5xBXl4eeXl5fPLJJ+zatYvp06f7j/vDH/7AnXfeCcDChQu59dZbOeaYY3jooYf4z3/+w7x588jPz+f444/337m8sbGRyy67jBkzZjBz5kxeffVVnnjiCW644Qb/ef/+979z4403DrrehBBCiKE2Iv6Lf6AtLA0NDURFRQ3omPPOO4/rr7+eH/3oRwC8/PLLvPPOO9xwww1ER0dTWVnJEUccwWmnnYZSqs9zORwOXn/99f2O27RpE7/5zW/4+OOPSUxMpLq6GoDrrruOY445htdffx2Px0NjYyM1NTV9vkdtbS3Lly8HoKamhs8++wylFP/4xz+4//77+eMf/8jdd99NTEyM/5YSNTU12Gw2Zs6cyf3334/VauWpp57iscceG1BdCSGEEMPJiAg3QyE/P5/y8nL27t1LRUUFcXFxpKWlccMNN7BixQpMJhMlJSWUlZWRmpra57m01tx66637HffBBx9w1llnkZiYCEB8fDwAH3zwAc888wwAZrOZmJiYfsPNueee639eXFzMueeey759+3A6nYwdOxaA9957jxdffNG/X1xcHADHHXccS5cuZerUqbhcLmbMmDHA2hJCCCGGDwk3fTjrrLN45ZVXKC0t5bzzzuP555+noqKCVatWYbVaycnJobW1td/z9Hac1rrfVp92FosFr9frf939fSMiIvzPr732Wm688UZOO+00CgoK/Jevenu/yy+/nHvvvZcpU6Zw2WWXBVQeIYQQYriSPjd9OO+883jxxRd55ZVXOOuss6irqyM5ORmr1cqHH37I7t27AzpPb8ctWrSIl19+maqqKgD/ZalFixbx6KOPAuDxeKivryclJYXy8nKqqqpoa2tj6dKlfb5fRkYGAP/85z/960844QQefvhh/+v21qB58+axZ88eXnjhBc4///xAq0cIIYQYliTc9CE3N5eGhgYyMjJIS0vjwgsv5KuvvmLOnDk8//zzTJkyJaDz9HZcbm4ut912G8cccwx5eXn+jrwPPfQQH374ITNmzOCwww5j48aNWK1WfvnLXzJv3jxOOeWUPt/7zjvv5Oyzz+boo4/2X/ICuP3226mpqWH69Onk5eXx4Ycf+redc845HHnkkf5LVUIIIcRIJZel+tHe+RYgMTGRTz/9tMf9Ghsbez1HX8ddcsklXHLJJV3WpaSk9DgS67rrruO6667bb31BQUGX10uWLGHJkiX77RcZGdmlJaezlStXdhk1JYQQQoxU0nIzytXW1jJp0iTCwsJYtGjRUBdHCCGEOGDSchNE69ev989V085ut/P5558PUYn6FxsbS2Fh4VAXQwghhAiaYR1uBjKaaDiYMWMGa9euHepiHBRa66EughBCCBGQYXtZyuFwUFVVJT+qw4DWmqqqKhwOx1AXRQghhOjXsG25yczMpLi4mIqKigM+V2trq/wwHyCHw0FmZmbAw9+FEEKIoTJsw43VavXPrHugCgoKyM/PD8q5hBBCCDG8BXRZSikVr5R6XSnVpJTarZS6oJf9lFLqPqVUle9xvxpJnWaEEEIIMeIF2nLzV8AJpACzgLeUUuu01hu77XclcDqQB2jgXWAH8LdgFFYIIYQQoj/9ttwopSKAM4E7tNaNWuuVwJvAxT3sfgnwR611sda6BPgjcGkQyyuEEEII0adAWm4mAR6tdefJUNYBx/Swb65vW+f9cns6qVLqSoyWHoBGpdTWAMoyWIlA5UE8/2gidRkcUo/BI3UZPFKXwSH1GDx91eWY3g4KJNxEAnXd1tUBUQHsWwdEKqWU7jamW2v9OPB4AO9/wJRSX2mt5xyK9wp1UpfBIfUYPFKXwSN1GRxSj8Ez2LoMpENxIxDdbV000BDAvtFAY/dgI4QQQghxsAQSbgoBi1JqYqd1eUD3zsT41uUFsJ8QQgghxEHRb7jRWjcBrwF3KaUilFJHAkuAZ3vY/RngRqVUhlIqHfgp8HQQyztYh+Ty1yghdRkcUo/BI3UZPFKXwSH1GDyDqksVyBUjpVQ88CTwbaAKuFlr/YJS6mjgba11pG8/BdwHXO479B/ATXJZSgghhBCHSkDhRgghhBBipBi2N84UQgghhBgMCTdCCCGECCkhHW4CvSeW6J9SqkAp1aqUavQ9DuakiyFDKXWNUuorpVSbUurpbtsWKaW2KKWalVIfKqV6nZBK9F6XSqkcpZTu9N1sVErdMYRFHdaUUnal1BO+fxMblFJrlFLf6bRdvpcB6qsu5Xs5MEqp55RS+5RS9UqpQqXU5Z22Dfg7GdLhhq73xLoQeFQp1eOMySIg12itI32PyUNdmBFiL3APRod8P6VUIsYoxDuAeOAr4KVDXrqRpce67CS20/fz7kNYrpHGAuzBmGU+BuM7+LLvx1i+lwPTa1122ke+l4H5LZCjtY4GTgPuUUodNtjvZKA3zhxxOt0Ta7rWuhFYqZRqvyfWzUNaODFqaK1fA1BKzQEyO236LrBRa/0v3/Y7gUql1BSt9ZZDXtARoI+6FAPgm97jzk6rliqldgKHAQnI9zJg/dTlqiEp1AjV7Ubc2vcYj1GXA/5OhnLLTW/3xJKWm8H7rVKqUin1sVJq4VAXZoTrch823z+S25Hv54HYrZQqVko95fvfngiAUioF49/Ljcj38oB0q8t28r0MkFLqEaVUM7AF2AcsY5DfyVAONwO5J5bo303AOCADY1Kl/yilxg9tkUY0+X4GTyVwOMZN9A7DqMPnh7REI4RSyopRV//0/S9YvpeD1ENdyvdygLTWP8Kop6MxLkW1McjvZCiHm4HcE0v0Q2v9uda6QWvdprX+J/AxsHioyzWCyfczSLTWjVrrr7TWbq11GXANcIJSqnv9ik6UUiaMmeadGHUG8r0clJ7qUr6Xg6O19mitV2Jcer6aQX4nQzncDOSeWGLgNKCGuhAjWJf7sPn6iI1Hvp/B0D4zqXw/e+GbTf4JjMEWZ2qtXb5N8r0coD7qsjv5Xg6MhY7v3oC/kyEbbgZ4TyzRB6VUrFLqRKWUQyllUUpdCCwA/jvUZRvufPXlAMyAub0OgdeB6UqpM33bfwl8LZ02e9dbXSql5imlJiulTEqpBODPQIHWuntTtujwKDAVOFVr3dJpvXwvB67HupTvZeCUUslKqfOUUpFKKbNS6kTgfOADBvud1FqH7ANj2Ni/gSagCLhgqMs0Eh9AEvAlRjNgLfAZ8O2hLtdIeGCMpNDdHnf6th2P0XGuBSjAGAY55GUero/e6tL3j+BO39/zfRg38E0d6vIO1wdGHxANtGI0+bc/LvRtl+9lEOpSvpcDqsckYLnv96UeWA9c0Wn7gL+Tcm8pIYQQQoSUkL0sJYQQQojRScKNEEIIIUKKhBshhBBChBQJN0IIIYQIKRJuhBBCCBFSJNwIIYQQIqRIuBFCCCFESJFwI4QQQoiQ8v863qRX6v5kNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "save_fig(\"keras_learning_curves_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10-12. Learning curves: the mean training loss and accuracy measured over each epoch, and the mean validation loss and accuracy measured at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both the training accuracy and the validation accuracy steadily increase during training, while the training loss and the validation loss decrease. Good! Moreover, the validation curves are close to the training curves, which means that there is not too much overfitting. In this particular case, the model looks like it performed better on the validation set than on the training set at the beginning of training. But that’s not the case: indeed, the validation error is computed at the end of each epoch, while the training error is computed using a running mean during each epoch. So the training curve should be shifted by half an epoch to the left. If you do that, you will see that the training and validation curves overlap almost perfectly at the beginning of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set performance ends up beating the validation performance, as is generally the case when you train for long enough. You can tell that the model has not quite converged yet, as the validation loss is still going down, so you should probably continue training. It’s as simple as calling the `fit()` method again, since Keras just continues training where it left off (you should be able to reach close to 89% validation accuracy).\n",
    "\n",
    "If you are not satisfied with the performance of your model, you should go back and tune the hyperparameters. The first one to check is the learning rate. If that doesn’t help, try another optimizer (and always retune the learning rate after changing any hyperparameter). If the performance is still not great, then try tuning model hyperparameters such as the number of layers, the number of neurons per layer, and the types of activation functions to use for each hidden layer. You can also try tuning other hyperparameters, such as the batch size (it can be set in the `fit()` method using the `batch_size` argument, which defaults to 32). We will get back to hyperparameter tuning at the end of this chapter. Once you are satisfied with your model’s validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. You can easily do this using the `evaluate()` method (it also supports several other arguments, such as `batch_size` and `sample_weight`; please check the documentation for more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3370836079120636, 0.882099986076355]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING THE MODEL TO MAKE PREDICTIONS**  \n",
    "\n",
    "Next, we can use the model’s `predict()` method to make predictions on new instances. Since we don’t have actual new instances, we will just use the first three instances of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: `model.predict_classes(X_new)` is deprecated. It is replaced with `np.argmax(model.predict(X_new), axis=-1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_new) # deprecated\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure fashion_mnist_images_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "save_fig('fashion_mnist_images_plot', tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 10-13. Correctly classified Fashion MNIST images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a Regression MLP Using the Sequential API**  \n",
    "\n",
    "\n",
    "Let’s switch to the California housing problem and tackle it using a regression neural network. For simplicity, we will use Scikit-Learn’s `fetch_california_housing()` function to load the data. This dataset is simpler than the one we used in Chapter 2, since it contains only numerical features (there is no `ocean_proximity` feature), and there is no missing value. After loading the data, we split it into a training set, a validation set, and a test set, and we scale all the features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load, split and scale the California housing dataset (the original one, not the modified one as in chapter 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 977us/step - loss: 2.2656 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.7413 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.6604 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.6245 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.5770 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.5609 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.5500 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.5200 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.5051 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.4910 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.4794 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.4656 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.4693 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.4537 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 814us/step - loss: 0.4586 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4612 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.4449 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.4407 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.4128 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 508us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Sequential API is quite easy to use. However, although `Sequential` models are extremely common, it is sometimes useful to build neural networks with more complex topologies, or with multiple inputs or outputs. For this purpose, Keras offers the Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see [paper](https://ai.google/research/pubs/pub45413)) connects all or part of the inputs directly to the output layer, as shown in Figure 10-14. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./chapters/10/10.14.png\" width=600>\n",
    "<div style=\"text-align:left\"> Figure 10-14. Wide & Deep neural network </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through each line of this code:\n",
    "\n",
    "- First, we need to create an `Input` object. This is a specification of the kind of input the model will get, including its `shape` and `dtype`. A model may actually have multiple inputs, as we will see shortly.\n",
    "\n",
    "- Next, we create a `Dense` layer with 30 neurons, using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together; no actual data is being processed yet.\n",
    "\n",
    "- We then create a second hidden layer, and again we use it as a function. Note that we pass it the output of the first hidden layer.\n",
    "\n",
    "- Next, we create a Concatenate layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer. You may prefer the `keras.layers.concatenate()` function, which creates a `Concatenate` layer and immediately calls it with the given inputs.\n",
    "\n",
    "- Then we create the output layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
    "\n",
    "- Lastly, we create a Keras `Model`, specifying which inputs and outputs to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.9731 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.7638 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.6045 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.5862 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.5452 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.5243 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.5185 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4947 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.4782 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.4708 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.4481 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4476 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.4361 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.4392 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.4420 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4277 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4216 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.4033 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3939 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 539us/step - loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path (see Figure 10-15)? In this case, one solution is to use multiple inputs. For example, suppose we want to send five features through the wide path (features 0 to 4), and six features through the deep path (features 2 to 7):What if you want to send different subsets of input features through the wide or deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./chapters/10/10.15.png\" width=600>\n",
    "<div style=\"text-align:left\"> Figure 10-15. Handling multiple inputs </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is self-explanatory. You should name at least the most important layers, especially when the model gets a bit complex like this. Note that we specified `inputs=[input_A, input_B]` when creating the model. Now we can compile the model as usual, but when we call the `fit()` method, instead of passing a single input matrix `X_train`, we must pass a pair of matrices (`X_train_A, X_train_B`): one per input. The same is true for `X_valid`, and also for `X_test` and `X_new` when you call `evaluate()` or `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5,], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6,], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, :5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.1941 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.7247 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.6176 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.5409 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.5173 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.5186 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.4977 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.4765 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4676 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4574 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.4479 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.4487 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.4469 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4460 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.4378 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.4375 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.4151 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 484us/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many use cases in which you may want to have multiple outputs:\n",
    "\n",
    "- The task may demand it. For instance, you may want to locate and classify the main object in a picture. This is both a regression task (finding the coordinates of the object’s center, as well as its width and height) and a classification task.\n",
    "\n",
    "- Similarly, you may have multiple independent tasks based on the same data. Sure, you could train one neural network per task, but in many cases you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can learn features in the data that are useful across tasks. For example, you could perform *multitask classification* on pictures of faces, using one output to classify the person’s facial expression (smiling, surprised, etc.) and another output to identify whether they are wearing glasses or not.\n",
    "\n",
    "- Another use case is as a regularization technique (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). For example, you may want to add some auxiliary outputs in a neural network architecture (see Figure 10-16) to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./chapters/10/10.16.png\" width=600>\n",
    "<div style=\"text-align:left\"> Figure 10-16. Handling multiple outputs, in this example to add an auxiliary output for regularization </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5,], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6,], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output will need its own loss function. Therefore, when we compile the model, we should pass a list of losses (if we pass a single loss, Keras will assume that the same loss must be used for all outputs). By default, Keras will compute all these losses and simply add them up to get the final loss used for training. We care much more about the main output than about the auxiliary output (as it is just used for regularization), so we want to give the main output’s loss a much greater weight. Fortunately, it is possible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we train the model, we need to provide labels for each output. In this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. So instead of passing `y_train`, we need to pass (`y_train, y_train`) (and the same goes for `y_valid` and `y_test`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.4633 - main_output_loss: 3.3289 - aux_output_loss: 4.6732 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9807 - main_output_loss: 0.7503 - aux_output_loss: 3.0537 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7742 - main_output_loss: 0.6290 - aux_output_loss: 2.0810 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6952 - main_output_loss: 0.5897 - aux_output_loss: 1.6449 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6469 - main_output_loss: 0.5508 - aux_output_loss: 1.5118 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6120 - main_output_loss: 0.5251 - aux_output_loss: 1.3943 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6114 - main_output_loss: 0.5256 - aux_output_loss: 1.3833 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5765 - main_output_loss: 0.5024 - aux_output_loss: 1.2439 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5535 - main_output_loss: 0.4811 - aux_output_loss: 1.2057 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5456 - main_output_loss: 0.4708 - aux_output_loss: 1.2189 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5297 - main_output_loss: 0.4587 - aux_output_loss: 1.1684 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5181 - main_output_loss: 0.4501 - aux_output_loss: 1.1305 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5100 - main_output_loss: 0.4487 - aux_output_loss: 1.0620 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5064 - main_output_loss: 0.4459 - aux_output_loss: 1.0503 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5027 - main_output_loss: 0.4452 - aux_output_loss: 1.0207 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5057 - main_output_loss: 0.4480 - aux_output_loss: 1.0249 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4931 - main_output_loss: 0.4360 - aux_output_loss: 1.0075 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4922 - main_output_loss: 0.4352 - aux_output_loss: 1.0053 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4658 - main_output_loss: 0.4139 - aux_output_loss: 0.9323 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4589 - main_output_loss: 0.4072 - aux_output_loss: 0.9243 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we evaluate the model, Keras will return the total loss, as well as all the individual losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 752us/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0598d739d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Subclassing API to Build Dynamic Models  \n",
    "\n",
    "\n",
    "Both the Sequential API and the Functional API are declarative: you start by declaring which layers you want to use and how they should be connected, and only then can you start feeding the model some data for training or inference. This has many advantages: the model can easily be saved, cloned, and shared; its structure can be displayed and analyzed; the framework can infer shapes and check types, so errors can be caught early (i.e., before any data ever goes through the model). It’s also fairly easy to debug, since the whole model is a static graph of layers. But the flip side is just that: it’s static. Some models involve loops, varying shapes, conditional branching, and other dynamic behaviors. For such cases, or simply if you prefer a more imperative programming style, the Subclassing API is for you.\n",
    "\n",
    "Simply subclass the `Model` class, create the layers you need in the constructor, and use them to perform the computations you want in the `call()` method. For example, creating an instance of the following `WideAndDeepModel` class gives us an equivalent model to the one we just built with the Functional API. You can then compile it, evaluate it, and use it to make predictions, exactly like we just did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.3855 - output_1_loss: 3.3304 - output_2_loss: 3.8821 - val_loss: 2.1435 - val_output_1_loss: 1.1581 - val_output_2_loss: 11.0117\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0790 - output_1_loss: 0.9329 - output_2_loss: 2.3942 - val_loss: 1.7567 - val_output_1_loss: 0.8205 - val_output_2_loss: 10.1825\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8644 - output_1_loss: 0.7583 - output_2_loss: 1.8194 - val_loss: 1.5664 - val_output_1_loss: 0.7913 - val_output_2_loss: 8.5419\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7850 - output_1_loss: 0.6979 - output_2_loss: 1.5689 - val_loss: 1.3088 - val_output_1_loss: 0.6549 - val_output_2_loss: 7.1933\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7294 - output_1_loss: 0.6499 - output_2_loss: 1.4452 - val_loss: 1.1357 - val_output_1_loss: 0.5964 - val_output_2_loss: 5.9898\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6880 - output_1_loss: 0.6092 - output_2_loss: 1.3974 - val_loss: 1.0036 - val_output_1_loss: 0.5937 - val_output_2_loss: 4.6933\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6918 - output_1_loss: 0.6143 - output_2_loss: 1.3899 - val_loss: 0.8904 - val_output_1_loss: 0.5591 - val_output_2_loss: 3.8714\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6504 - output_1_loss: 0.5805 - output_2_loss: 1.2797 - val_loss: 0.8009 - val_output_1_loss: 0.5243 - val_output_2_loss: 3.2903\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6270 - output_1_loss: 0.5574 - output_2_loss: 1.2533 - val_loss: 0.7357 - val_output_1_loss: 0.5144 - val_output_2_loss: 2.7275\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6160 - output_1_loss: 0.5456 - output_2_loss: 1.2495 - val_loss: 0.6849 - val_output_1_loss: 0.5014 - val_output_2_loss: 2.3370\n",
      "162/162 [==============================] - 0s 666us/step - loss: 0.5841 - output_1_loss: 0.5188 - output_2_loss: 1.1722\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f05978cd940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example looks very much like the Functional API, except we do not need to create the inputs; we just use the input argument to the `call()` method, and we separate the creation of the layers in the constructor from their usage in the `call()` method. The big difference is that you can do pretty much anything you want in the `call()` method: for loops, if statements, low-level TensorFlow operations—your imagination is the limit (see Chapter 12)! This makes it a great API for researchers experimenting with new ideas.\n",
    "\n",
    "This extra flexibility does come at a cost: your model’s architecture is hidden within the `call()` method, so Keras cannot easily inspect it; it cannot save or clone it; and when you call the `summary()` method, you only get a list of layers, without any information on how they are connected to each other. Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4549 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 497us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will use the HDF5 format to save both the model’s architecture (including every layer’s hyperparameters) and the values of all the model parameters for every layer (e.g., connection weights and biases). It also saves the optimizer (including its hyperparameters and any state it may have). In Chapter 19, we will see how to save a tf.keras model using TensorFlow’s SavedModel format instead.\n",
    "\n",
    "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0597aabdc0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks during Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method accepts a callbacks argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. For example, the `ModelCheckpoint` callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you use a validation set during training, you can set `save_best_only=True` when creating the `ModelCheckpoint`. In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set. The following code is a simple way to implement early stopping (introduced in Chapter 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4549 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 472us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to simply use the `EarlyStopping` callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the patience argument), and it will optionally roll back to the best model. You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4578 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.4430 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.4376 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 889us/step - loss: 0.4361 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.4204 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 889us/step - loss: 0.4112 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.4226 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.4135 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 878us/step - loss: 0.4039 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.4023 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3912 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3939 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3868 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3878 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.3935 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3817 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3801 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3679 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3624 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3746 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3605 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3626 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3610 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.3626 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 889us/step - loss: 0.3685 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3684 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3581 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.3687 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3613 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3555 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3620 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3502 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.3471 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.3780 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3474 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3689 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.3675 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3471 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 885us/step - loss: 0.3545 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.3407 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.3554 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.3499 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.3623 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3401 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3528 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3560 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.3483 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3405 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3468 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3462 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.3342 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.3395 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.3315 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.3394 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3378 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.3522 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.3473 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3427 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3212 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3374 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3323 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3470 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.3316 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 872us/step - loss: 0.3354 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3316 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3371 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.3201 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3373 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3268 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.3322 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3224 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.3331 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.3310 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.3323 - val_loss: 0.3354\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 848us/step - loss: 0.3297 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3441 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3369 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.3182 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3184 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.3395 - val_loss: 0.3529\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3264 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.3210 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3192 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3237 - val_loss: 0.3211\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.3281 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3424 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3209 - val_loss: 0.3409\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.3230 - val_loss: 0.3379\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3341 - val_loss: 0.3213\n",
      "162/162 [==============================] - 0s 510us/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of epochs can be set to a large value since training will stop automatically when there is no more progress. In this case, there is no need to restore the best model saved because the EarlyStopping callback will keep track of the best weights and restore them for you at the end of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3556\n",
      "\n",
      "val/train: 1.08\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, you can implement `on_train_begin()`, `on_train_end()`, `on_epoch_begin()`, `on_epoch_end()`, `on_batch_begin()`, and `on_batch_end()`. Callbacks can also be used during evaluation and predictions, should you ever need them (e.g., for debugging). For evaluation, you should implement `on_test_begin()`, `on_test_end()`, `on_test_batch_begin()`, or `on_test_batch_end()` (called by `evaluate()`), and for prediction you should implement `on_predict_begin()`, `on_predict_end()`, `on_predict_batch_begin()`, or `on_predict_batch_end()` (called by `predict()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more! \n",
    "\n",
    "To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called event files. Each binary data record is called a *summary*. The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations: this allows you to visualize live data (with a short delay), such as the learning curves during training. In general, you want to point the TensorBoard server to a root log directory and configure your program so that it writes to a different subdirectory every time it runs. This way, the same TensorBoard server instance will allow you to visualize and compare data from multiple runs of your program, without getting everything mixed up.\n",
    "\n",
    "Let’s start by defining the root log directory we will use for our TensorBoard logs, plus a small function that will generate a subdirectory path based on the current date and time so that it’s different at every run. You may want to include extra information in the log directory name, such as hyperparameter values that you are testing, to make it easier to know what you are looking at in TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2022_04_22-16_57_55'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 879us/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4549 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.4416 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4295 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4326 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 946us/step - loss: 0.4207 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.4198 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.4248 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.4070 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3902 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 877us/step - loss: 0.3864 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3978 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3816 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4042 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3823 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3792 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.3800 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3858 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3839 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3736 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3843 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./my_logs/:\n",
      "run_2022_04_22-16_57_55\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55:\n",
      "train  validation\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55/train:\n",
      "events.out.tfevents.1650661075.DESKTOP-0TJ97T7.19565.255930.v2\tplugins\n",
      "events.out.tfevents.1650661075.DESKTOP-0TJ97T7.profile-empty\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55/train/plugins:\n",
      "profile\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55/train/plugins/profile:\n",
      "2022_04_22_16_57_55\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55/train/plugins/profile/2022_04_22_16_57_55:\n",
      "DESKTOP-0TJ97T7.input_pipeline.pb\tDESKTOP-0TJ97T7.tensorflow_stats.pb\n",
      "DESKTOP-0TJ97T7.kernel_stats.pb\t\tDESKTOP-0TJ97T7.trace.json.gz\n",
      "DESKTOP-0TJ97T7.memory_profile.json.gz\tDESKTOP-0TJ97T7.xplane.pb\n",
      "DESKTOP-0TJ97T7.overview_page.pb\n",
      "\n",
      "./my_logs/run_2022_04_22-16_57_55/validation:\n",
      "events.out.tfevents.1650661076.DESKTOP-0TJ97T7.19565.256701.v2\n"
     ]
    }
   ],
   "source": [
    "!ls -R ./my_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
    "\n",
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20567), started 2 days, 2:19:02 ago. (Use '!kill 20567' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cd740abf5a2e8383\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cd740abf5a2e8383\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2022_04_22-16_58_13'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7645 - val_loss: 302.8536\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 816us/step - loss: 8159520618.2209 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 984us/step - loss: 1.3439 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 868us/step - loss: 1.3546 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 961us/step - loss: 1.3513 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 933us/step - loss: 1.3274 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3639 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 865us/step - loss: 1.3487 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 941us/step - loss: 1.3445 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 867us/step - loss: 1.3697 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 939us/step - loss: 1.3622 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 875us/step - loss: 1.3389 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 948us/step - loss: 1.3336 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 940us/step - loss: 1.3429 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 892us/step - loss: 1.3275 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 956us/step - loss: 1.3669 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 931us/step - loss: 1.3645 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 920us/step - loss: 1.3839 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 904us/step - loss: 1.3078 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 914us/step - loss: 1.3215 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 961us/step - loss: 1.3344 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 919us/step - loss: 1.3269 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 944us/step - loss: 1.3590 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 910us/step - loss: 1.3381 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 866us/step - loss: 1.3265 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 898us/step - loss: 1.3532 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 960us/step - loss: 1.3552 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 932us/step - loss: 1.3447 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 917us/step - loss: 1.3379 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 934us/step - loss: 1.3583 - val_loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flexibility of neural networks is also one of their main drawbacks: there are many hyperparameters to tweak. Not only can you use any imaginable network architecture, but even in a simple MLP you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic, and much more. How do you know what combination of hyperparameters is the best for your task?\n",
    "\n",
    "One option is to simply try many combinations of hyperparameters and see which one works best on the validation set (or use K-fold cross-validation). For example, we can use `GridSearchCV` or `RandomizedSearchCV` to explore the hyperparameter space, as we did in Chapter 2. To do this, we need to wrap our Keras models in objects that mimic regular Scikit-Learn regressors. The first step is to create a function that will build and compile a Keras model, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 999us/step - loss: 1.5673 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 1.3216 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.5972 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.4985 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.4608 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.4410 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.4463 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.4283 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.4139 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.4107 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 836us/step - loss: 0.3992 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3982 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3983 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.3910 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3948 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3981 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.3821 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.3851 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3753 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3634 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 824us/step - loss: 0.3787 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3628 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3892 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3676 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.3677 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.3690 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 810us/step - loss: 0.3731 - val_loss: 0.3474\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.3725 - val_loss: 0.3920\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.3660 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3700 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3635 - val_loss: 0.3721\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.3628 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3647 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3547 - val_loss: 0.3453\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3496 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.3476 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 814us/step - loss: 0.3786 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.3540 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3769 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 768us/step - loss: 0.3522 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.3705 - val_loss: 0.3659\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.3545 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.3597 - val_loss: 0.3765\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.3443 - val_loss: 0.3814\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3591 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.3528 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.3663 - val_loss: 0.3655\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.3479 - val_loss: 0.3579\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.3601 - val_loss: 0.3360\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.3616 - val_loss: 0.3318\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3532 - val_loss: 0.3562\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3427 - val_loss: 0.3520\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3503 - val_loss: 0.4579\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3402 - val_loss: 0.3808\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3496 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 814us/step - loss: 0.3401 - val_loss: 0.3723\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3440 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3348 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.3445 - val_loss: 0.3264\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3414 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3621 - val_loss: 0.3346\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.3497 - val_loss: 0.3493\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.3484 - val_loss: 0.3402\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3299 - val_loss: 0.3275\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.3410 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.3364 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3558 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 766us/step - loss: 0.3372 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.3394 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 785us/step - loss: 0.3350 - val_loss: 0.3672\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.3428 - val_loss: 0.3375\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 741us/step - loss: 0.3261 - val_loss: 0.3271\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 796us/step - loss: 0.3409 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3394 - val_loss: 0.3665\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.3286 - val_loss: 0.3283\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3391 - val_loss: 0.3240\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.3293 - val_loss: 0.3381\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 751us/step - loss: 0.3372 - val_loss: 0.3356\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 812us/step - loss: 0.3364 - val_loss: 0.3224\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3374 - val_loss: 0.3595\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3381 - val_loss: 0.3432\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 827us/step - loss: 0.3481 - val_loss: 0.3211\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.3441 - val_loss: 0.3342\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 771us/step - loss: 0.3240 - val_loss: 0.4136\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 840us/step - loss: 0.3303 - val_loss: 0.3285\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.3263 - val_loss: 0.3440\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 781us/step - loss: 0.3483 - val_loss: 0.3733\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 777us/step - loss: 0.3305 - val_loss: 0.3188\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.3283 - val_loss: 0.3492\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 729us/step - loss: 0.3243 - val_loss: 0.3175\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 822us/step - loss: 0.3288 - val_loss: 0.3594\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.3343 - val_loss: 0.3169\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.3485 - val_loss: 0.3607\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 762us/step - loss: 0.3262 - val_loss: 0.5184\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.3284 - val_loss: 0.7536\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.3494 - val_loss: 0.5075\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3290 - val_loss: 0.8087\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.3277 - val_loss: 1.0447\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 803us/step - loss: 0.3199 - val_loss: 1.6881\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3706 - val_loss: 1.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05978ca9d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 722us/step - loss: 0.3409\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0598aa51f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5888452, 1.5484407, 4.1112185, 2.622048 , 2.9170763],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:5]\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001, 2.186  , 2.78   ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don’t want to train and evaluate a single model like this, though we want to train hundreds of variants and see which one performs best on the validation set. Since there are many hyperparameters, it is preferable to use a randomized search rather than grid search (as we discussed in Chapter 2). Let’s try to explore the number of hidden layers, the number of neurons, and the learning rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the following cell crashes at the end of training. This seems to be caused by [Keras issue #13586](https://github.com/keras-team/keras/issues/13586), which was triggered by a recent change in Scikit-Learn. [Pull Request #13598](https://github.com/keras-team/keras/pull/13598) seems to fix the issue, so this problem should be resolved soon. In the meantime, I've added `.tolist()` and `.rvs(1000).tolist()` as workarounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3827 - val_loss: 0.4703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.4880 - val_loss: 0.4247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4541 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4518 - val_loss: 0.3975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4337 - val_loss: 0.3991\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4263 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4385 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4301 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4108 - val_loss: 0.4040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.4200 - val_loss: 0.3886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4099 - val_loss: 0.3999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3897 - val_loss: 0.4085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4265 - val_loss: 0.3922\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.4108 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4070 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4032 - val_loss: 0.3933\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4212 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4241 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4040 - val_loss: 0.3935\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4146 - val_loss: 0.3891\n",
      "121/121 [==============================] - 0s 539us/step - loss: 0.4251\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   4.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3852 - val_loss: 0.4860\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4722 - val_loss: 0.4280\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4384 - val_loss: 0.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4422 - val_loss: 0.4549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4527 - val_loss: 0.5250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4474 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.5871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4382 - val_loss: 0.4759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4299 - val_loss: 0.7523\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.4390 - val_loss: 0.7478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4395 - val_loss: 0.8981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4234 - val_loss: 0.8543\n",
      "121/121 [==============================] - 0s 575us/step - loss: 0.4537\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   3.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13.5523 - val_loss: 4.2468\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 1.2460 - val_loss: 0.5794\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.5520 - val_loss: 0.4357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4507 - val_loss: 0.4169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4365 - val_loss: 0.4135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4283 - val_loss: 0.4206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4100\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4636 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4411 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.4840 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4626 - val_loss: 0.4062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4326 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4226 - val_loss: 0.4160\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4260 - val_loss: 0.4158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4551 - val_loss: 0.4137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4552 - val_loss: 0.4069\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4343 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4453 - val_loss: 0.4149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4530 - val_loss: 0.4081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4502 - val_loss: 0.4141\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4420 - val_loss: 0.4100\n",
      "121/121 [==============================] - 0s 513us/step - loss: 0.4473\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   4.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7737 - val_loss: 6.2480\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 5.2166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5147 - val_loss: 0.4474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3757 - val_loss: 0.3803\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3961\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.3988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3770\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3843\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3770\n",
      "121/121 [==============================] - 0s 496us/step - loss: 0.3561\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   4.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5396 - val_loss: 3.5738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.7767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.5515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.5335\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.5336\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.8724\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.9645\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.7225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.7257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.7218\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.8428\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.7061\n",
      "121/121 [==============================] - 0s 558us/step - loss: 0.3650\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   4.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7832 - val_loss: 2.9433\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5594 - val_loss: 4.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 2.8526\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4774 - val_loss: 1.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3736 - val_loss: 0.4172\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3769\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3418\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.4452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3454\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.4354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3302\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3545\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3459\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3327 - val_loss: 0.3245\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3455 - val_loss: 0.3256\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3216 - val_loss: 0.3385\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3660\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3963\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3146\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3194\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.4215\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3238\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3141\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3294 - val_loss: 0.4323\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3191 - val_loss: 0.3116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.4257\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.4807\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3009 - val_loss: 0.6419\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.6205\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 1.0407\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.9436\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3885\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3000 - val_loss: 0.7540\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 1.0124\n",
      "121/121 [==============================] - 0s 516us/step - loss: 0.3183\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.2328 - val_loss: 13.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 2.4156 - val_loss: 10.8972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 1.4953 - val_loss: 7.7330\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 1.1092 - val_loss: 5.0744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.8935 - val_loss: 3.2363\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.8194 - val_loss: 2.1597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.7802 - val_loss: 1.4840\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.7285 - val_loss: 1.1083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6921 - val_loss: 0.8942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.6951 - val_loss: 0.7687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.6599 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.6237 - val_loss: 0.6524\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.6619 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6487 - val_loss: 0.6061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.6429 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.6103 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.6492 - val_loss: 0.5733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.6227 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.6024 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5992 - val_loss: 0.5508\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5874 - val_loss: 0.5446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5653 - val_loss: 0.5384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.5863 - val_loss: 0.5326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5639 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.5689 - val_loss: 0.5214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5438 - val_loss: 0.5166\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5653 - val_loss: 0.5116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.5540 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.5635 - val_loss: 0.5035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5438 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5203 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.5238 - val_loss: 0.4915\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5159 - val_loss: 0.4883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.5200 - val_loss: 0.4856\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.5080 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4939 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.5136 - val_loss: 0.4780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4794 - val_loss: 0.4742\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5037 - val_loss: 0.4729\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 0.4714\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4870 - val_loss: 0.4686\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5008 - val_loss: 0.4666\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4892 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4786 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4812 - val_loss: 0.4616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4710 - val_loss: 0.4582\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4787 - val_loss: 0.4581\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.4573\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4752 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4641 - val_loss: 0.4544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4536 - val_loss: 0.4525\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4800 - val_loss: 0.4527\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4622 - val_loss: 0.4522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4648 - val_loss: 0.4509\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4387 - val_loss: 0.4509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4897 - val_loss: 0.4513\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4494 - val_loss: 0.4496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4645 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4580 - val_loss: 0.4502\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4393 - val_loss: 0.4478\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4271 - val_loss: 0.4485\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4362 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4499 - val_loss: 0.4477\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4377 - val_loss: 0.4497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4153 - val_loss: 0.4512\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4718 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4375 - val_loss: 0.4483\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4390 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.4546 - val_loss: 0.4476\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4346 - val_loss: 0.4481\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4486 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4463 - val_loss: 0.4486\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.4312 - val_loss: 0.4491\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4328 - val_loss: 0.4496\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4235 - val_loss: 0.4483\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4181 - val_loss: 0.4474\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4187 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4158 - val_loss: 0.4495\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4468\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4071 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3911 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4320 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4206 - val_loss: 0.4495\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3961 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4143 - val_loss: 0.4512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.4150 - val_loss: 0.4481\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4045 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3976 - val_loss: 0.4506\n",
      "121/121 [==============================] - 0s 619us/step - loss: 0.4209\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  20.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4546 - val_loss: 7.5238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7950 - val_loss: 8.6120\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 1.1115 - val_loss: 8.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.9287 - val_loss: 7.7423\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8253 - val_loss: 6.8202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.7837 - val_loss: 5.9344\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.7711 - val_loss: 5.1492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.7292 - val_loss: 4.4548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.7279 - val_loss: 3.9122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.7055 - val_loss: 3.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.6956 - val_loss: 2.9997\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.6640 - val_loss: 2.6082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.6539 - val_loss: 2.2766\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.6447 - val_loss: 1.9984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.6831 - val_loss: 1.7447\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.6364 - val_loss: 1.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.6425 - val_loss: 1.3410\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.6340 - val_loss: 1.1762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.6140 - val_loss: 1.0345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.6101 - val_loss: 0.9174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5938 - val_loss: 0.8153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5975 - val_loss: 0.7363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.5956 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.5714 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5535 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.5553 - val_loss: 0.5491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5299\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5688 - val_loss: 0.5199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5619 - val_loss: 0.5172\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.5510 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5401 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5370 - val_loss: 0.5447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.5423 - val_loss: 0.5639\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.5211 - val_loss: 0.5821\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.5081 - val_loss: 0.6039\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5036 - val_loss: 0.6306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.5191 - val_loss: 0.6564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4928 - val_loss: 0.6820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5096 - val_loss: 0.7087\n",
      "121/121 [==============================] - 0s 498us/step - loss: 0.5160\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=   9.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8993 - val_loss: 7.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 2.4173 - val_loss: 5.2071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 1.4701 - val_loss: 2.9554\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 1.1716 - val_loss: 1.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.9242 - val_loss: 1.1201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.8307 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.7780 - val_loss: 0.7512\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.7632 - val_loss: 0.7064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.7361 - val_loss: 0.6896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6859 - val_loss: 0.6760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.7064 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6826 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.6416 - val_loss: 0.6454\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.6539 - val_loss: 0.6355\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.6736 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.6529 - val_loss: 0.6213\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.6253 - val_loss: 0.6120\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.6484 - val_loss: 0.6024\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.6228 - val_loss: 0.5998\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5912 - val_loss: 0.5822\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.6250 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.5804 - val_loss: 0.5664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.5735 - val_loss: 0.5574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5793 - val_loss: 0.5527\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5576 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.5786 - val_loss: 0.5437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5683 - val_loss: 0.5366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5475 - val_loss: 0.5322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5471 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5281 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5547 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.5437 - val_loss: 0.5137\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.5078\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.5125 - val_loss: 0.5045\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5127 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5158 - val_loss: 0.4911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5132 - val_loss: 0.4887\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.4847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4995 - val_loss: 0.4815\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4795 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4838 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4966 - val_loss: 0.4706\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4932 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4810 - val_loss: 0.4655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4737 - val_loss: 0.4625\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4866 - val_loss: 0.4576\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.4719 - val_loss: 0.4554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.4859 - val_loss: 0.4525\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4618 - val_loss: 0.4495\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4862 - val_loss: 0.4468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.4576 - val_loss: 0.4446\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4641 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4641 - val_loss: 0.4394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4560 - val_loss: 0.4373\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4620 - val_loss: 0.4349\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4330\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4659 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4584 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4684 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4678 - val_loss: 0.4257\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4516 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4410 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4622 - val_loss: 0.4208\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4594 - val_loss: 0.4193\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4354 - val_loss: 0.4180\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4460 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4504 - val_loss: 0.4151\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4247 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4433 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4618 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4168 - val_loss: 0.4101\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4359 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4307 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4273 - val_loss: 0.4073\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4386 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4324 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4313 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4328 - val_loss: 0.4034\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4033\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4138 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4241 - val_loss: 0.4008\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4112 - val_loss: 0.4002\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4320 - val_loss: 0.3996\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4259 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4110 - val_loss: 0.3980\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4237 - val_loss: 0.3981\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4058 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4303 - val_loss: 0.3978\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.4157 - val_loss: 0.3961\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4229 - val_loss: 0.3951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4118 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4005 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4222 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4279 - val_loss: 0.3934\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4027 - val_loss: 0.3932\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4108 - val_loss: 0.3939\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3998 - val_loss: 0.3913\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4002 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4052 - val_loss: 0.3918\n",
      "121/121 [==============================] - 0s 556us/step - loss: 0.4139\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  23.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.4453 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7645 - val_loss: 0.7463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6590 - val_loss: 0.5899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.5580 - val_loss: 0.5063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5150 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4985 - val_loss: 0.4639\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4716 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4393\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4204 - val_loss: 0.4071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3978 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.3947\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3741\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3800 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3691 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4047\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3599 - val_loss: 0.3839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3795 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3629 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3476\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3566\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3414\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3944\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3453 - val_loss: 0.4403\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3539 - val_loss: 0.4722\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3449 - val_loss: 0.3722\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.4019\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 0.3376\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3738\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3563\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3370 - val_loss: 0.3547\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3398\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3304\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3850\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3238 - val_loss: 0.3430\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3329 - val_loss: 0.3387\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3654\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3310\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3366 - val_loss: 0.3730\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3374\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3402\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3440\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3275 - val_loss: 0.3581\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3303\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3680\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3119 - val_loss: 0.3292\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3276\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3562\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3287 - val_loss: 0.3295\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3439\n",
      "121/121 [==============================] - 0s 533us/step - loss: 0.3550\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  17.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2276 - val_loss: 3.4090\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.7673 - val_loss: 1.6754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6369 - val_loss: 0.9319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.6031 - val_loss: 0.6042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.5652 - val_loss: 0.5061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5258 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4977 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.5600\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4640 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.5221\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4878\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4222 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3975 - val_loss: 0.4022\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4348\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4935\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.5340\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.5982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.6541\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.7245\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.3840 - val_loss: 0.8045\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.8587\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.9089\n",
      "121/121 [==============================] - 0s 576us/step - loss: 0.3884\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   6.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3058 - val_loss: 2.1643\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7651 - val_loss: 0.6141\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6136 - val_loss: 0.5601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5596 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5239 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4749\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4755 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4131 - val_loss: 0.4250\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.4009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4130 - val_loss: 0.4014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3964\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3962 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3999 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3901 - val_loss: 0.4053\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3864\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3718 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3711 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3648 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3695 - val_loss: 0.3879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3659 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.4232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 542us/step - loss: 0.3555\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   9.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.9995 - val_loss: 297.3653\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 1.2481 - val_loss: 539.0366\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 2.5441 - val_loss: 3736.4512\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 7.4651 - val_loss: 12227.6963\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 22.4715 - val_loss: 61529.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 2537.2815 - val_loss: 268363.3750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 2132.8528 - val_loss: 1210516.8750\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 32696.8214 - val_loss: 5411000.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 28036.2842 - val_loss: 24506666.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 910065.1954 - val_loss: 119812880.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 1721895.0969 - val_loss: 529730336.0000\n",
      "121/121 [==============================] - 0s 561us/step - loss: 1402363.6250\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2323 - val_loss: 15.8284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5228 - val_loss: 22.4892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.5292 - val_loss: 24.7894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.5081 - val_loss: 22.4864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.5095 - val_loss: 21.9009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.5093 - val_loss: 21.2895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4936 - val_loss: 19.9064\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.5221 - val_loss: 22.5013\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5027 - val_loss: 20.0987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4831 - val_loss: 10.7128\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.5128 - val_loss: 19.7319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4957 - val_loss: 24.3237\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5081 - val_loss: 25.9485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4740 - val_loss: 10.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5379 - val_loss: 17.1916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5078 - val_loss: 21.8347\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4993 - val_loss: 11.7743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5211 - val_loss: 14.1555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5103 - val_loss: 20.9814\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4812 - val_loss: 12.3621\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.5134 - val_loss: 25.9146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4890 - val_loss: 16.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5148 - val_loss: 19.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4909 - val_loss: 12.1054\n",
      "121/121 [==============================] - 0s 449us/step - loss: 0.7813\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   5.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9669 - val_loss: 307.7497\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 1.0908 - val_loss: 76.3015\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.8437 - val_loss: 795.2294\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 41.8219 - val_loss: 704.0454\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 1.0379 - val_loss: 2668.0312\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 6.1716 - val_loss: 1446.2616\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 3.3018 - val_loss: 1540.5388\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 71.5701 - val_loss: 1396.7128\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 6.0212 - val_loss: 1334.0870\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 2.0299 - val_loss: 216.7278\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 21.3466 - val_loss: 125.2071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.7510 - val_loss: 2.2903\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4922 - val_loss: 790.5432\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.4409 - val_loss: 468.7433\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0499 - val_loss: 1073.9164\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 45.2525 - val_loss: 865.6384\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7759 - val_loss: 1128.1508\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 2.7236 - val_loss: 499.5195\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 34.6840 - val_loss: 309.7943\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 2.3475 - val_loss: 354.6347\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 2.4646 - val_loss: 559.4493\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 3.0812 - val_loss: 393.8702\n",
      "121/121 [==============================] - 0s 456us/step - loss: 0.6226\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   5.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.9862 - val_loss: 1.4543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6404 - val_loss: 0.9557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.4628\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.4214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 0.3984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4032 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3741\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3832\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3490 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3900\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3902\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3942\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3438 - val_loss: 0.3811\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3389 - val_loss: 0.3907\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.3624\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   5.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.7235 - val_loss: 0.5822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5852 - val_loss: 0.4873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.4420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.4139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4132\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4464\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.8506\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3419 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.9306\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.9345\n",
      "121/121 [==============================] - 0s 606us/step - loss: 0.3685\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   4.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.7434 - val_loss: 0.6796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5868 - val_loss: 0.4957\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4565\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.4150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.3785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3652\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3635 - val_loss: 0.3763\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3498 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.3555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3807\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3312 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3432\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3436 - val_loss: 0.4466\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3323\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3290 - val_loss: 0.3991\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3434\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3349\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3639\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3461\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3119 - val_loss: 0.3591\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3636\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3380\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.5245\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3326\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3191 - val_loss: 0.4047\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3341\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3658\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3322\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3245 - val_loss: 0.3683\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3088\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3814\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3186\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3053 - val_loss: 0.3008\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.4070\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3025\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3945\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3052\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3039\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.2963\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.2948\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3069 - val_loss: 0.3446\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3004\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.2959\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3250\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3697\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.5512\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3448\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3010 - val_loss: 0.4009\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3734\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2988 - val_loss: 0.3429\n",
      "121/121 [==============================] - 0s 571us/step - loss: 0.3114\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  17.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4800 - val_loss: 29.5063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.8491 - val_loss: 33.7784\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.8416 - val_loss: 4.0125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.6237 - val_loss: 0.5556\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5755 - val_loss: 0.5119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5306 - val_loss: 0.4888\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.5198 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4973 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4747 - val_loss: 0.4601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4664 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4450 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4195 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4480 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4328 - val_loss: 0.4231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4293 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4155 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4284 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.4067 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4111 - val_loss: 0.4001\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4041 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.3951 - val_loss: 0.4032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3942 - val_loss: 0.3764\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4024 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3863 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4067 - val_loss: 0.4126\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3956 - val_loss: 0.3967\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.3976 - val_loss: 0.4045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3876 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3863 - val_loss: 0.3717\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3779 - val_loss: 0.4054\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3758 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.4182\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3769 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3741 - val_loss: 0.4403\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3729 - val_loss: 0.3551\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3570 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3686 - val_loss: 0.3665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3748 - val_loss: 0.3591\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3570\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3743 - val_loss: 0.3547\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3585 - val_loss: 0.3779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3692 - val_loss: 0.3886\n",
      "121/121 [==============================] - 0s 472us/step - loss: 0.3877\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  11.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3075 - val_loss: 0.7805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.7479 - val_loss: 1.1550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.6249 - val_loss: 1.8115\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5885 - val_loss: 2.6113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.5412 - val_loss: 3.2626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5083 - val_loss: 3.5247\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4786 - val_loss: 3.5926\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.4660 - val_loss: 3.5562\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4559 - val_loss: 2.9541\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4427 - val_loss: 2.5606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 2.1560\n",
      "121/121 [==============================] - 0s 619us/step - loss: 0.4866\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   2.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9276 - val_loss: 2.5834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.7344 - val_loss: 3.5564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.6461 - val_loss: 1.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.6260 - val_loss: 1.7436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5519 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.5085 - val_loss: 0.8713\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5055 - val_loss: 0.5604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.5012 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4772 - val_loss: 0.4942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4582 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4637 - val_loss: 0.4536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4395 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4150 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.4219 - val_loss: 0.4897\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4455 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4279 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4250 - val_loss: 0.4347\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.3835\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.4083 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4025 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4011 - val_loss: 0.3720\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3929 - val_loss: 0.4318\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3957 - val_loss: 0.4158\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3918 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4040 - val_loss: 0.4069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3972 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3859 - val_loss: 0.5904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3872 - val_loss: 0.4027\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3742 - val_loss: 0.4216\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4065 - val_loss: 0.3604\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3831 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.3633\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3720 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3710 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3822 - val_loss: 0.4216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3764 - val_loss: 0.5522\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3867 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3818 - val_loss: 0.6416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3684 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3616 - val_loss: 0.5255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3771 - val_loss: 0.7023\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3837 - val_loss: 0.7508\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3698 - val_loss: 0.5608\n",
      "121/121 [==============================] - 0s 487us/step - loss: 0.3745\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  10.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.6933 - val_loss: 6.4183\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 16.7917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - val_loss: 4.7823\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4575 - val_loss: 8.6077\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 1.8033\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4075 - val_loss: 0.3655\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3664 - val_loss: 0.3784\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.4055\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3909\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3910\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3555\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.3611\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3653\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3632\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3252 - val_loss: 0.3562\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3238 - val_loss: 0.3559\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3556\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3494\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3533\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3203 - val_loss: 0.3413\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3364\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3530\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3387\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3084 - val_loss: 0.3076\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3483\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2950 - val_loss: 0.3063\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3288\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3452\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3321\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.2967\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2952 - val_loss: 0.3079\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.2935\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.3203\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3131\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.2900\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.3643\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.3348\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.3545\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.2958\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.3321\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.2870\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.2950\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.2850\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2744 - val_loss: 0.3206\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3254\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3312\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2683 - val_loss: 0.2868\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.2856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 0.2862\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2644 - val_loss: 0.3474\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2591 - val_loss: 0.3195\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.3195\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.2824\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2581 - val_loss: 0.2857\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2576 - val_loss: 0.2941\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.2839\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3084\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.2756\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.2859\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.2778\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2545 - val_loss: 0.3473\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.2803\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.3849\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2533 - val_loss: 0.2723\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2456 - val_loss: 0.3335\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.4009\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.4573\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2571 - val_loss: 0.2717\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2533 - val_loss: 0.3129\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.2774\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.3059\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.2838\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2606 - val_loss: 0.2842\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2620 - val_loss: 0.3037\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2507 - val_loss: 0.2853\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2595 - val_loss: 0.2895\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2486 - val_loss: 0.2767\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2429 - val_loss: 0.2956\n",
      "121/121 [==============================] - 0s 604us/step - loss: 0.3085\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  21.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4417 - val_loss: 0.7369\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.4431\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3834\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3951\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.6408\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.7273\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.9104\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.6969\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.6999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.7835\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.8539\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.8282\n",
      "121/121 [==============================] - 0s 512us/step - loss: 0.3525\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   4.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.6880 - val_loss: 0.9196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4943 - val_loss: 2.1025\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 3.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 1.5867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3522 - val_loss: 0.3738\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3350\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3384\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3720\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.3971\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3329\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3226\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.3672\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3210\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3253 - val_loss: 0.3579\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3125 - val_loss: 0.3219\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3227 - val_loss: 0.3558\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.3361\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3591\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3142\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3186\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3591\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3072\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3338\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.3272\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3140 - val_loss: 0.3118\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3419\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3102 - val_loss: 0.3919\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3055\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2896 - val_loss: 0.3150\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3035\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2980 - val_loss: 0.3303\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2852 - val_loss: 0.3032\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.2941\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.4024\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2903 - val_loss: 0.3373\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.4171\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3120\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.2846 - val_loss: 0.3722\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2699 - val_loss: 0.3132\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3368\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2922 - val_loss: 0.2825\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3396\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.2745 - val_loss: 0.2980\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.2761 - val_loss: 0.3311\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.2825\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2725 - val_loss: 0.2851\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 0.3564\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.2971\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.3396\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.2958\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.2951\n",
      "121/121 [==============================] - 0s 525us/step - loss: 0.3002\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  14.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5786 - val_loss: 10.9251\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 3.3912\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4521 - val_loss: 0.4039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.3692\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3670 - val_loss: 0.3555\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3875\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3633\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3991\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3797\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.3703\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3310\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3511\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3793\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3316\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3488\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3173 - val_loss: 0.3472\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.3264\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3422\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3366\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3223\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.4002\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3110\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3629\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3637\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3314\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3077\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3396\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3379\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3446\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.3101\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3391\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.3048\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.3312\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3129\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.2918\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2825 - val_loss: 0.3515\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2732 - val_loss: 0.3330\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3513\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3001\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.3296\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2753 - val_loss: 0.2921\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.3098\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2771 - val_loss: 0.2918\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3196\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2755 - val_loss: 0.2798\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2630 - val_loss: 0.3235\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2673 - val_loss: 0.3136\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3066\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.2784\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2654 - val_loss: 0.3552\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.3143\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.3259\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3045\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2540 - val_loss: 0.2954\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3185\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2768 - val_loss: 0.2765\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2679 - val_loss: 0.3349\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2640 - val_loss: 0.3149\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.2738\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.3173\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2515 - val_loss: 0.3197\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2552 - val_loss: 0.3052\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2630 - val_loss: 0.3356\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2531 - val_loss: 0.3531\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2465 - val_loss: 0.2817\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2685 - val_loss: 0.3063\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2575 - val_loss: 0.3056\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3599\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.2705\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3327\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2569 - val_loss: 0.2791\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.4311\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3029\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2640 - val_loss: 0.4839\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2524 - val_loss: 0.2760\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2584 - val_loss: 0.3965\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.3056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2464 - val_loss: 0.3750\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2515 - val_loss: 0.2797\n",
      "121/121 [==============================] - 0s 618us/step - loss: 0.3016\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  21.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5488 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.6096\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.6534\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.6227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.8399\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 1.0573\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 1.1232\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 1.2405\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.8071\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.8317\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.7693\n",
      "121/121 [==============================] - 0s 565us/step - loss: 0.3595\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   3.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4295 - val_loss: 2.2007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5148 - val_loss: 3.3028\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.9130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.5328\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.3609\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3567 - val_loss: 0.4231\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3283\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3466\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.4040\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3272\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3769\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3130 - val_loss: 0.3209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3198 - val_loss: 0.3301\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3349 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3440\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3378\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3046\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3115\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3425\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3284\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3661\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3144 - val_loss: 0.4084\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3410\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3022 - val_loss: 0.3331\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.3120\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3405\n",
      "121/121 [==============================] - 0s 659us/step - loss: 0.3036\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   9.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1527 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5713 - val_loss: 8.9879\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 11.0986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5126 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.5258\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3984 - val_loss: 0.4499\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3998\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3701 - val_loss: 0.3903\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3650\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3528 - val_loss: 0.3816\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3518 - val_loss: 0.3620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3489 - val_loss: 0.3670\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3669\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3606\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3551\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 0.3535\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3521\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3313 - val_loss: 0.3474\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3531\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3382 - val_loss: 0.3298\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3398 - val_loss: 0.3679\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3262 - val_loss: 0.3244\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3421\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.3408\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3318 - val_loss: 0.3430\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3208\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3150\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3229 - val_loss: 0.3509\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3158\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3178 - val_loss: 0.3836\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3596\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3258 - val_loss: 0.3542\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3116 - val_loss: 0.3175\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3007 - val_loss: 0.3486\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3138 - val_loss: 0.3187\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3190\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3086\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3092 - val_loss: 0.3505\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3051\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.3303\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3051 - val_loss: 0.3350\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2949 - val_loss: 0.3231\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3179 - val_loss: 0.3016\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3612\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.2900 - val_loss: 0.3298\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3131\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2994 - val_loss: 0.3143\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.2968 - val_loss: 0.3070\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.2971 - val_loss: 0.3698\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.2995\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3884\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3142\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.3033\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3000 - val_loss: 0.3136\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3676\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3380\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3356\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.3342\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.3091\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3091 - val_loss: 0.2988\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.3918\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.2933 - val_loss: 0.3026\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2925 - val_loss: 0.3563\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3104\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.4927\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3005\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.2985\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3542\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3016\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.2943 - val_loss: 0.5721\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.2832 - val_loss: 0.8889\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.2971 - val_loss: 0.8371\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3073 - val_loss: 0.3383\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2850 - val_loss: 0.3761\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2747 - val_loss: 0.2930\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.3313\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.2939\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3487\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2880 - val_loss: 0.2920\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2715 - val_loss: 0.2984\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.3051\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2867 - val_loss: 0.3356\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.2880\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.4234\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.2941 - val_loss: 0.3515\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.2944 - val_loss: 0.4546\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3065 - val_loss: 0.4674\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.4872\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3859\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2761 - val_loss: 0.7000\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.8526\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2835 - val_loss: 0.8769\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3565\n",
      "121/121 [==============================] - 0s 598us/step - loss: 0.3209\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  25.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2993 - val_loss: 0.8898\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5586 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4289 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.3735\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.4576\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4928\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.5255\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.5956\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.6364\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3456 - val_loss: 0.7456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.7136\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.6905\n",
      "121/121 [==============================] - 0s 590us/step - loss: 0.3615\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   4.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1229 - val_loss: 2.8528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6059 - val_loss: 2.3412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5163 - val_loss: 0.9015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4576 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.4012\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.6122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.3579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3497\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.5161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.5739\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.4975\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.4887\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 0.3371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3536 - val_loss: 0.4123\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3289\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3393 - val_loss: 0.3287\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3355 - val_loss: 0.5231\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3320 - val_loss: 0.7723\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.8988\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4934\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3446 - val_loss: 0.6236\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3448\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3345 - val_loss: 0.5678\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3712\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3455 - val_loss: 0.7379\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3972\n",
      "121/121 [==============================] - 0s 526us/step - loss: 0.3361\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   9.0s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4030 - val_loss: 1.8036\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.5715 - val_loss: 2.0827\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4548 - val_loss: 0.3796\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.4007 - val_loss: 0.4283\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3832 - val_loss: 0.3617\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3677 - val_loss: 0.4566\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3573\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3380\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3757\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3433 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3312 - val_loss: 0.5455\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.6470\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3320 - val_loss: 0.3109\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.3259 - val_loss: 0.3198\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3065\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3252\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3095 - val_loss: 0.3965\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3107 - val_loss: 0.2997\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3079\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3003 - val_loss: 0.4544\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3274\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.2949 - val_loss: 0.5018\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.5565\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.5390\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3339\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.2988 - val_loss: 0.5095\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3001 - val_loss: 0.6597\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 946us/step - loss: 0.3058 - val_loss: 0.5106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f0597afa370>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.0...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32039451599121094"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x7f065cdd6e20>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 709us/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3028871417045593"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f05a4c42e80>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 521us/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3028871417045593"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Hidden Layers**  \n",
    "\n",
    "For many problems, you can begin with a single hidden layer and get reasonable results. An MLP with just one hidden layer can theoretically model even the most complex functions, provided it has enough neurons. But for complex problems, deep networks have a much higher *parameter efficiency* than shallow ones: they can model complex functions using exponentially fewer neurons than shallow nets, allowing them to reach much better performance with the same amount of training data.\n",
    "\n",
    "To understand why, suppose you are asked to draw a forest using some drawing software, but you are forbidden to copy and paste anything. It would take an enormous amount of time: you would have to draw each tree individually, branch by branch, leaf by leaf. If you could instead draw one leaf, copy and paste it to draw a branch, then copy and paste that branch to create a tree, and finally copy and paste this tree to make a forest, you would be finished in no time. Real-world data is often structured in such a hierarchical way, and deep neural networks automatically take advantage of this fact: lower hidden layers model low-level structures (e.g., line segments of various shapes and orientations), intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g., squares, circles), and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g., faces).\n",
    "\n",
    "Not only does this hierarchical architecture help DNNs converge faster to a good solution, but it also improves their ability to generalize to new datasets. For example, if you have already trained a model to recognize faces in pictures and you now want to train a new neural network to recognize hairstyles, you can kickstart the training by reusing the lower layers of the first network. Instead of randomly initializing the weights and biases of the first few layers of the new neural network, you can initialize them to the values of the weights and biases of the lower layers of the first network. This way the network will not have to learn from scratch all the low-level structures that occur in most pictures; it will only have to learn the higher-level structures (e.g., hairstyles). This is called transfer learning.\n",
    "\n",
    "In summary, for many problems you can start with just one or two hidden layers and the neural network will work just fine. For instance, you can easily reach above 97% accuracy on the MNIST dataset using just one hidden layer with a few hundred neurons, and above 98% accuracy using two hidden layers with the same total number of neurons, in roughly the same amount of training time. For more complex problems, you can ramp up the number of hidden layers until you start overfitting the training set. Very complex tasks, such as large image classification or speech recognition, typically require networks with dozens of layers (or even hundreds, but not fully connected ones, as we will see in Chapter 14), and they need a huge amount of training data. You will rarely have to train such networks from scratch: it is much more common to reuse parts of a pretrained state-of-the-art network that performs a similar task. Training will then be a lot faster and require much less data (we will discuss this in Chapter 11).\n",
    "\n",
    "**Number of Neurons per Hidden Layer**  \n",
    "\n",
    "\n",
    "The number of neurons in the input and output layers is determined by the type of input and output your task requires. For example, the MNIST task requires 28 × 28 = 784 input neurons and 10 output neurons.\n",
    "\n",
    "As for the hidden layers, it used to be common to size them to form a pyramid, with fewer and fewer neurons at each layer—the rationale being that many low-level features can coalesce into far fewer high-level features. A typical neural network for MNIST might have 3 hidden layers, the first with 300 neurons, the second with 200, and the third with 100. However, this practice has been largely abandoned because it seems that using the same number of neurons in all hidden layers performs just as well in most cases, or even better; plus, there is only one hyperparameter to tune, instead of one per layer. That said, depending on the dataset, it can sometimes help to make the first hidden layer bigger than the others.\n",
    "\n",
    "Just like the number of layers, you can try increasing the number of neurons gradually until the network starts overfitting. But in practice, it’s often simpler and more efficient to pick a model with more layers and neurons than you actually need, then use early stopping and other regularization techniques to prevent it from overfitting. Vincent Vanhoucke, a scientist at Google, has dubbed this the “stretch pants” approach: instead of wasting time looking for pants that perfectly match your size, just use large stretch pants that will shrink down to the right size. With this approach, you avoid bottleneck layers that could ruin your model. On the flip side, if a layer has too few neurons, it will not have enough representational power to preserve all the useful information from the inputs (e.g., a layer with two neurons can only output 2D data, so if it processes 3D data, some information will be lost). No matter how big and powerful the rest of the network is, that information will never be recovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The TensorFlow Playground is a handy neural network simulator built by the TensorFlow team. In this exercise, you will train several binary classifiers in just a few clicks, and tweak the model’s architecture and its hyperparameters to gain some intuition on how neural networks work and what their hyperparameters do. Take some time to explore the following:\n",
    "\n",
    "  a. The patterns learned by a neural net. Try training the default neural network by clicking the Run button (top left). Notice how it quickly finds a good solution for the classification task. The neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns. In general, the more layers there are, the more complex the patterns can be.\n",
    "\n",
    "  b. Activation functions. Try replacing the tanh activation function with a ReLU activation function, and train the network again. Notice that it finds a solution even faster, but this time the boundaries are linear. This is due to the shape of the ReLU function.\n",
    "\n",
    "  c. The risk of local minima. Modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, click the Reset button next to the Play button). Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
    "\n",
    "  d. What happens when neural nets are too small. Remove one neuron to keep just two. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. The model has too few parameters and systematically underfits the training set.\n",
    "\n",
    "  e. What happens when neural nets are large enough. Set the number of neurons to eight, and train the network several times. Notice that it is now consistently fast and never gets stuck. This highlights an important finding in neural network theory: large neural networks almost never get stuck in local minima, and even when they do these local optima are almost as good as the global optimum. However, they can still get stuck on long plateaus for a long time.\n",
    "\n",
    "  f. The risk of vanishing gradients in deep networks. Select the spiral dataset (the bottom-right dataset under “DATA”), and change the network architecture to have four hidden layers with eight neurons each. Notice that training takes much longer and often gets stuck on plateaus for long periods of time. Also notice that the neurons in the highest layers (on the right) tend to evolve faster than the neurons in the lowest layers (on the left). This problem, called the “vanishing gradients” problem, can be alleviated with better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or Batch Normalization (discussed in Chapter 11).\n",
    "\n",
    "  g. Go further. Take an hour or so to play around with other parameters and get a feel for what they do, to build an intuitive understanding about neural networks.\n",
    "  \n",
    "  > Visit the [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.64512&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) and play around with it, as described in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Draw an ANN using the original artificial neurons (like the ones in Figure 10-3) that computes $A \\oplus B$ (where $\\oplus$ represents the XOR operation). Hint: $A \\oplus B = (A \\land \\lnot B \\lor (\\lnot A \\land B)$.\n",
    "\n",
    ">Here is a neural network based on the original artificial neurons that computes $A \\oplus B$ (where $\\oplus$ represents the exclusive OR), using the fact that $A \\oplus B = (A \\land \\lnot B \\lor (\\lnot A \\land B)$. There are other solutions—for example, using the fact that $A \\oplus B = (A \\lor B) \\land \\lnot (A \\land B)$, or the fact that $A \\oplus B = (A \\lor B) \\land (\\lnot A \\lor \\land B)$, and so on. \n",
    "\n",
    "<img src=\"./chapters/10/s2.png\" width=600>\n",
    "\n",
    "3. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?\n",
    "\n",
    ">A classical Perceptron will converge only if the dataset is linearly separable, and it won’t be able to estimate class probabilities. In contrast, a Logistic Regression classifier will converge to a good solution even if the dataset is not linearly separable, and it will output class probabilities. If you change the Perceptron’s activation function to the logistic activation function (or the softmax activation function if there are multiple neurons), and if you train it using Gradient Descent (or some other optimization algorithm minimizing the cost function, typically cross entropy), then it becomes equivalent to a Logistic Regression classifier.\n",
    "\n",
    "4. Why was the logistic activation function a key ingredient in training the first MLPs?\n",
    "\n",
    ">The logistic activation function was a key ingredient in training the first MLPs because its derivative is always nonzero, so Gradient Descent can always roll down the slope. When the activation function is a step function, Gradient Descent cannot move, as there is no slope at all.\n",
    "\n",
    "5. Name three popular activation functions. Can you draw them?\n",
    "\n",
    ">Popular activation functions include the step function, the logistic (sigmoid) function, the hyperbolic tangent (tanh) function, and the Rectified Linear Unit (ReLU) function (see Figure 10-8). See Chapter 11 for other examples, such as ELU and variants of the ReLU function.\n",
    "\n",
    "6. Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "- What is the shape of the input matrix $\\mathbf X$?\n",
    "> $m \\times 10$, where $m$ represents the training batch size.\n",
    "\n",
    "- What are the shapes of the hidden layer’s weight vector $\\mathbf W_h$ and its bias vector $\\mathbf b_h$?\n",
    "\n",
    "> $\\mathbf W_h$ is $10\\times 50$ and $\\mathbf b_h$ is $1\\times 50$\n",
    "\n",
    "- What are the shapes of the output layer’s weight vector $\\mathbf W_o$ and its bias vector $\\mathbf b_o$?\n",
    "\n",
    "> $\\mathbf W_o$ is $50\\times 3$ and $\\mathbf b_o$ is $1\\times 3$\n",
    "- What is the shape of the network’s output matrix $\\mathbf Y$?\n",
    "\n",
    "> $m\\times 3$ \n",
    "\n",
    "- Write the equation that computes the network’s output matrix $\\mathbf Y$ as a function of $\\mathbf X, \\mathbf W_h, \\mathbf b_h, \\mathbf W_o$, and $\\mathbf b_o$.\n",
    "\n",
    "> $$\\mathbf Y^* = ReLU(ReLU(\\mathbf X \\mathbf W_h + \\mathbf b_h) \\mathbf W_o + \\mathbf b_o)$$. Recall that the ReLU function just sets every negative number in the matrix to zero. Also note that when you are adding a bias vector to a matrix, it is added to every single row in the matrix, which is called *broadcasting*.\n",
    "\n",
    "7. How many neurons do you need in the output layer if you want to classify email into spam or ham? What activation function should you use in the output layer? If instead you want to tackle MNIST, how many neurons do you need in the output layer, and which activation function should you use? What about for getting your network to predict housing prices, as in Chapter 2?\n",
    "\n",
    "> To classify email into spam or ham, you just need one neuron in the output layer of a neural network—for example, indicating the probability that the email is spam. You would typically use the logistic activation function in the output layer when estimating a probability. If instead you want to tackle MNIST, you need 10 neurons in the output layer, and you must replace the logistic function with the softmax activation function, which can handle multiple classes, outputting one probability per class. If you want your neural network to predict housing prices like in Chapter 2, then you need one output neuron, using no activation function at all in the output layer.\n",
    "\n",
    "\n",
    "8. What is backpropagation and how does it work? What is the difference between backpropagation and reverse-mode autodiff?\n",
    "\n",
    "> Backpropagation is a technique used to train artificial neural networks. It first computes the gradients of the cost function with regard to every model parameter (all the weights and biases), then it performs a Gradient Descent step using these gradients. This backpropagation step is typically performed thousands or millions of times, using many training batches, until the model parameters converge to values that (hopefully) minimize the cost function. To compute the gradients, backpropagation uses reverse-mode autodiff (although it wasn’t called that when backpropagation was invented, and it has been reinvented several times). Reverse-mode autodiff performs a forward pass through a computation graph, computing every node’s value for the current training batch, and then it performs a reverse pass, computing all the gradients at once (see Appendix D for more details). So what’s the difference? Well, backpropagation refers to the whole process of training an artificial neural network using multiple backpropagation steps, each of which computes gradients and uses them to perform a Gradient Descent step. In contrast, reverse-mode autodiff is just a technique to compute gradients efficiently, and it happens to be used by backpropagation.\n",
    "\n",
    "9. Can you list all the hyperparameters you can tweak in a basic MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem? \n",
    "\n",
    "> Here is a list of all the hyperparameters you can tweak in a basic MLP: the number of hidden layers, the number of neurons in each hidden layer, and the activation function used in each hidden layer and in the output layer. In general, the ReLU activation function (or one of its variants; see Chapter 11) is a good default for the hidden layers.  {In Chapter 11 we discuss many techniques that introduce additional hyperparameters: type of weight initialization, activation function hyperparameters (e.g., the amount of leak in leaky ReLU), Gradient Clipping threshold, type of optimizer and its hyperparameters (e.g., the momentum hyperparameter when using a `MomentumOptimizer`), type of regularization for each layer and regularization hyperparameters (e.g., dropout rate when using dropout), and so on.} For the output layer, in general you will want the logistic activation function for binary classification, the softmax activation function for multiclass classification, or no activation function for regression.\n",
    "If the MLP overfits the training data, you can try reducing the number of hidden layers and reducing the number of neurons per hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Train a deep MLP on the MNIST dataset (you can load it using `keras.datasets.mnist.load_data()`. See if you can get over 98% precision. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for the Fashion MNIST dataset, the MNIST training set contains 60,000 grayscale images, each 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel intensity is also represented as a byte (0 to 255):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255, just like we did for Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
    " color map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGHElEQVR4nO3cz4tNfQDH8blPU4Zc42dKydrCpJQaopSxIdlYsLSykDBbO1slJWExSjKRP2GytSEWyvjRGKUkGzYUcp/dU2rO9z7umTv3c++8XkufzpkjvTvl25lGq9UaAvL80+sHABYmTgglTgglTgglTgg13Gb3X7nQfY2F/tCbE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0IN9/oBlqPbt29Xbo1Go3jthg0bivvLly+L+/j4eHHft29fcWfpeHNCKHFCKHFCKHFCKHFCKHFCKHFCqJ6dc967d6+4P3v2rLhPTU0t5uMsqS9fvnR87fBw+Z/sx48fxX1kZKS4r1q1qnIbGxsrXvvgwYPivmnTpuLOn7w5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IVSj1WqV9uLYzoULFyq3q1evFq/9/ft3nR9NDxw4cKC4T09PF/fNmzcv5uP0kwU/4vXmhFDihFDihFDihFDihFDihFDihFBdPefcunVr5fbhw4fite2+HVy5cmVHz7QY9u7dW9yPHTu2NA/SgZmZmeJ+586dym1+fr7Wz253Dnr//v3KbcC/BXXOCf1EnBBKnBBKnBBKnBBKnBBKnBCqq+ecr1+/rtxevHhRvHZiYqK4N5vNjp6Jsrm5ucrt8OHDxWtnZ2dr/ezLly9XbpOTk7XuHc45J/QTcUIocUIocUIocUIocUKorh6lMFgePnxY3I8fP17r/hs3bqzcPn/+XOve4RylQD8RJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Qa7vUDkOX69euV25MnT7r6s79//165PX36tHjtrl27Fvtxes6bE0KJE0KJE0KJE0KJE0KJE0KJE0L5vbU98PHjx8rt7t27xWuvXLmy2I/zh9Kz9dKaNWuK+9evX5foSbrC762FfiJOCCVOCCVOCCVOCCVOCCVOCOV7zg7MzMwU93bfHt68ebNye/fuXUfPNOhOnTrV60dYct6cEEqcEEqcEEqcEEqcEEqcEGpZHqW8efOmuJ8+fbq4P3r0aDEf569s27atuK9bt67W/S9dulS5jYyMFK89c+ZMcX/16lVHzzQ0NDS0ZcuWjq/tV96cEEqcEEqcEEqcEEqcEEqcEEqcEGpgzzlLv0Ly2rVrxWvn5uaK++rVq4v76OhocT9//nzl1u48b8+ePcW93TloN7X7e7fTbDYrtyNHjtS6dz/y5oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQA3vO+fjx48qt3Tnm0aNHi/vk5GRx379/f3HvV8+fPy/u79+/r3X/FStWVG7bt2+vde9+5M0JocQJocQJocQJocQJocQJocQJoQb2nPPGjRuV29jYWPHaixcvLvbjDIS3b98W90+fPtW6/8GDB2tdP2i8OSGUOCGUOCGUOCGUOCGUOCHUwB6lrF+/vnJzVNKZ0md4/8fatWuL+9mzZ2vdf9B4c0IocUIocUIocUIocUIocUIocUKogT3npDM7duyo3GZnZ2vd+9ChQ8V9fHy81v0HjTcnhBInhBInhBInhBInhBInhBInhHLOyR/m5+crt1+/fhWvHR0dLe7nzp3r4ImWL29OCCVOCCVOCCVOCCVOCCVOCCVOCOWcc5mZnp4u7t++favcms1m8dpbt24Vd99r/h1vTgglTgglTgglTgglTgglTgglTgjVaLVapb04kufnz5/Ffffu3cW99LtpT5w4Ubx2amqquFOpsdAfenNCKHFCKHFCKHFCKHFCKHFCKJ+MDZhGY8H/lf/PyZMni/vOnTsrt4mJiU4eiQ55c0IocUIocUIocUIocUIocUIocUIon4xB7/lkDPqJOCGUOCGUOCGUOCGUOCGUOCFUu+85yx8HAl3jzQmhxAmhxAmhxAmhxAmhxAmh/gWlotX4VjU5XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are the class IDs (represented as uint8), from 0 to 9. Conveniently, the class IDs correspond to the digits represented in the images, so we don't need a `class_names` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation set contains 5,000 images, and the test set contains 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a sample of the images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple dense network and find the optimal learning rate. We will need a callback to grow the learning rate at each iteration. It will also record the learning rate and the loss at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a small learning rate of 1e-3, and grow it by 0.5% at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model for just 1 epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.4883 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the loss as a functionof the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss starts shooting back up violently when the learning rate goes over 6e-1, so let's try using half of that, at 3e-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_mnist_logs/run_001'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4195 - accuracy: 0.8677 - val_loss: 0.0995 - val_accuracy: 0.9724\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0941 - accuracy: 0.9698 - val_loss: 0.0913 - val_accuracy: 0.9746\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.0785 - val_accuracy: 0.9772\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0438 - accuracy: 0.9855 - val_loss: 0.0793 - val_accuracy: 0.9784\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.0724 - val_accuracy: 0.9812\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0814 - val_accuracy: 0.9792\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0794 - val_accuracy: 0.9808\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0718 - val_accuracy: 0.9826\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.0796 - val_accuracy: 0.9812\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0930 - val_accuracy: 0.9796\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0832 - val_accuracy: 0.9824\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0954 - val_accuracy: 0.9808\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0795 - val_accuracy: 0.9826\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0936 - val_accuracy: 0.9816\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0914 - val_accuracy: 0.9848\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 5.6378e-04 - accuracy: 0.9999 - val_loss: 0.0836 - val_accuracy: 0.9848\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.3330e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.5450e-05 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9854\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.4051e-05 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9852\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 6.7127e-05 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 6.1427e-05 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9858\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 5.7542e-05 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9860\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 5.4774e-05 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9862\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 4.6887e-05 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9862\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 4.4208e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 4.0569e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9862\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 3.7617e-05 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 3.9655e-05 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9862\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 962us/step - loss: 0.0804 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08043693006038666, 0.9805999994277954]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got over 98% accuracy. Finally, let's look at the learning curves using TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-461beab1e88e8fbf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-461beab1e88e8fbf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
